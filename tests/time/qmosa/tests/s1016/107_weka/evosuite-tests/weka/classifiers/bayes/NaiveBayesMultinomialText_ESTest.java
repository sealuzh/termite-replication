/*
 * This file was automatically generated by EvoSuite
 * Wed Dec 04 02:25:27 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;
import java.io.StringReader;
import java.net.URISyntaxException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import java.util.Vector;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.net.MockURI;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.BayesNet;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.FindWithCapabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.neighboursearch.CoverTree;
import weka.core.neighboursearch.LinearNNSearch;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.core.stemmers.IteratedLovinsStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.AlphabeticTokenizer;
import weka.core.tokenizers.NGramTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.filters.AllFilter;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=3.3984526950965765
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      MockFile mockFile0 = new MockFile("u*");
      mockFile0.createNewFile();
      mockFile0.setReadable(true, true);
      mockFile0.setWritable(true, false);
      naiveBayesMultinomialText0.m_wordsPerClass = null;
      mockFile0.getCanonicalPath();
      mockFile0.setExecutable(false);
      mockFile0.delete();
      mockFile0.setReadable(true, true);
      mockFile0.toURL();
      mockFile0.getAbsoluteFile();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      Instance instance0 = null;
      naiveBayesMultinomialText0.m_leplace = 0.0;
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=2.7380350459888416
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.toString();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.getStemmer();
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.stopwordsTipText();
      String string1 = naiveBayesMultinomialText0.toString();
      assertEquals("The independent probability of a class\n--------------------------------------\nclass1\t12.0\nclass2\t10.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\t\n", string1);
      
      naiveBayesMultinomialText0.globalInfo();
      String string2 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string2);
      
      String string3 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string3);
      
      String string4 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string4);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      String string5 = naiveBayesMultinomialText2.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string5);
      assertEquals(1.0, naiveBayesMultinomialText2.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText2.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText2.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.574464215715726
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) nGramTokenizer0;
      naiveBayesMultinomialText0.pruneDictionary();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "r");
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.m_t = 743.9367254559;
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.getTokenizer();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "r";
      stringArray0[1] = "r";
      stringArray0[2] = "r";
      stringArray0[3] = "If true, ignores all words that are on the stoplist.";
      stringArray0[4] = "r";
      stringArray0[5] = "r";
      stringArray0[6] = "r";
      Tokenizer.runTokenizer(nGramTokenizer0, stringArray0);
      naiveBayesMultinomialText0.toString();
      try { 
        naiveBayesMultinomialText0.distributionForInstance((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=3.170615129749024
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "";
      stringArray0[1] = "t5.]Vc,19,";
      stringArray0[2] = "";
      stringArray0[3] = "com";
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      Tokenizer.runTokenizer(tokenizer0, stringArray0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray1.length);
      
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getTokenizer();
      String string0 = naiveBayesMultinomialText0.globalInfo();
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string0);
      
      String string1 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string1);
      
      String string2 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string2);
      
      String string3 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string3);
      
      String string4 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string4);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.5531257522061517
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "3W#A4_7lt");
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, true);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "3W#A4_7lt");
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = tokenizer0;
      AbstractClassifier.makeCopies(naiveBayesMultinomialText0, 2453);
      naiveBayesMultinomialText0.m_norm = (double) 2453;
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      MockFile mockFile0 = (MockFile)naiveBayesMultinomialText1.m_stopwordsFile;
      naiveBayesMultinomialText0.m_stopwordsFile = (File) mockFile0;
      naiveBayesMultinomialText0.m_minWordP = 0.0;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=3.4183959869756366
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      iteratedLovinsStemmer0.toString();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.toString();
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getOptions();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 6
  /*Coverage entropy=3.1743174176930435
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      String[] stringArray0 = new String[0];
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.setPeriodicPruning((-2534));
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.getRevision();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      file0.toURL();
      file0.setWritable(true, true);
      naiveBayesMultinomialText0.setStopwords(file0);
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
      assertFalse(boolean0);
  }

  /**
  //Test case number: 7
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      int[] intArray0 = new int[3];
      intArray0[0] = 1142;
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostSensitiveClassifier costSensitiveClassifier1 = new CostSensitiveClassifier();
      costSensitiveClassifier1.setSeed(2676);
      costSensitiveClassifier1.getOnDemandDirectory();
      naiveBayesMultinomialText0.m_norm = (-3059.3);
      File file0 = MockFile.createTempFile("ize", "ize");
      naiveBayesMultinomialText0.setStopwords(file0);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 8
  /*Coverage entropy=2.9005822944550714
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      String[] stringArray0 = wordTokenizer0.getOptions();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      snowballStemmer0.stem("");
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      Tokenizer.runTokenizer(wordTokenizer0, stringArray0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      naiveBayesMultinomialText0.setPeriodicPruning(14);
      naiveBayesMultinomialText0.getOptions();
      String string0 = "com";
      try { 
        MockURI.URI("?so$bBK4kU@*gj#", (String) null, "", "", "com");
        fail("Expecting exception: URISyntaxException");
      
      } catch(URISyntaxException e) {
         //
         // Illegal character in fragment at index 17: ?so$bBK4kU@*gj#:?#com
         //
         verifyException("java.net.URI$Parser", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.8613788200998678
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "LogitBoost: Base classifiers and their weights: \n";
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setTokenizer((Tokenizer) null);
      int int0 = 18;
      naiveBayesMultinomialText0.setPeriodicPruning(18);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.getOptions();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=2.015255863586861
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      int int0 = 14;
      naiveBayesMultinomialText0.setPeriodicPruning(14);
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=3.0428162336583116
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      int int0 = 14;
      naiveBayesMultinomialText0.setPeriodicPruning(14);
      naiveBayesMultinomialText0.getOptions();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("", arrayList0, 0);
      Instances instances1 = Instances.mergeInstances(instances0, instances0);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances1);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: No attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=0.9004024235381879
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance1, false);
      // Undeclared exception!
      try { 
        binarySparseInstance1.hasMissingValue();
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=3.485076661791088
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      NaiveBayesMultinomialText.main(stringArray0);
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      iteratedLovinsStemmer0.toString();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) iteratedLovinsStemmer0;
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = 257.0;
      doubleArray0[1] = 257.0;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 257.0;
      doubleArray0[4] = 257.0;
      int[] intArray0 = new int[9];
      intArray0[0] = 0;
      intArray0[1] = 1;
      intArray0[2] = 3701;
      intArray0[3] = (-4523);
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.find();
      Attribute attribute0 = new Attribute((String) null, vector0, 3701);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-2007.1597682), intArray0, 0);
      binarySparseInstance0.setMissing(attribute0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=2.419594359581629
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      String[] stringArray0 = new String[7];
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.toString();
      SparseInstance sparseInstance0 = new SparseInstance(59);
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getTokenizer();
      DenseInstance denseInstance0 = new DenseInstance(7);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(denseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      BayesNet bayesNet0 = new BayesNet();
      try { 
        bayesNet0.normalizeInstance(denseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.BayesNet", e);
      }
  }

  /**
  //Test case number: 15
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      naiveBayesMultinomialText0.setPeriodicPruning((-10));
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      naiveBayesMultinomialText0.pruneDictionary();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      AllFilter allFilter0 = new AllFilter();
      Capabilities capabilities0 = findWithCapabilities0.getCapabilities();
      findWithCapabilities0.setCapabilities(capabilities0);
      findWithCapabilities0.getOptions();
      int int0 = 2136;
      double[] doubleArray0 = new double[0];
      int[] intArray0 = new int[20];
      intArray0[0] = 2136;
      FileSystemHandling.shouldAllThrowIOExceptions();
      intArray0[1] = 2136;
      intArray0[2] = (-10);
      intArray0[3] = (-10);
      intArray0[4] = 2136;
      intArray0[5] = (-10);
      SparseInstance sparseInstance0 = new SparseInstance((-361.50429125), doubleArray0, intArray0, (-10));
      StringReader stringReader0 = new StringReader("weka/core/Capabilities.props");
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0);
      BufferedReader bufferedReader1 = new BufferedReader(bufferedReader0, 4);
      bufferedReader1.lines();
      Instances instances0 = null;
      try {
        instances0 = new Instances(bufferedReader1);
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // keyword @relation expected, read Token[weka/core/Capabilities.props], line 1
         //
         verifyException("weka.core.converters.ArffLoader$ArffReader", e);
      }
  }

  /**
  //Test case number: 16
  /*Coverage entropy=2.631353359565896
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_minWordP = (-2143.29958442);
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.setUseStopList(true);
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = (-2143.29958442);
      doubleArray0[1] = (-2143.29958442);
      doubleArray0[2] = (-2143.29958442);
      doubleArray0[3] = (-2143.29958442);
      doubleArray0[4] = (-2143.29958442);
      doubleArray0[5] = (-2143.29958442);
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertEquals((-2143.29958442), double0, 0.01);
  }

  /**
  //Test case number: 17
  /*Coverage entropy=2.221751559072405
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      String[] stringArray0 = new String[7];
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.toString();
      SparseInstance sparseInstance0 = new SparseInstance(59);
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities1 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities2 = new FindWithCapabilities();
      AllFilter allFilter0 = new AllFilter();
      Capabilities capabilities0 = allFilter0.getCapabilities();
      findWithCapabilities2.setCapabilities(capabilities0);
      findWithCapabilities2.getOptions();
      Vector<String> vector0 = findWithCapabilities1.find();
      Attribute attribute0 = new Attribute("specify", vector0, 0);
      sparseInstance0.setMissing(attribute0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.822061379926953
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[1];
      AlphabeticTokenizer.main(stringArray0);
      AlphabeticTokenizer.main(stringArray0);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.reset();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("c");
      SnowballStemmer snowballStemmer1 = new SnowballStemmer();
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      try { 
        MockURI.URI("weka.classifiers.rules.Rule", "ri\">kFHI6-6", "\tA file containing stopwords to override the default ones.\n\tUsing this option automatically sets the flag ('-stoplist') to use the\n\tstoplist if the file exists.\n\tFormat: one stopword per line, lines starting with '#'\n\tare interpreted as comments and ignored.", "$Revision: 9122 $", "org.tartarus.snowball");
        fail("Expecting exception: URISyntaxException");
      
      } catch(URISyntaxException e) {
         //
         // Relative path in absolute URI: weka.classifiers.rules.Rule://ri%22%3EkF%7FHI6-6%09A%20file%20containing%20stopwords%20to%20override%20the%20default%20ones.%0A%09Using%20this%20option%20automatically%20sets%20the%20flag%20('-stoplist')%20to%20use%20the%0A%09stoplist%20if%20the%20file%20exists.%0A%09Format:%20one%20stopword%20per%20line,%20lines%20starting%20with%20'%23'%0A%09are%20interpreted%20as%20comments%20and%20ignored.?$Revision:%209122%20$#org.tartarus.snowball
         //
         verifyException("java.net.URI", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=2.9813013333333287
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      String[] stringArray0 = new String[7];
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.toString();
      SparseInstance sparseInstance0 = new SparseInstance(59);
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities1 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities2 = new FindWithCapabilities();
      AllFilter allFilter0 = new AllFilter();
      Capabilities capabilities0 = allFilter0.getCapabilities();
      findWithCapabilities2.setCapabilities(capabilities0);
      findWithCapabilities2.getOptions();
      Vector<String> vector0 = findWithCapabilities1.find();
      Attribute attribute0 = new Attribute("specify", vector0, 0);
      sparseInstance0.setMissing(attribute0);
      naiveBayesMultinomialText0.setStopwords((File) null);
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.1290003949677563
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      int[] intArray0 = new int[3];
      intArray0[0] = 1142;
      intArray0[1] = 0;
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0, intArray0, 0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance0);
      BallNode ballNode0 = new BallNode(76);
      BallNode ballNode1 = ballNode0.m_Right;
      CoverTree coverTree0 = new CoverTree();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setStopwords(file0);
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 21
  /*Coverage entropy=3.078013150707321
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "LogitBoost: Base classifiers and their weights: \n";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.toString();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (-2);
      doubleArray0[1] = (double) (-2);
      doubleArray0[2] = (double) (-2);
      doubleArray0[3] = (double) (-2);
      doubleArray0[4] = (double) (-1);
      int[] intArray0 = new int[9];
      intArray0[0] = (-1);
      intArray0[1] = (-2);
      intArray0[2] = (-1);
      intArray0[3] = (-1);
      intArray0[4] = (-1);
      intArray0[5] = (-1);
      intArray0[6] = (-2);
      intArray0[7] = (-2);
      intArray0[8] = (-1);
      SparseInstance sparseInstance0 = new SparseInstance((-2), doubleArray0, intArray0, (-2));
      LinearNNSearch linearNNSearch0 = new LinearNNSearch(instances0);
      try { 
        linearNNSearch0.nearestNeighbour(sparseInstance0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -1
         //
         verifyException("weka.core.NormalizableDistance", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=0.8505612088663046
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      naiveBayesMultinomialText0.m_minWordP = (double) 893;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance1, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 23
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostSensitiveClassifier costSensitiveClassifier1 = new CostSensitiveClassifier();
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.getMatches();
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0);
      Vector<String> vector1 = findWithCapabilities0.find();
      Attribute attribute0 = new Attribute("Normalized Poly Kernel with lower order: K(x,y) = (<x,y>+1)^", vector1, (-1417));
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) sparseInstance0);
      binarySparseInstance0.setMissing(attribute0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.673415053526696
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      SystemInUtil.addInputLine("1I*wyhC");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_periodicP = 1151;
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      naiveBayesMultinomialText0.setMinWordFrequency(1.0E-5);
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.m_probOfClass = null;
      naiveBayesMultinomialText0.m_leplace = (-1690.432705336);
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.getCapabilities();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("weka/core/Capabilities.props");
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      naiveBayesMultinomialText0.normTipText();
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(1.0E-5, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, double0, 0.01);
  }

  /**
  //Test case number: 25
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getTokenizer();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      naiveBayesMultinomialText0.pruneDictionary();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      AllFilter allFilter0 = new AllFilter();
      Capabilities capabilities0 = allFilter0.getCapabilities();
      naiveBayesMultinomialText0.getRevision();
      findWithCapabilities0.setCapabilities(capabilities0);
      findWithCapabilities0.getOptions();
      int int0 = 0;
      double[] doubleArray0 = new double[0];
      int[] intArray0 = new int[6];
      intArray0[0] = 0;
      intArray0[1] = 0;
      intArray0[4] = 0;
      SparseInstance sparseInstance0 = new SparseInstance((-361.50429125), doubleArray0, intArray0, 0);
      StringReader stringReader0 = new StringReader("weka/core/Capabilities.props");
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0);
      BufferedReader bufferedReader1 = new BufferedReader(bufferedReader0, 4);
      Instances instances0 = null;
      try {
        instances0 = new Instances(bufferedReader1);
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // keyword @relation expected, read Token[weka/core/Capabilities.props], line 1
         //
         verifyException("weka.core.converters.ArffLoader$ArffReader", e);
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.m_normalize = false;
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 493.701115;
      doubleArray0[1] = 0.001;
      naiveBayesMultinomialText0.m_minWordP = 493.701115;
      doubleArray0[2] = (-2307.4981371);
      doubleArray0[3] = 2.0;
      doubleArray0[4] = (-3112.485122);
      naiveBayesMultinomialText0.setNorm((-1564.8840137008065));
      doubleArray0[5] = 190.91051893;
      doubleArray0[6] = 0.0;
      doubleArray0[7] = 0.0;
      doubleArray0[8] = 0.0;
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals((-1564.8840137008065), double0, 0.01);
  }

  /**
  //Test case number: 27
  /*Coverage entropy=2.9868916459747457
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setLNorm(0.0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      int int0 = 14;
      naiveBayesMultinomialText0.setPeriodicPruning(14);
      naiveBayesMultinomialText0.getOptions();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=1.9366147725931562
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      Tokenizer tokenizer0 = sGDText0.getTokenizer();
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      naiveBayesMultinomialText0.setNorm(0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      File file0 = naiveBayesMultinomialText1.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      assertEquals(0.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
  }

  /**
  //Test case number: 29
  /*Coverage entropy=2.2584261358947213
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      int[] intArray0 = new int[3];
      intArray0[0] = 1142;
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      intArray0[1] = 0;
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0, intArray0, 0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance0);
      BallNode ballNode0 = new BallNode(76);
      BallNode ballNode1 = ballNode0.m_Right;
      CoverTree coverTree0 = new CoverTree();
      ballNode0.m_Right = null;
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("\tNormalize document length (use in conjunction with -norm and -lnorm)");
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getTokenizer();
      DenseInstance denseInstance0 = new DenseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) binarySparseInstance1, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=3.0428162336583116
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      naiveBayesMultinomialText0.getOptions();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (-1.0);
      doubleArray0[1] = (-4401.1754697);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      doubleArray0[2] = (-1802.58875);
      doubleArray0[3] = (-1017.4140430782678);
      doubleArray0[4] = (-1017.4140430782678);
      doubleArray0[5] = 1195.93262;
      doubleArray0[6] = 0.0;
      doubleArray0[7] = 4307.2;
      doubleArray0[8] = 2036.99310809473;
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      FileSystemHandling.createFolder(evoSuiteFile0);
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.toString();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 31
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      naiveBayesMultinomialText0.setStopwords(file0);
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      String string1 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string1);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 32
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.toString();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) iteratedLovinsStemmer0;
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = 257.0;
      doubleArray0[1] = 257.0;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 257.0;
      doubleArray0[4] = 257.0;
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.find();
      Attribute attribute0 = new Attribute((String) null, vector0, 3701);
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(2.0, double0, 0.01);
      
      String string0 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string0);
      
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(boolean0);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 33
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      
      naiveBayesMultinomialText0.m_minWordP = (-2143.29958442);
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, (String[]) null);
      double double0 = naiveBayesMultinomialText0.m_leplace;
      String string0 = naiveBayesMultinomialText0.globalInfo();
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string0);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      naiveBayesMultinomialText0.m_minWordP = (double) 893;
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      try { 
        linearNNSearch0.getDistances();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No distances available. Please call either kNearestNeighbours or nearestNeighbours first.
         //
         verifyException("weka.core.neighboursearch.LinearNNSearch", e);
      }
  }

  /**
  //Test case number: 35
  /*Coverage entropy=3.1091774622598547
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.getUseStopList();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray0.length);
      
      naiveBayesMultinomialText0.getRevision();
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = 0.95;
      String string0 = naiveBayesMultinomialText0.getRevision();
      assertEquals("9122", string0);
      
      doubleArray0[1] = (-3813.215436);
      doubleArray0[2] = (-1198.78376304835);
      doubleArray0[3] = (-2731.075174288733);
      doubleArray0[4] = 269.8198447882172;
      doubleArray0[5] = 0.0;
      doubleArray0[6] = (-392.99);
      doubleArray0[7] = (-1843.094304544);
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      String string1 = naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string1);
      
      String string2 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string2);
      
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getCapabilities();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      String string3 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string3);
      
      String string4 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", string4);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 36
  /*Coverage entropy=2.9005822944550714
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setNorm(1597.973583242636);
      naiveBayesMultinomialText0.getLowercaseTokens();
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      double double0 = 0.1;
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = 0.1;
      doubleArray0[1] = 0.1;
      doubleArray0[2] = 0.1;
      doubleArray0[3] = 1597.973583242636;
      doubleArray0[4] = 0.1;
      doubleArray0[5] = (-419.06778);
      doubleArray0[6] = 0.1;
      doubleArray0[7] = 0.1;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.1, doubleArray0);
      try { 
        naiveBayesMultinomialText0.updateClassifier(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 37
  /*Coverage entropy=2.2584261358947213
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      Stemmer stemmer0 = sGDText0.getStemmer();
      naiveBayesMultinomialText0.setStemmer(stemmer0);
      naiveBayesMultinomialText0.setNorm(0);
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.setNorm(0);
      naiveBayesMultinomialText0.setLNorm(300.0);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "Not enough training instances (required: ";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }
}
