/*
 * This file was automatically generated by EvoSuite
 * Wed Dec 04 07:45:15 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.BufferedReader;
import java.io.File;
import java.io.StringReader;
import java.net.URISyntaxException;
import java.util.ArrayList;
import java.util.Locale;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.net.MockURI;
import org.evosuite.runtime.mock.java.util.MockRandom;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.bayes.BayesNet;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.misc.SerializedClassifier;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.Stopwords;
import weka.core.TestInstances;
import weka.core.neighboursearch.LinearNNSearch;
import weka.core.stemmers.IteratedLovinsStemmer;
import weka.core.stemmers.LovinsStemmer;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.estimators.DiscreteEstimator;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.841330733645315
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_stopwordsFile = null;
      MockFile mockFile0 = new MockFile("klg$!");
      mockFile0.setReadOnly();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.getOptions();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=2.9915400293925045
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) lovinsStemmer0;
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("Whether to convert all tokens to lowercase");
      MockRandom mockRandom0 = new MockRandom((-2));
      byte[] byteArray0 = new byte[6];
      LovinsStemmer.main(testInstances0.DEFAULT_WORDS);
      naiveBayesMultinomialText0.listOptions();
      byteArray0[0] = (byte)0;
      byteArray0[1] = (byte)0;
      byteArray0[2] = (byte)87;
      byteArray0[3] = (byte)94;
      byteArray0[4] = (byte)0;
      mockRandom0.nextBytes(byteArray0);
      instances0.resample(mockRandom0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.setLNorm((-2));
      naiveBayesMultinomialText0.getStemmer();
      int[] intArray0 = new int[8];
      intArray0[0] = (-1);
      intArray0[1] = (-2);
      intArray0[3] = (-2);
      testInstances0.clone();
      intArray0[4] = (-2);
      intArray0[5] = (int) (byte)94;
      intArray0[7] = (-2);
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.setNorm((byte)0);
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertEquals((-2.0), naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.41257681572198
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.toString();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      naiveBayesMultinomialText0.setLNorm(1.0);
      long long0 = 1646L;
      MockRandom mockRandom0 = new MockRandom(1646L);
      byte[] byteArray0 = new byte[0];
      mockRandom0.nextBytes(byteArray0);
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("weka.classifiers.bayes.NaiveBayesMultinomialText", arrayList0, (byte)94);
      Instances instances1 = instances0.resample(mockRandom0);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances1);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: No attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.listOptions();
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertEquals(3.0, double0, 0.01);
      
      naiveBayesMultinomialText0.setTokenizer((Tokenizer) null);
      MockFile mockFile0 = new MockFile("aa2//7mH*[");
      mockFile0.getAbsolutePath();
      mockFile0.getCanonicalPath();
      naiveBayesMultinomialText0.m_stopwordsFile = (File) mockFile0;
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertNull(tokenizer0);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.739424802905942
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[2];
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("Rb_-JP2%R_.L!/mBU");
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      stringArray0[0] = "Rb_-JP2%R_.L!/mBU";
      stringArray0[1] = "ignored";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.listOptions();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=1.7766234846545668
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      MockFile mockFile0 = new MockFile("z![OJRn6LU6Ei W<%s", "The stemming algorithm to use on the words.");
      MockFile mockFile1 = new MockFile(mockFile0, "z![OJRn6LU6Ei W<%s");
      naiveBayesMultinomialText0.setStopwords(mockFile1);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.pruneDictionary();
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 6
  /*Coverage entropy=2.297687147780183
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      TestInstances testInstances0 = new TestInstances();
      MockRandom mockRandom0 = new MockRandom((-2));
      byte[] byteArray0 = new byte[6];
      byteArray0[1] = (byte)0;
      byteArray0[2] = (byte)87;
      byteArray0[1] = (byte)94;
      byteArray0[4] = (byte)94;
      mockRandom0.nextBytes(byteArray0);
      naiveBayesMultinomialText0.setLNorm((-2));
      MockFile mockFile0 = new MockFile(" ");
      NullStemmer nullStemmer0 = new NullStemmer();
      mockFile0.mkdirs();
      int[] intArray0 = new int[8];
      intArray0[0] = (-1);
      intArray0[1] = (-2);
      intArray0[2] = (-1);
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.reset();
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals((-2.0), double0, 0.01);
  }

  /**
  //Test case number: 7
  /*Coverage entropy=2.41257681572198
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.toString();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      naiveBayesMultinomialText0.setLNorm(1.0);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.clone();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.setNorm(1.0);
      testInstances0.getRelationalClassFormat();
      boolean boolean0 = naiveBayesMultinomialText0.getUseStopList();
      assertEquals(1.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(boolean0);
  }

  /**
  //Test case number: 8
  /*Coverage entropy=3.031076397381428
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.m_periodicP = (-8);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      Stemmer stemmer0 = naiveBayesMultinomialText1.getStemmer();
      naiveBayesMultinomialText0.m_stemmer = stemmer0;
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText1.useStopListTipText();
      naiveBayesMultinomialText0.setLNorm(0.0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "Whether to convert all tokens to lowercase";
      stringArray0[1] = "If true, ignores all words that are on the stoplist.";
      stringArray0[2] = "Whether to convert all tokens to lowercase";
      stringArray0[3] = "If true, ignores all words that are on the stoplist.";
      stringArray0[4] = "Whether to convert all tokens to lowercase";
      naiveBayesMultinomialText1.setOptions(stringArray0);
      naiveBayesMultinomialText1.useStopListTipText();
      naiveBayesMultinomialText1.getNorm();
      naiveBayesMultinomialText1.setNormalizeDocLength(false);
      naiveBayesMultinomialText1.setNorm(3.0);
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals(0.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.9676652704776565
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.m_leplace = 431.5040622714765;
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "WucbUwP+$ltI^n '";
      stringArray0[1] = "org.tartarus.snowball.ext";
      stringArray0[2] = "WucbUwP+$ltI^n '";
      stringArray0[3] = "org.tartarus.snowball";
      stringArray0[4] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[5] = "If true then document length is normalized according to the settings for norm and lnorm";
      snowballStemmer0.setOptions(stringArray0);
      snowballStemmer0.getRevision();
      snowballStemmer0.setStemmer("WucbUwP+$ltI^n '");
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      NaiveBayesMultinomialText.main(stringArray0);
      snowballStemmer0.stemmerTipText();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.setNorm(3.0);
      naiveBayesMultinomialText0.getMinWordFrequency();
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(3.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  /**
  //Test case number: 10
  /*Coverage entropy=2.6709087878625355
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.stemmerTipText();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      naiveBayesMultinomialText0.setLNorm(1.0);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.clone();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.setNorm(1582.308);
      testInstances0.getRelationalClassFormat();
      testInstances0.getRelationalClassFormat();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.757637858307174
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[4];
      Stopwords stopwords0 = naiveBayesMultinomialText0.m_stopwords;
      naiveBayesMultinomialText0.m_stopwords = null;
      stringArray0[0] = " ";
      stringArray0[1] = "-lnorm";
      stringArray0[2] = "\tA file containing stopwords to override the default ones.\n\tUsing this option automatically sets the flag ('-stoplist') to use the\n\tstoplist if the file exists.\n\tFormat: one stopword per line, lines starting with '#'\n\tare interpreted as comments and ignored.";
      stringArray0[3] = "KDTree currently only works with EuclideanDistanceFunction.";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = (-576.96);
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getNorm();
      BinarySparseInstance binarySparseInstance0 = null;
      try {
        binarySparseInstance0 = new BinarySparseInstance(217.1434125, (double[]) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.BinarySparseInstance", e);
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=3.3191132217408597
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setLNorm(0.0);
      FileSystemHandling.createFolder(evoSuiteFile0);
      String[] stringArray1 = new String[4];
      stringArray1[0] = "Whether to convert all tokens to lowercase";
      StringReader stringReader0 = new StringReader("Douglas H. Fisher");
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0);
      stringArray1[1] = "Whether to convert all tokens to lowercase";
      stringArray1[2] = "Whether to convert all tokens to lowercase";
      stringArray1[3] = "Whether to convert all tokens to lowercase";
      naiveBayesMultinomialText0.setOptions(stringArray1);
      naiveBayesMultinomialText0.useStopListTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.getNorm();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText1.setNorm(1.0);
      naiveBayesMultinomialText0.stemmerTipText();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      naiveBayesMultinomialText1.LNormTipText();
      naiveBayesMultinomialText1.periodicPruningTipText();
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
  }

  /**
  //Test case number: 15
  /*Coverage entropy=3.4082430893282907
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setLNorm(0.0);
      FileSystemHandling.createFolder(evoSuiteFile0);
      String[] stringArray1 = new String[4];
      stringArray1[0] = "If true then document length is normalized according to the settings for norm and lnorm";
      SparseInstance sparseInstance0 = new SparseInstance(0);
      SparseInstance sparseInstance1 = new SparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance1);
      binarySparseInstance0.dataset();
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.clone();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((-2), intArray0, 1450);
      binarySparseInstance2.setMissing((-239));
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 16
  /*Coverage entropy=2.534059615514255
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      naiveBayesMultinomialText0.pruneDictionary();
      boolean boolean0 = true;
      naiveBayesMultinomialText0.setUseStopList(true);
      String[] stringArray0 = new String[8];
      stringArray0[0] = " ?";
      stringArray0[1] = " ?";
      stringArray0[2] = "";
      stringArray0[3] = " ?";
      stringArray0[4] = " ?";
      stringArray0[5] = " ?";
      stringArray0[6] = " ?";
      stringArray0[7] = " ?";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      // Undeclared exception!
      try { 
        MockFile.createTempFile(" ?", " ?");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Prefix string too short
         //
         verifyException("org.evosuite.runtime.vfs.VirtualFileSystem", e);
      }
  }

  /**
  //Test case number: 17
  /*Coverage entropy=2.419594359581629
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      int[] intArray0 = new int[7];
      intArray0[0] = 4;
      intArray0[1] = 19;
      intArray0[2] = 4;
      intArray0[3] = 12;
      intArray0[4] = 13;
      intArray0[5] = 19;
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.m_leplace = (double) 13;
      naiveBayesMultinomialText1.setNormalizeDocLength(false);
      naiveBayesMultinomialText1.setNorm((-3075.380474569));
      naiveBayesMultinomialText0.stemmerTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.setUseStopList(false);
      naiveBayesMultinomialText1.LNormTipText();
      assertEquals((-3075.380474569), naiveBayesMultinomialText1.getNorm(), 0.01);
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.41257681572198
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.getLowercaseTokens();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      instances0.setClassIndex((-2));
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      instances0.lastIndexOf(wordTokenizer0);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Class index is negative (not set)!
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, false, false);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances");
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      
      String string1 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", string1);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.5323204850794725
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "\tThe tokenizing algorihtm (classname plus parameters) to use.\n\t(default: ";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = 315.73362;
      doubleArray0[1] = 315.73362;
      doubleArray0[2] = 315.73362;
      doubleArray0[3] = 315.73362;
      doubleArray0[4] = 315.73362;
      doubleArray0[5] = 315.73362;
      doubleArray0[6] = 315.73362;
      SparseInstance sparseInstance0 = new SparseInstance(315.73362, doubleArray0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) sparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "FL0q";
      stringArray0[1] = "\tThe tokenizing algorihtm (classname plus parameters) to use.\n\t(default: ";
      stringArray0[2] = "FL0q";
      stringArray0[3] = "\tThe tokenizing algorihtm (classname plus parameters) to use.\n\t(default: ";
      stringArray0[4] = "FL0q";
      stringArray0[5] = "FL0q";
      stringArray0[6] = "FL0q";
      String[] stringArray1 = new String[8];
      stringArray1[0] = "FL0q";
      stringArray1[1] = "\tThe tokenizing algorihtm (classname plus parameters) to use.\n\t(default: ";
      stringArray1[2] = "FL0q";
      stringArray1[3] = "FL0q";
      stringArray1[4] = "FL0q";
      stringArray1[5] = "";
      stringArray1[6] = "FL0q";
      stringArray1[7] = "Invalid stemmer specification string";
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=3.2808765576791212
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      NullStemmer nullStemmer0 = (NullStemmer)naiveBayesMultinomialText0.m_stemmer;
      naiveBayesMultinomialText0.setStemmer(nullStemmer0);
      String[] stringArray0 = new String[6];
      stringArray0[0] = "WucbUwP+$ltI^n '";
      stringArray0[1] = "org.tartarus.snowball.ext";
      stringArray0[2] = "WucbUwP+$ltI^n '";
      stringArray0[3] = "org.tartarus.snowball";
      snowballStemmer0.getOptions();
      stringArray0[4] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[5] = "If true then document length is normalized according to the settings for norm and lnorm";
      snowballStemmer0.setOptions(stringArray0);
      snowballStemmer0.setStemmer("WucbUwP+$ltI^n '");
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      NaiveBayesMultinomialText.main(stringArray0);
      snowballStemmer0.stemmerTipText();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.stopwordsTipText();
      snowballStemmer0.setStemmer("TRm4f;{Xy`sBf");
      naiveBayesMultinomialText0.getLowercaseTokens();
      snowballStemmer0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.useStopListTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 23
  /*Coverage entropy=3.314898769050031
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setLNorm(0.0);
      FileSystemHandling.createFolder(evoSuiteFile0);
      String[] stringArray1 = new String[4];
      stringArray1[0] = "Whether to convert all tokens to lowercase";
      int int0 = 0;
      SparseInstance sparseInstance0 = new SparseInstance(0);
      SparseInstance sparseInstance1 = new SparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance1);
      binarySparseInstance0.dataset();
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.clone();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.setNorm(10);
      testInstances0.getRelationalClassFormat();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      try { 
        principalComponents0.transformedHeader();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Principal components hasn't been built yet
         //
         verifyException("weka.attributeSelection.PrincipalComponents", e);
      }
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.5500297769739535
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getRevision();
      Stopwords stopwords0 = naiveBayesMultinomialText0.m_stopwords;
      naiveBayesMultinomialText0.m_stopwords = null;
      naiveBayesMultinomialText0.setMinWordFrequency(2.0);
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.reset();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 25
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("klg$!");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "\tIgnored attributes: ");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_stopwordsFile = null;
      MockFile mockFile0 = new MockFile("klg$!");
      mockFile0.setReadOnly();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.m_stopwordsFile = (File) mockFile0;
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      mockFile0.toURL();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 26
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setMinWordFrequency(2286.0);
      assertEquals(2286.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.543056733112554
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.globalInfo();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      int[] intArray0 = new int[7];
      intArray0[0] = (-2975);
      intArray0[1] = (-515);
      intArray0[2] = (-226);
      intArray0[3] = (-670);
      intArray0[4] = (-1);
      intArray0[5] = (-892);
      intArray0[6] = (-2271);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.0, intArray0, 2264);
      try { 
        principalComponents0.convertInstance(binarySparseInstance0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // convertInstance: Principal components not built yet
         //
         verifyException("weka.attributeSelection.PrincipalComponents", e);
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      int[] intArray0 = new int[3];
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances");
      snowballStemmer0.listOptions();
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      String string0 = naiveBayesMultinomialText0.globalInfo();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      int[] intArray0 = new int[5];
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      MockFile mockFile0 = new MockFile(file0, "");
      mockFile0.toURL();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      BayesNet bayesNet0 = new BayesNet();
      double[] doubleArray0 = new double[4];
      doubleArray0[2] = 0.0;
      doubleArray0[3] = (double) 12;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(3357.477, doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_stopwordsFile = null;
      MockFile mockFile0 = new MockFile("klg$!");
      mockFile0.setReadOnly();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.m_stopwordsFile = (File) mockFile0;
      mockFile0.toURL();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      BayesNet bayesNet0 = new BayesNet();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 1000.0;
      doubleArray0[1] = 1000.0;
      doubleArray0[2] = (-1840.801901213167);
      doubleArray0[3] = 1000.0;
      doubleArray0[4] = 1000.0;
      doubleArray0[5] = 1000.0;
      doubleArray0[6] = 1000.0;
      doubleArray0[7] = 1000.0;
      doubleArray0[8] = 1000.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1000.0, doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      try { 
        bayesNet0.normalizeInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.BayesNet", e);
      }
  }

  /**
  //Test case number: 31
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning(370);
      DiscreteEstimator discreteEstimator0 = null;
      try {
        discreteEstimator0 = new DiscreteEstimator((-1209), false);
        fail("Expecting exception: NegativeArraySizeException");
      
      } catch(NegativeArraySizeException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.estimators.DiscreteEstimator", e);
      }
  }

  /**
  //Test case number: 32
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = 1.0;
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "RM^`8K|1TZ_bj ");
      doubleArray0[1] = 1.2;
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      String string0 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string0);
      
      String string1 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      
      String string2 = naiveBayesMultinomialText0.useStopListTipText();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", string2);
  }

  /**
  //Test case number: 33
  /*Coverage entropy=2.2584261358947213
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.toString();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      naiveBayesMultinomialText0.setLNorm(0.0);
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      testInstances1.clone();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.setNorm(0.0);
      Instances instances0 = testInstances0.getRelationalClassFormat();
      assertNull(instances0);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.toString();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      naiveBayesMultinomialText0.setLNorm(1.0);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.clone();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.setNorm(1582.308);
      Instances instances0 = testInstances0.getRelationalClassFormat();
      assertNull(instances0);
  }

  /**
  //Test case number: 35
  /*Coverage entropy=1.5280883009539779
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      MockFile mockFile0 = new MockFile("Relative absolute error            ", "six");
      boolean boolean0 = naiveBayesMultinomialText0.m_lowercaseTokens;
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.pruneDictionary();
      mockFile0.toURL();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      BayesNet bayesNet0 = new BayesNet();
      double[] doubleArray0 = new double[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1000.0, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance1);
      DenseInstance denseInstance0 = new DenseInstance(10);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.getData();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText1.tokenizeInstance(binarySparseInstance1, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      int[] intArray0 = new int[1];
      intArray0[0] = 13;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1654.91315055, intArray0, (-8));
      binarySparseInstance0.setMissing(3376);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 37
  /*Coverage entropy=2.5531257522061517
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.toString();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      naiveBayesMultinomialText0.setLNorm(0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      SnowballStemmer snowballStemmer1 = new SnowballStemmer("");
      Locale.getISOLanguages();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      SnowballStemmer snowballStemmer2 = new SnowballStemmer("\tConvert all tokens to lowercase before adding to the dictionary.");
      naiveBayesMultinomialText0.setStemmer(snowballStemmer2);
      snowballStemmer2.stemmerTipText();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.stopwordsTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      try { 
        MockURI.URI(":|Kat6mei", "org.tartarus.snowball", "org.tartarus.snowball", "wek.cla<sifiers.rules.RGleStats", "");
        fail("Expecting exception: URISyntaxException");
      
      } catch(URISyntaxException e) {
         //
         // Relative path in absolute URI: :|Kat6mei://org.tartarus.snowballorg.tartarus.snowball?wek.cla%3Csifiers.rules.RGleStats#
         //
         verifyException("java.net.URI", e);
      }
  }

  /**
  //Test case number: 38
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "\tThe tokenizing algorihtm (classname plus parameters) to use.\n\t(default: ";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 39
  /*Coverage entropy=2.8059494252188184
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.stemmerTipText();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "The stemming algorithm to use on the words.";
      stringArray0[1] = "The stemming algorithm to use on the words.";
      stringArray0[2] = "The stemming algorithm to use on the words.";
      stringArray0[3] = "The stemming algorithm to use on the words.";
      stringArray0[4] = "The stemming algorithm to use on the words.";
      stringArray0[5] = "The stemming algorithm to use on the words.";
      stringArray0[6] = "The stemming algorithm to use on the words.";
      naiveBayesMultinomialText1.setOptions(stringArray0);
      try { 
        naiveBayesMultinomialText1.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 40
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      int[] intArray0 = new int[6];
      intArray0[0] = 4;
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 4;
      doubleArray0[1] = (double) 4;
      doubleArray0[2] = (double) 4;
      doubleArray0[3] = (double) 4;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(4, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((Instance) binarySparseInstance1);
      try { 
        naiveBayesMultinomialText0.updateClassifier(binarySparseInstance2);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 41
  /*Coverage entropy=2.419594359581629
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.toString();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      naiveBayesMultinomialText0.setLNorm((-2174.810859));
      TestInstances testInstances0 = new TestInstances();
      testInstances0.clone();
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.setNorm(1.0);
      Instances instances0 = testInstances0.getRelationalClassFormat();
      assertNull(instances0);
  }

  /**
  //Test case number: 42
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      intArray0[0] = 1790;
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "weka.classifiers.trees.RandomTree");
      intArray0[1] = 0;
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, true);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      Stemmer stemmer0 = naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText1.setStemmer(stemmer0);
      naiveBayesMultinomialText1.getUseStopList();
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 43
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      naiveBayesMultinomialText0.setLNorm(1.0);
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = 1.0;
      doubleArray0[1] = 1.0;
      int[] intArray0 = new int[9];
      intArray0[2] = 5;
      intArray0[3] = 5;
      intArray0[4] = 19;
      intArray0[5] = 12;
      intArray0[6] = 13;
      intArray0[7] = 16;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(5.7, intArray0, 5);
      naiveBayesMultinomialText0.getLowercaseTokens();
      assertEquals(1.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 44
  /*Coverage entropy=3.4078460275851894
  */
  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      intArray0[0] = 1790;
      naiveBayesMultinomialText0.pruneDictionary();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setLNorm(1790);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      SparseInstance sparseInstance0 = new SparseInstance(9);
      sparseInstance0.toStringNoWeight((-1856));
      SparseInstance sparseInstance1 = new SparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1790);
      Attribute attribute0 = new Attribute("{0 ?,1 ?,2 ?,3 ?,4 ?,5 ?,6 ?,7 ?,8 ?}", 10);
      sparseInstance0.value(attribute0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      binarySparseInstance1.setValueSparse(10, 10);
      binarySparseInstance1.dataset();
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      TestInstances testInstances0 = new TestInstances();
      double[] doubleArray0 = new double[14];
      doubleArray0[0] = (double) 10;
      doubleArray0[1] = (double) 1790;
      doubleArray0[2] = (double) 10;
      doubleArray0[3] = (double) 2;
      doubleArray0[4] = (double) 10;
      doubleArray0[5] = (double) 9;
      DenseInstance denseInstance0 = new DenseInstance(0.5, doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 45
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test45()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertEquals(3.0, double0, 0.01);
      
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(boolean0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 46
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test46()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int int0 = naiveBayesMultinomialText0.getPeriodicPruning();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, int0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 47
  /*Coverage entropy=2.961542260479888
  */
  @Test(timeout = 4000)
  public void test47()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      
      naiveBayesMultinomialText0.pruneDictionary();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      stringArray0[4] = "";
      stringArray0[5] = "`@~,Y1D";
      stringArray0[6] = "";
      stringArray0[7] = "";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.useStopListTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.getNorm();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setNormalizeDocLength(true);
      assertTrue(naiveBayesMultinomialText1.getNormalizeDocLength());
      
      naiveBayesMultinomialText2.setNorm(1.0);
      naiveBayesMultinomialText2.stemmerTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText2.setStopwords((File) null);
      assertFalse(naiveBayesMultinomialText2.getNormalizeDocLength());
  }

  /**
  //Test case number: 48
  /*Coverage entropy=2.1341286000959614
  */
  @Test(timeout = 4000)
  public void test48()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "4bJO|-x";
      stringArray0[1] = "\tThe tokenizing algorihtm (classname plus parameters) to use.\n\t(default: ";
      stringArray0[2] = "FL0q";
      stringArray0[3] = "\tThe tokenizing algorihtm (classname plus parameters) to use.\n\t(default: ";
      stringArray0[4] = "4bJO|-x";
      stringArray0[5] = "4bJO|-x";
      stringArray0[6] = "FL0q";
      stringArray0[7] = "\tThe tokenizing algorihtm (classname plus parameters) to use.\n\t(default: ";
      serializedClassifier0.setOptions(stringArray0);
      NaiveBayesMultinomialText.main(stringArray0);
      SerializedClassifier serializedClassifier1 = new SerializedClassifier();
      serializedClassifier1.getModelFile();
      File file0 = MockFile.createTempFile("_7Q5)pD!\"*fC{,4FpR", "FL0q");
      MockFile mockFile0 = new MockFile(file0, "");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.reset();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 49
  /*Coverage entropy=1.847832822658352
  */
  @Test(timeout = 4000)
  public void test49()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      int[] intArray0 = new int[3];
      intArray0[0] = 14;
      intArray0[1] = 14;
      intArray0[2] = 14;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.0, intArray0, 1493);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 50
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test50()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances");
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = 579.2621231941104;
      doubleArray0[1] = 579.2621231941104;
      doubleArray0[2] = 579.2621231941104;
      doubleArray0[3] = 579.2621231941104;
      doubleArray0[4] = 579.2621231941104;
      doubleArray0[5] = 579.2621231941104;
      doubleArray0[6] = 579.2621231941104;
      DenseInstance denseInstance0 = new DenseInstance(579.2621231941104, doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }
}
