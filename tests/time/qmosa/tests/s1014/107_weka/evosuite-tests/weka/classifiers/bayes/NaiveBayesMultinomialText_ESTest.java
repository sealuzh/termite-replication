/*
 * This file was automatically generated by EvoSuite
 * Wed Dec 04 00:27:37 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.util.ArrayList;
import java.util.Properties;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.misc.InputMappedClassifier;
import weka.classifiers.misc.SerializedClassifier;
import weka.classifiers.trees.DecisionStump;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.ProtectedProperties;
import weka.core.SparseInstance;
import weka.core.Stopwords;
import weka.core.TestInstances;
import weka.core.neighboursearch.KDTree;
import weka.core.stemmers.LovinsStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.NGramTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.filters.unsupervised.attribute.ReplaceMissingValues;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.753349994178044
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning(10000);
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.setLNorm(10000);
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      naiveBayesMultinomialText0.tokenizerTipText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.getOptions();
      precomputedKernelMatrixKernel0.getCapabilities();
      precomputedKernelMatrixKernel0.toString();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.getStopwords();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      System.setCurrentTimeMillis(0L);
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getNorm();
      System.setCurrentTimeMillis(0L);
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.getNorm();
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      int[] intArray0 = new int[8];
      intArray0[0] = 10000;
      intArray0[1] = 10000;
      intArray0[2] = 10000;
      intArray0[3] = 10000;
      intArray0[4] = 10000;
      intArray0[5] = 10000;
      intArray0[6] = 10000;
      intArray0[7] = 10000;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(10000, intArray0, 10000);
      try { 
        inputMappedClassifier0.constructMappedInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.misc.InputMappedClassifier", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, true, false);
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getNorm();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "";
      stringArray0[1] = "mZ~D{h0]3(W";
      stringArray0[2] = "c\"DBRC>-q";
      stringArray0[3] = "\tHow often to prune the dictionary of low frequency words (default = 0, i.e. don't prune)";
      stringArray0[4] = "";
      stringArray0[5] = "-P";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No value given for -P option.
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.883954558163018
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[5];
      doubleArray0[1] = 517.0;
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 3.0;
      doubleArray0[4] = (-3210.502856277135);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      String[] stringArray0 = new String[0];
      naiveBayesMultinomialText0.setOptions(stringArray0);
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      boolean boolean0 = naiveBayesMultinomialText0.getLowercaseTokens();
      assertFalse(boolean0);
      
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(2.0, double0, 0.01);
      
      int[] intArray0 = new int[9];
      intArray0[0] = 2353;
      intArray0[1] = 963;
      intArray0[2] = 6;
      intArray0[3] = 1088;
      intArray0[4] = 8;
      intArray0[5] = (-4502);
      intArray0[6] = 4709;
      intArray0[7] = (-487);
      intArray0[8] = (-1034);
      SparseInstance sparseInstance0 = new SparseInstance(0.1, doubleArray0, intArray0, (-1034));
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      naiveBayesMultinomialText0.tokenizeInstance(sparseInstance1, false);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 3
  /*Coverage entropy=2.2584261358947213
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "W1nYT\"";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      stringArray0[1] = "once";
      naiveBayesMultinomialText0.m_wordsPerClass = null;
      stringArray0[2] = "-P";
      stringArray0[3] = "yIOh-p<|'~lv+";
      naiveBayesMultinomialText0.setMinWordFrequency(6.0);
      NaiveBayesMultinomialText.main(stringArray0);
      stringArray0[4] = ",C3*;g^xb";
      EvoSuiteFile evoSuiteFile0 = null;
      boolean boolean0 = false;
      boolean boolean1 = false;
      ReplaceMissingValues replaceMissingValues0 = new ReplaceMissingValues();
      Capabilities capabilities0 = replaceMissingValues0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Cannot handle relational attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=3.463156073375423
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[0];
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, true);
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      MockFile mockFile0 = new MockFile(file0, "");
      MockFile mockFile1 = new MockFile(mockFile0, "0");
      MockFile mockFile2 = new MockFile(mockFile1, "");
      mockFile1.delete();
      naiveBayesMultinomialText0.setStopwords(mockFile2);
      mockFile1.getCanonicalFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file1 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      MockFile mockFile3 = new MockFile(file1, "-lnorm <num>");
      mockFile2.delete();
      naiveBayesMultinomialText0.setStopwords((File) null);
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      lovinsStemmer0.getTechnicalInformation();
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.getNorm();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("", arrayList0, 30);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: No attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=2.3674724429174536
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      byte[] byteArray0 = new byte[9];
      byteArray0[0] = (byte)11;
      byteArray0[1] = (byte) (-69);
      byteArray0[2] = (byte) (-69);
      byteArray0[3] = (byte) (-69);
      byteArray0[4] = (byte) (-69);
      naiveBayesMultinomialText0.getLowercaseTokens();
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      File file0 = MockFile.createTempFile("O;5*JP^THC", "Izu");
      naiveBayesMultinomialText0.setStopwords(file0);
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file1 = serializedClassifier0.getModelFile();
      MockFile mockFile0 = new MockFile(file1, "ws}L)e05@gR");
      mockFile0.delete();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file2 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file2);
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.stemmerTipText();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 6
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-612.466), doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      byte[] byteArray0 = new byte[8];
      byteArray0[1] = (byte) (-44);
      byteArray0[2] = (byte)112;
      byteArray0[3] = (byte)3;
      byteArray0[4] = (byte)34;
      byteArray0[5] = (byte)6;
      byteArray0[6] = (byte) (-77);
      byteArray0[7] = (byte)100;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      DenseInstance denseInstance0 = new DenseInstance((byte)100, doubleArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 7
  /*Coverage entropy=2.372821413206516
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "weka/core/Capabilities.props";
      stringArray0[1] = "weka/core/Capabilities.props";
      stringArray0[5] = "weka/core/Capabilities.props";
      stringArray0[4] = "weka/core/Capabilities.props";
      stringArray0[5] = "weka/core/Capabilities.props";
      stringArray0[6] = "weka/core/Capabilities.props";
      stringArray0[7] = "weka/core/Capabilities.props";
      stringArray0[8] = "weka/core/Capabilities.props";
      NGramTokenizer.main(stringArray0);
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      MockFile mockFile0 = (MockFile)naiveBayesMultinomialText0.m_stopwordsFile;
      MockFile mockFile1 = new MockFile(mockFile0, "\tThe file to store the output in, instead of outputting it on stdout.\n\tGets ignored if the supplied path is a directory.\n\t(default: .)");
      mockFile1.delete();
      naiveBayesMultinomialText0.setStopwords(mockFile1);
      MockFile mockFile2 = new MockFile(mockFile0, "b<$;;~d:eIbxC");
      mockFile0.delete();
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      File file0 = naiveBayesMultinomialText0.getStopwords();
      assertEquals("\tThe file to store the output in, instead of outputting it on stdout.\n\tGets ignored if the supplied path is a directory.\n\t(default: .)", file0.getName());
      
      String string1 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string1);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 8
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0;
      doubleArray0[1] = 2527.1324;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 3.0;
      int[] intArray0 = new int[9];
      intArray0[0] = 109;
      intArray0[1] = (-1767);
      intArray0[2] = (-1767);
      intArray0[3] = (-1767);
      intArray0[4] = 86;
      intArray0[5] = (-1767);
      intArray0[6] = (-1767);
      intArray0[7] = 109;
      intArray0[8] = (-1767);
      SparseInstance sparseInstance0 = new SparseInstance(1.0, doubleArray0, intArray0, 109);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.132999251994992
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "\tMinimum word frequency. Words with less than this frequence are ignored.\n\tIf periodic pruning is turned on then this is also used to determine which\n\twords to remove from the dictionary (default = 3).";
      stringArray0[1] = "GuGQLu&4)x]UNZG=";
      stringArray0[2] = "-lnorm";
      stringArray0[3] = "Em]@kL;@{sS2";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte[] byteArray0 = new byte[6];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      byteArray0[0] = (byte) (-69);
      byteArray0[1] = (byte)32;
      byteArray0[2] = (byte)109;
      byteArray0[3] = (byte)34;
      byteArray0[4] = (byte) (-50);
      byteArray0[5] = (byte)57;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      double[] doubleArray0 = new double[0];
      DenseInstance denseInstance0 = new DenseInstance((-1613.724894501074), doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=0.9289738521096165
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-611.9602738208536), doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      byte[] byteArray0 = new byte[8];
      byteArray0[0] = (byte) (-50);
      byteArray0[1] = (byte) (-44);
      byteArray0[2] = (byte)112;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "";
      stringArray0[1] = "";
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText1.tokenizeInstance(binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1720.656, (int[]) null, 886);
      try { 
        naiveBayesMultinomialText0.updateClassifier(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=1.8203806314665187
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[5];
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.setUseStopList(true);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      DenseInstance denseInstance0 = new DenseInstance(5.7, doubleArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(denseInstance0);
      naiveBayesMultinomialText0.getLowercaseTokens();
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=2.41257681572198
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      byte[] byteArray0 = new byte[9];
      byteArray0[0] = (byte) (-40);
      byteArray0[1] = (byte)121;
      byteArray0[2] = (byte)107;
      byteArray0[3] = (byte)5;
      byteArray0[4] = (byte)71;
      byteArray0[5] = (byte) (-82);
      byteArray0[6] = (byte)109;
      byteArray0[7] = (byte) (-1);
      byteArray0[8] = (byte)9;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = 1.0;
      doubleArray0[1] = 1.0;
      doubleArray0[2] = (-612.466);
      doubleArray0[3] = (-612.466);
      doubleArray0[4] = 0.0;
      doubleArray0[5] = 0.0;
      doubleArray0[6] = 1.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-612.466), doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(1.0, double0, 0.01);
  }

  /**
  //Test case number: 15
  /*Coverage entropy=3.390690462546264
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      String[] stringArray0 = new String[7];
      stringArray0[0] = "lnorm";
      stringArray0[1] = "-Q weka.classifiers.bayes.net.search.SearchAlgorithm";
      stringArray0[2] = "mA0}lP";
      stringArray0[3] = "KX";
      stringArray0[4] = "4Rvh9";
      stringArray0[5] = "Xt!V=";
      stringArray0[6] = "sx";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.m_leplace = 1887.878004;
      String[] stringArray1 = new String[8];
      naiveBayesMultinomialText0.setUseStopList(true);
      stringArray1[0] = "The file containing the stopwords (if this is a directory then the default ones are used).";
      stringArray1[1] = "The file containing the stopwords (if this is a directory then the default ones are used).";
      stringArray1[2] = "The file containing the stopwords (if this is a directory then the default ones are used).";
      stringArray1[3] = "The file containing the stopwords (if this is a directory then the default ones are used).";
      stringArray1[4] = "The file containing the stopwords (if this is a directory then the default ones are used).";
      stringArray1[5] = "lnorm";
      stringArray1[6] = "The file containing the stopwords (if this is a directory then the default ones are used).";
      stringArray1[7] = "The file containing the stopwords (if this is a directory then the default ones are used).";
      NaiveBayesMultinomialText.main(stringArray1);
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setLNorm(2585.18);
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.setPeriodicPruning(10000);
      assertEquals(2585.18, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 16
  /*Coverage entropy=1.847832822658352
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0;
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 3.0;
      doubleArray0[4] = (-3210.502856277135);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "\"pbF3/wf|^z?v, ";
      stringArray0[1] = "`0/VgE`_D;+-H]Sn";
      stringArray0[2] = "";
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      MockFile mockFile0 = new MockFile((File) null, "");
      MockFile mockFile1 = new MockFile(mockFile0, "\"pbF3/wf|^z?v, ");
      MockFile mockFile2 = new MockFile(mockFile0, "The LNorm to use for document length normalization.");
      mockFile2.delete();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      File file0 = mockFile2.getCanonicalFile();
      MockFile mockFile3 = new MockFile(file0, "-lnorm");
      mockFile0.delete();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      naiveBayesMultinomialText0.LNormTipText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.toString();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 17
  /*Coverage entropy=1.5981863871455346
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0;
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 3.0;
      doubleArray0[4] = (-3210.502856277135);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.setPeriodicPruning(1915);
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "\"pbF3/wf|^z?v, ";
      DenseInstance denseInstance0 = new DenseInstance((-3210.502856277135), doubleArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(denseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 18
  /*Coverage entropy=1.6082873972465448
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      byte[] byteArray0 = new byte[9];
      byteArray0[0] = (byte)11;
      byteArray0[1] = (byte) (-69);
      byteArray0[2] = (byte) (-69);
      byteArray0[3] = (byte) (-69);
      byteArray0[4] = (byte) (-69);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = (double) (byte) (-69);
      doubleArray0[2] = (double) (byte) (-69);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.0, (int[]) null, (byte) (-69));
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=2.5719579500515657
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getMinWordFrequency();
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertFalse(boolean0);
      
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      MockFile mockFile0 = new MockFile((File) null, "\"pbF3/wf|^z?v, ");
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file0 = serializedClassifier0.getModelFile();
      MockFile mockFile1 = new MockFile(file0, "\"pbF3/wf|^z?v, ");
      mockFile1.delete();
      naiveBayesMultinomialText0.setStopwords(file0);
      mockFile0.getCanonicalFile();
      MockFile mockFile2 = new MockFile(mockFile0, "D>Mo<lb");
      mockFile1.delete();
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.toString();
      boolean boolean1 = naiveBayesMultinomialText0.getLowercaseTokens();
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(boolean1);
  }

  /**
  //Test case number: 20
  /*Coverage entropy=3.2955193301273638
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      MockFile mockFile0 = new MockFile("If true then document length is normalized according to the settings for norm and lnorm", "If true then document length is normalized according to the settings for norm and lnorm");
      mockFile0.toURI();
      mockFile0.setExecutable(false, false);
      mockFile0.getAbsoluteFile();
      mockFile0.setWritable(false, true);
      mockFile0.toPath();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.getCapabilities();
      Stopwords stopwords0 = new Stopwords();
      stopwords0.elements();
      naiveBayesMultinomialText0.m_stopwords = stopwords0;
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.m_lnorm = 1407.6620807621985;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.periodicPruningTipText();
      Stopwords.main(stringArray0);
      assertEquals(1407.6620807621985, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getStemmer();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", naiveBayesMultinomialText0.periodicPruningTipText());
  }

  /**
  //Test case number: 21
  /*Coverage entropy=3.1590695284682866
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_wordFrequencies = false;
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.m_leplace = 1.0E-5;
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      wordTokenizer0.getRevision();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.m_norm = 0.0;
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      wordTokenizer0.getOptions();
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, (String[]) null);
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      naiveBayesMultinomialText0.getCapabilities();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      naiveBayesMultinomialText0.m_lnorm = 1.0E-5;
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getPeriodicPruning();
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
  }

  /**
  //Test case number: 22
  /*Coverage entropy=2.042632211710285
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.m_lnorm = (-2936.160485);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.tokenizerTipText();
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (-2936.160485);
      doubleArray0[1] = (-2936.160485);
      doubleArray0[2] = (-2521.314672641);
      doubleArray0[3] = 6.283185307179586;
      doubleArray0[4] = (-2936.160485);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-2521.314672641), doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(0.0, doubleArray0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((Instance) binarySparseInstance2);
      binarySparseInstance3.setWeight(7);
      try { 
        naiveBayesMultinomialText0.classifyInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 23
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-611.9602738208536), doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      byte[] byteArray0 = new byte[8];
      byteArray0[0] = (byte)121;
      byteArray0[1] = (byte) (-44);
      byteArray0[2] = (byte)112;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "";
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) binarySparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 24
  /*Coverage entropy=3.2698986887396755
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setOptions(stringArray0);
      assertEquals(12, stringArray0.length);
      
      naiveBayesMultinomialText1.getStemmer();
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getUseStopList());
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText1.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText1.getLowercaseTokens());
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
  }

  /**
  //Test case number: 25
  /*Coverage entropy=3.0506636431758234
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      
      naiveBayesMultinomialText0.m_norm = 4.9E-324;
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.setDebug(true);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "weka/core/Capabilities.props");
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.toString();
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.normTipText();
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
  }

  /**
  //Test case number: 26
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.shouldAllThrowIOExceptions();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      serializedClassifier0.getModelFile();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.normTipText();
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 27
  /*Coverage entropy=3.170615129749024
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.getNorm();
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      Stemmer stemmer0 = naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.setStemmer(stemmer0);
      String[] stringArray0 = new String[7];
      stringArray0[0] = "";
      stringArray0[1] = "";
      naiveBayesMultinomialText0.m_stemmer = stemmer0;
      stringArray0[3] = "-date-class";
      naiveBayesMultinomialText0.m_minWordP = 1.0;
      naiveBayesMultinomialText0.getOptions();
      stringArray0[4] = "K7}vW#";
      stringArray0[5] = "tokenizer";
      stringArray0[6] = "r}P=#Y#}!,B.cdkrT";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getRevision();
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=2.41257681572198
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-611.9602738208536), doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      byte[] byteArray0 = new byte[8];
      byteArray0[0] = (byte) (-50);
      byteArray0[1] = (byte) (-44);
      byteArray0[2] = (byte)112;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      String string1 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string1);
      
      String string2 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string2);
      
      String string3 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string3);
      
      String string4 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", string4);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 29
  /*Coverage entropy=2.449191882584089
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      
      Properties properties0 = new Properties();
      ProtectedProperties protectedProperties0 = new ProtectedProperties(properties0);
      ProtectedProperties protectedProperties1 = new ProtectedProperties(properties0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string1 = naiveBayesMultinomialText1.globalInfo();
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string1);
      
      String string2 = naiveBayesMultinomialText1.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string2);
      
      String string3 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string3);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      String string4 = naiveBayesMultinomialText2.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string4);
      
      File file0 = naiveBayesMultinomialText1.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 30
  /*Coverage entropy=2.890159515691326
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      naiveBayesMultinomialText0.setLNorm(271.3);
      DecisionStump decisionStump0 = new DecisionStump();
      Capabilities capabilities0 = new Capabilities(decisionStump0);
      capabilities0.dependencies();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "";
      stringArray0[1] = "weka/core/Capabilities.props";
      stringArray0[2] = "weka/core/Capabilities.props";
      stringArray0[3] = "weka/core/Capabilities.props";
      stringArray0[4] = "weka/core/Capabilities.props";
      stringArray0[5] = "weka/core/Capabilities.props";
      stringArray0[6] = "weka/core/Capabilities.props";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getLNorm();
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(271.3, double0, 0.01);
  }

  /**
  //Test case number: 31
  /*Coverage entropy=1.9296217656001493
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0;
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 3.0;
      doubleArray0[4] = (-3210.502856277135);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "\"pbF3/wf|^z?v, ";
      stringArray0[1] = "`0/VgE`_D;+-H]Sn";
      stringArray0[2] = "";
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      MockFile mockFile0 = new MockFile((File) null, "");
      MockFile mockFile1 = new MockFile(mockFile0, "\"pbF3/wf|^z?v, ");
      MockFile mockFile2 = new MockFile(mockFile0, "The LNorm to use for document length normalization.");
      mockFile2.delete();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      File file0 = mockFile2.getCanonicalFile();
      file0.deleteOnExit();
      MockFile mockFile3 = new MockFile(file0, "-lnorm");
      naiveBayesMultinomialText0.setMinWordFrequency((-3210.502856277135));
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      assertEquals((-3210.502856277135), naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 32
  /*Coverage entropy=2.042632211710285
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 2140.3291447025854;
      doubleArray0[1] = (double) (byte)32;
      doubleArray0[2] = (double) (byte)109;
      doubleArray0[3] = (double) (byte)109;
      doubleArray0[4] = (double) (byte) (-50);
      DenseInstance denseInstance0 = new DenseInstance(2140.3291447025854, doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 33
  /*Coverage entropy=3.2539982750941
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setPeriodicPruning(1042);
      String[] stringArray1 = new String[7];
      stringArray0[11] = "0";
      stringArray1[3] = "0";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: ClassNotFoundException");
      
      } catch(ClassNotFoundException e) {
      }
  }

  /**
  //Test case number: 34
  /*Coverage entropy=2.5531257522061517
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.getRevision();
      assertEquals("9122", string0);
      
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte) (-69);
      byteArray0[1] = (byte) (-69);
      byteArray0[2] = (byte) (-69);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      byte[] byteArray1 = new byte[8];
      byteArray1[0] = (byte) (-69);
      byteArray1[1] = (byte) (-69);
      byteArray1[2] = (byte)32;
      byteArray1[3] = (byte)32;
      byteArray1[4] = (byte)32;
      byteArray1[5] = (byte)32;
      byteArray1[6] = (byte)32;
      String string1 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string1);
      
      String string2 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string2);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string3 = naiveBayesMultinomialText1.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string3);
      
      String string4 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string4);
      
      String string5 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string5);
      
      naiveBayesMultinomialText1.setUseWordFrequencies(false);
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText1.getPeriodicPruning());
  }

  /**
  //Test case number: 35
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte byte0 = (byte) (-69);
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte) (-69);
      naiveBayesMultinomialText0.reset();
      byteArray0[1] = (byte) (-69);
      byteArray0[2] = (byte) (-69);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      int int0 = 1417;
      BinarySparseInstance binarySparseInstance0 = null;
      try {
        binarySparseInstance0 = new BinarySparseInstance((byte) (-69));
        fail("Expecting exception: NegativeArraySizeException");
      
      } catch(NegativeArraySizeException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.BinarySparseInstance", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-612.466), doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      byte[] byteArray0 = new byte[8];
      byteArray0[0] = (byte) (-50);
      byteArray0[1] = (byte) (-44);
      byteArray0[2] = (byte) (-120);
      byteArray0[3] = (byte)3;
      byteArray0[4] = (byte)34;
      byteArray0[5] = (byte)6;
      byteArray0[6] = (byte) (-77);
      byteArray0[7] = (byte)100;
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 37
  /*Coverage entropy=1.5981863871455346
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte) (-69);
      byteArray0[1] = (byte) (-69);
      byteArray0[2] = (byte) (-69);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "FY2/|f&M^<tBZh)";
      stringArray0[1] = "FY2/|f&M^<tBZh)";
      stringArray0[2] = "-stopwords <file>";
      stringArray0[3] = "FY2/|f&M^<tBZh)";
      stringArray0[4] = "The learning rate.";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = (double) (byte) (-69);
      doubleArray0[1] = (double) (byte) (-69);
      doubleArray0[2] = (double) (byte) (-69);
      doubleArray0[3] = 0.0;
      doubleArray0[4] = (double) (byte)32;
      doubleArray0[5] = (double) (byte) (-69);
      DenseInstance denseInstance0 = new DenseInstance((byte)32, doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 38
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      sGDText0.getStopwords();
      boolean boolean0 = true;
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getStopwords();
      KDTree kDTree0 = new KDTree();
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      SparseInstance sparseInstance0 = new SparseInstance(2);
      try { 
        inputMappedClassifier0.getMappedClassIndex();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // [InputMappedClassifier] No model available!
         //
         verifyException("weka.classifiers.misc.InputMappedClassifier", e);
      }
  }

  /**
  //Test case number: 39
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      boolean boolean0 = false;
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 40
  /*Coverage entropy=2.890159515691326
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getCapabilities();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[8];
      naiveBayesMultinomialText0.m_norm = 271.3;
      naiveBayesMultinomialText0.setLNorm(271.3);
      stringArray0[0] = "weka/core/Capabilities.props";
      stringArray0[1] = "weka/core/Capabilities.props";
      stringArray0[2] = "weka/core/Capabilities.props";
      stringArray0[3] = "weka/core/Capabilities.props";
      stringArray0[4] = "weka/core/Capabilities.props";
      stringArray0[5] = "weka/core/Capabilities.props";
      stringArray0[6] = "weka/core/Capabilities.props";
      stringArray0[7] = "weka/core/Capabilities.props";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(271.3, double0, 0.01);
  }

  /**
  //Test case number: 41
  /*Coverage entropy=3.109021729705143
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      String[] stringArray1 = new String[7];
      stringArray1[0] = "q-lnorm <num>";
      stringArray1[1] = "0";
      stringArray1[3] = "0";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.setOptions(stringArray0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText2.getUseStopList());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(12, stringArray0.length);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText2.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 42
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm(3518.9909244);
      assertEquals(3518.9909244, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 43
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getTokenizer();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "rQ%";
      stringArray0[3] = "~EX&6*SEKU";
      stringArray0[4] = "JWqVeds2k'j;.d";
      stringArray0[5] = "";
      stringArray0[6] = "";
      stringArray0[7] = "A0dhaQiqg[(=EE";
      Tokenizer.tokenize((Tokenizer) wordTokenizer0, stringArray0);
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertEquals(3.0, double0, 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }
}
