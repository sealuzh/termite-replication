/*
 * This file was automatically generated by EvoSuite
 * Wed Dec 04 04:46:31 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.util.ArrayList;
import java.util.Properties;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.ProtectedProperties;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.AlphabeticTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=1.7646308653001805
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      int[] intArray0 = new int[9];
      intArray0[0] = (-1693);
      intArray0[1] = (-1693);
      intArray0[2] = (-1693);
      intArray0[3] = (-1693);
      intArray0[5] = (-1693);
      intArray0[7] = (-1693);
      intArray0[8] = (-1693);
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0, intArray0, (-1693));
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      double double0 = naiveBayesMultinomialText0.m_lnorm;
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setLNorm(0.0);
      naiveBayesMultinomialText1.pruneDictionary();
      naiveBayesMultinomialText1.getMinWordFrequency();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(sparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=3.092239687046295
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm((-223.3839792));
      naiveBayesMultinomialText0.setUseStopList(false);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.getOptions();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (double) (byte)12;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.0, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      double double0 = naiveBayesMultinomialText0.m_lnorm;
      naiveBayesMultinomialText0.setPeriodicPruning(6);
      naiveBayesMultinomialText0.setLNorm((-1494.0));
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance0);
      SparseInstance sparseInstance1 = new SparseInstance((SparseInstance) binarySparseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 2
  /*Coverage entropy=1.757637858307174
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "cNP]'JQo=52<";
      stringArray0[1] = "-lnorm";
      stringArray0[2] = "i#.fdo2BP rhhGz";
      stringArray0[3] = "";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "");
      doubleArray0[0] = 7.0;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 0.0;
      int[] intArray0 = new int[4];
      intArray0[0] = 3654;
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("", arrayList0, 3654);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: No attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=3.0428162336583116
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm(3.0);
      naiveBayesMultinomialText0.getOptions();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) (byte)12;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 3.0;
      doubleArray0[4] = 0.0;
      doubleArray0[5] = 0.0;
      doubleArray0[6] = (-1.0);
      doubleArray0[7] = 3.0;
      doubleArray0[8] = 0.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(195.6400021, doubleArray0);
      int[] intArray0 = new int[0];
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((byte)12, intArray0, (byte)12);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      double double0 = naiveBayesMultinomialText1.m_lnorm;
      naiveBayesMultinomialText1.setPeriodicPruning((-574));
      naiveBayesMultinomialText1.setLNorm(1.0);
      naiveBayesMultinomialText1.pruneDictionary();
      naiveBayesMultinomialText1.toString();
      assertEquals((-574), naiveBayesMultinomialText1.getPeriodicPruning());
  }

  /**
  //Test case number: 5
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (-753.2670048859558);
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 0.0;
      int[] intArray0 = new int[4];
      intArray0[0] = 3654;
      intArray0[1] = 1475;
      intArray0[2] = (-7);
      intArray0[3] = 1404;
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0, intArray0, (-7));
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=2.94218229742502
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useStopListTipText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      naiveBayesMultinomialText0.setNorm(0.0);
      naiveBayesMultinomialText0.reset();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.stemmerTipText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.setChecksTurnedOff(false);
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      naiveBayesMultinomialText0.getUseStopList();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.getCapabilities();
      naiveBayesMultinomialText1.setStopwords(file0);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", naiveBayesMultinomialText1.stopwordsTipText());
  }

  /**
  //Test case number: 7
  /*Coverage entropy=1.9012735713814104
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[4];
      intArray0[2] = 3654;
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = 23.77332640003224;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0, doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      SparseInstance sparseInstance1 = new SparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance1);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.generate();
      SparseInstance sparseInstance2 = new SparseInstance(1.0, doubleArray0, intArray0, 9);
      Properties properties0 = new Properties();
      ProtectedProperties protectedProperties0 = new ProtectedProperties(properties0);
      ProtectedProperties protectedProperties1 = new ProtectedProperties(protectedProperties0);
      Attribute attribute0 = new Attribute("@relation", protectedProperties1);
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      File file1 = MockFile.createTempFile("date", (String) null, file0);
      naiveBayesMultinomialText0.setStopwords(file1);
      binarySparseInstance0.setValue(attribute0, (-1646.24574849892));
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance2);
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance(sparseInstance0);
      SparseInstance sparseInstance3 = new SparseInstance((Instance) binarySparseInstance4);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance3);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=2.673415053526696
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.getData();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      Instance instance0 = null;
      try { 
        naiveBayesMultinomialText1.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, true, true);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 0.0;
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) sparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      int[] intArray0 = new int[4];
      intArray0[0] = 3654;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(866);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) 6;
      doubleArray0[1] = (double) 866;
      doubleArray0[2] = (double) 6;
      doubleArray0[3] = (double) 3654;
      doubleArray0[4] = (double) 6;
      doubleArray0[5] = (double) 6;
      doubleArray0[6] = (double) 3654;
      doubleArray0[7] = (double) 0;
      doubleArray0[8] = (double) 6;
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(3654, doubleArray0);
      String string0 = "(hqye9obf";
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "(hqye9obf");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.updateClassifier(binarySparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=2.900015079480596
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm((-223.3839792));
      naiveBayesMultinomialText0.setUseStopList(true);
      byte[] byteArray0 = null;
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      naiveBayesMultinomialText0.getOptions();
      double[] doubleArray0 = new double[15];
      doubleArray0[0] = (double) (byte)12;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-223.3839792), doubleArray0);
      // Undeclared exception!
      try { 
        binarySparseInstance0.isMissingSparse(5);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 5
         //
         verifyException("weka.core.BinarySparseInstance", e);
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=2.9737955386768893
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = 7.0;
      doubleArray0[1] = 0.0;
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "d_=7asv0[^Re<<j-";
      stringArray0[3] = ")";
      stringArray0[4] = "C+_\"05'\"BIyC]\"!";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      doubleArray0[2] = 0.0;
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getOptions();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 13
  /*Coverage entropy=0.9004024235381879
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      int[] intArray0 = new int[9];
      intArray0[0] = (-1693);
      intArray0[1] = (-1693);
      intArray0[2] = (-1693);
      intArray0[3] = (-1693);
      intArray0[5] = (-1693);
      intArray0[7] = (-1693);
      intArray0[8] = (-1693);
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0, intArray0, (-1693));
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, true, true);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, true, false);
      naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, false);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 14
  /*Coverage entropy=2.1341286000959614
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertFalse(boolean0);
      
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string1 = naiveBayesMultinomialText1.normTipText();
      assertEquals("The norm of the instances after normalization.", string1);
      
      DenseInstance denseInstance0 = new DenseInstance(1);
      String string2 = naiveBayesMultinomialText1.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string2);
      
      naiveBayesMultinomialText1.setStopwords((File) null);
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText1.getPeriodicPruning());
  }

  /**
  //Test case number: 15
  /*Coverage entropy=2.9005822944550714
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm((-223.3839792));
      naiveBayesMultinomialText0.setUseStopList(true);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      naiveBayesMultinomialText0.getOptions();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (double) (byte)12;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-223.3839792), doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((-223.3839792), doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      SparseInstance sparseInstance1 = new SparseInstance((SparseInstance) binarySparseInstance1);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance0);
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      binarySparseInstance2.toString(44);
      binarySparseInstance2.setDataset(instances0);
      SparseInstance sparseInstance2 = new SparseInstance((SparseInstance) binarySparseInstance1);
      naiveBayesMultinomialText0.toString();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      assertEquals((-223.3839792), double0, 0.01);
  }

  /**
  //Test case number: 16
  /*Coverage entropy=3.0257505895352663
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      String string1 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string1);
      
      naiveBayesMultinomialText0.getLowercaseTokens();
      String string2 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string2);
      
      String string3 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string3);
      
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel1.setChecksTurnedOff(true);
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.normalizeDocLengthTipText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      String[] stringArray0 = TestInstances.DEFAULT_WORDS;
      String[] stringArray1 = new String[3];
      stringArray1[0] = "Whether to convert all tokens to lowercase";
      stringArray1[1] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray1[2] = "If true then document length is normalized according to the settings for norm and lnorm";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText1, stringArray1);
      SGDText sGDText0 = new SGDText();
      sGDText0.setEpochs(3);
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertFalse(boolean0);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      String string4 = naiveBayesMultinomialText3.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string4);
      
      String string5 = naiveBayesMultinomialText0.normTipText();
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals("The norm of the instances after normalization.", string5);
      
      String string6 = naiveBayesMultinomialText2.minWordFrequencyTipText();
      assertEquals(3.0, naiveBayesMultinomialText2.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText2.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText2.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText2.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText2.getNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string6);
  }

  /**
  //Test case number: 17
  /*Coverage entropy=3.1091634731495086
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.getNormalizeDocLength();
      naiveBayesMultinomialText0.setDebug(true);
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 2.0;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 0.0;
      doubleArray0[4] = 0.0;
      doubleArray0[5] = 0.0;
      byte[] byteArray0 = new byte[4];
      byteArray0[0] = (byte)76;
      byteArray0[1] = (byte)2;
      byteArray0[2] = (byte)2;
      byteArray0[3] = (byte)2;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "3um29");
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.setOptions(stringArray0);
      assertEquals(12, stringArray0.length);
      assertFalse(naiveBayesMultinomialText2.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText2.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText2.getUseStopList());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText2.getLowercaseTokens());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 18
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      int[] intArray0 = new int[4];
      intArray0[0] = 3654;
      intArray0[2] = 0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      TestInstances testInstances0 = new TestInstances();
      SparseInstance sparseInstance1 = new SparseInstance(0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance1);
      SparseInstance sparseInstance2 = new SparseInstance((SparseInstance) binarySparseInstance2);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=2.6298718780844146
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "Xro&Mmh'Ew";
      stringArray0[1] = "C$h92TTRNu[%fs %C";
      naiveBayesMultinomialText0.setMinWordFrequency((-101.93378));
      stringArray0[2] = "YzZ)XL@6Qgl";
      stringArray0[3] = "";
      stringArray0[4] = "";
      stringArray0[5] = "pWm+Sf$rp";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertEquals((-101.93378), naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(boolean0);
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertEquals(1.0, double0, 0.01);
      
      double double1 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(2.0, double1, 0.01);
      
      naiveBayesMultinomialText0.m_t = 2.0;
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      String string1 = naiveBayesMultinomialText0.normTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("The norm of the instances after normalization.", string1);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[4];
      intArray0[2] = 3654;
      double[] doubleArray0 = new double[1];
      naiveBayesMultinomialText0.setLNorm((-2484.499936));
      SparseInstance sparseInstance0 = new SparseInstance(23.77332640003224, doubleArray0);
      SparseInstance sparseInstance1 = new SparseInstance(sparseInstance0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(sparseInstance1, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      byte[] byteArray0 = new byte[9];
      byteArray0[0] = (byte)2;
      byteArray0[1] = (byte)8;
      byteArray0[2] = (byte) (-109);
      byteArray0[3] = (byte)87;
      byteArray0[4] = (byte)87;
      byteArray0[5] = (byte)2;
      byteArray0[6] = (byte)87;
      byteArray0[7] = (byte) (-30);
      byteArray0[8] = (byte) (-109);
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.appendStringToFile(evoSuiteFile1, "");
      String string0 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string0);
      
      SGDText sGDText0 = new SGDText();
      Stemmer stemmer0 = sGDText0.getStemmer();
      naiveBayesMultinomialText0.setStemmer(stemmer0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 23
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "");
      doubleArray0[0] = 7.0;
      int[] intArray0 = new int[4];
      intArray0[0] = 3654;
      intArray0[1] = 1475;
      SparseInstance sparseInstance0 = new SparseInstance((-114.0), doubleArray0, intArray0, 1475);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "");
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      SGDText sGDText0 = new SGDText();
      sGDText0.getStemmer();
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.015255863586861
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm((-223.3839792));
      FileSystemHandling.shouldAllThrowIOExceptions();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (double) (byte)42;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.6968082102470501, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(6);
      double double0 = naiveBayesMultinomialText0.m_lnorm;
      naiveBayesMultinomialText0.setPeriodicPruning(6);
      naiveBayesMultinomialText0.setLNorm(6);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=2.6401461330725327
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useStopListTipText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.setChecksTurnedOff(true);
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.normTipText();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 26
  /*Coverage entropy=2.4267173502315558
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      byte[] byteArray1 = new byte[3];
      byteArray1[0] = (byte) (-110);
      byteArray1[1] = (byte)21;
      byteArray1[2] = (byte)0;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, ".d7xo0Ah");
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (double) (byte)21;
      DenseInstance denseInstance0 = new DenseInstance(0.3, doubleArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.setOptions((String[]) null);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 27
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useStopListTipText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(151);
      wordTokenizer0.setDelimiters("Whether to convert all tokens to lowercase");
      ArrayList<String> arrayList0 = new ArrayList<String>();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      TestInstances testInstances0 = new TestInstances();
      arrayList0.remove((Object) alphabeticTokenizer0);
      binarySparseInstance0.dataset();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=2.673415053526696
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useStopListTipText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      ArrayList<String> arrayList0 = new ArrayList<String>();
      arrayList0.remove((Object) naiveBayesMultinomialText0.m_tokenizer);
      Attribute attribute0 = new Attribute("If true, ignores all words that are on the stoplist.", arrayList0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.listOptions();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "Whether to convert all tokens to lowercase";
      stringArray0[1] = "string";
      stringArray0[2] = "The tokenizing algorithm to use on the strings.";
      stringArray0[5] = "@attribute";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_tokenizer = null;
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 30
  /*Coverage entropy=2.2584261358947213
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.m_lnorm = (-2405.00987670087);
      naiveBayesMultinomialText0.stopwordsTipText();
      SGDText sGDText0 = new SGDText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.normTipText();
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (double) 0;
      doubleArray0[1] = (double) 0;
      doubleArray0[2] = (-2405.00987670087);
      doubleArray0[3] = (double) 0;
      doubleArray0[4] = (double) 0;
      doubleArray0[5] = (-2405.00987670087);
      doubleArray0[6] = (double) 0;
  }

  /**
  //Test case number: 31
  /*Coverage entropy=3.0952395734013582
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      String string1 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string1);
      
      naiveBayesMultinomialText0.getLowercaseTokens();
      String string2 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string2);
      
      String string3 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string3);
      
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(151);
      MockFile mockFile0 = new MockFile("rj0h(ZE", "rj0h(ZE");
      mockFile0.setWritable(false);
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      naiveBayesMultinomialText0.reset();
      String string4 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string4);
      
      naiveBayesMultinomialText0.setOptions((String[]) null);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 32
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "pMLNQb3M}v9sRX=1U";
      stringArray0[1] = "_db";
      stringArray0[2] = "";
      stringArray0[3] = "";
      stringArray0[4] = "Specify range of attributes to act on. This is a comma separated list of attribute indices, with \"first\" and \"last\" valid values. Specify an inclusive range with \"-\". E.g: \"first-3,5,6-10,last\".";
      stringArray0[5] = "";
      stringArray0[6] = "  std. dev.";
      stringArray0[7] = "";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.m_useStopList = false;
      naiveBayesMultinomialText0.setPeriodicPruning(110);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals(110, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 33
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int int0 = naiveBayesMultinomialText0.getPeriodicPruning();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, int0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=3.0436506099620244
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray0.length);
      
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      String string1 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string2 = naiveBayesMultinomialText1.normTipText();
      assertEquals("The norm of the instances after normalization.", string2);
      
      String string3 = naiveBayesMultinomialText1.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string3);
      
      naiveBayesMultinomialText1.getTokenizer();
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText1.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 35
  /*Coverage entropy=2.881995637895619
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm((-223.3839792));
      naiveBayesMultinomialText0.setUseStopList(true);
      byte byte0 = (byte)12;
      naiveBayesMultinomialText0.getOptions();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (double) (byte)12;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-223.3839792), doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      double double0 = naiveBayesMultinomialText0.m_lnorm;
      naiveBayesMultinomialText0.setLNorm((-1494.0));
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance1, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "Group: ";
      stringArray0[1] = "toward";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      String string0 = naiveBayesMultinomialText0.getRevision();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals("9122", string0);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 37
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "p<YU;KM(hA/UBm{";
      stringArray0[4] = "";
      stringArray0[5] = "&HE}Xn/v_5R";
      stringArray0[6] = "";
      stringArray0[7] = "(";
      stringArray0[8] = "^5p$eJ-U/!SJ&";
      NaiveBayesMultinomialText.main(stringArray0);
      assertEquals(9, stringArray0.length);
  }

  /**
  //Test case number: 38
  /*Coverage entropy=2.214534764133424
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = 7.0;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 0.0;
      int[] intArray0 = new int[5];
      intArray0[0] = 3654;
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.setChecksTurnedOff(false);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel1.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      String string0 = naiveBayesMultinomialText0.globalInfo();
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string0);
      
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string1 = naiveBayesMultinomialText1.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      
      String string2 = naiveBayesMultinomialText1.normTipText();
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText1.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", string2);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 39
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_wordFrequencies = false;
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.m_useStopList = false;
      naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      naiveBayesMultinomialText0.m_lnorm = 0.0;
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.useStopListTipText();
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(0.0, double0, 0.01);
  }

  /**
  //Test case number: 40
  /*Coverage entropy=2.557702411245053
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = 2010.238215;
      doubleArray0[1] = 2010.238215;
      doubleArray0[2] = 2010.238215;
      doubleArray0[3] = 2010.238215;
      doubleArray0[4] = 2010.238215;
      doubleArray0[5] = 2010.238215;
      doubleArray0[6] = 2010.238215;
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.getData();
      SGDText sGDText0 = new SGDText();
      sGDText0.setEpochs(3333);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.normalizeDocLengthTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText3.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
  }

  /**
  //Test case number: 41
  /*Coverage entropy=2.534059615514255
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)87;
      byteArray0[1] = (byte)8;
      byteArray0[2] = (byte)8;
      byteArray0[3] = (byte) (-109);
      byteArray0[4] = (byte)103;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.appendStringToFile(evoSuiteFile1, "");
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      naiveBayesMultinomialText1.setOptions(stringArray0);
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText1.getUseStopList());
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText1.getLowercaseTokens());
      
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(2.0, double0, 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 42
  /*Coverage entropy=2.5323204850794725
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "");
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "");
      DenseInstance denseInstance0 = new DenseInstance((byte)2, (double[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "";
      stringArray0[1] = "";
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.setMinWordFrequency(643.9624081871);
      stringArray0[2] = "";
      stringArray0[3] = "Copy with class value set to \"third\": ";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      System.setCurrentTimeMillis(0L);
  }

  /**
  //Test case number: 43
  /*Coverage entropy=2.534059615514255
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm((-223.3839792));
      naiveBayesMultinomialText0.setUseStopList(true);
      String[] stringArray0 = new String[4];
      stringArray0[0] = "";
      stringArray0[1] = "C$h92TTRNu[%fs %C";
      stringArray0[2] = "C$h92TTRNu[%fs %C";
      stringArray0[3] = ")\"'Tp^d eFnUih?";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals((-223.3839792), naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 44
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = 7.0;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 0.0;
      int[] intArray0 = new int[4];
      intArray0[0] = 3654;
      boolean boolean0 = true;
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.getData();
      // Undeclared exception!
      try { 
        Instances.mergeInstances((Instances) null, (Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Instances", e);
      }
  }
}
