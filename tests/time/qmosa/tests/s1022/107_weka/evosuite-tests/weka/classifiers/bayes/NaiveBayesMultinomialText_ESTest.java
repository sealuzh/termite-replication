/*
 * This file was automatically generated by EvoSuite
 * Wed Dec 04 06:50:35 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.net.URISyntaxException;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.net.MockURI;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.attributeSelection.InfoGainAttributeEval;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.CostMatrix;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.bayes.net.BIFReader;
import weka.classifiers.functions.GaussianProcesses;
import weka.classifiers.functions.LinearRegression;
import weka.classifiers.functions.MultilayerPerceptron;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.SMO;
import weka.classifiers.functions.SimpleLogistic;
import weka.classifiers.functions.supportVector.Kernel;
import weka.classifiers.meta.AdaBoostM1;
import weka.classifiers.rules.ZeroR;
import weka.classifiers.trees.RandomTree;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.neighboursearch.CoverTree;
import weka.core.neighboursearch.KDTree;
import weka.core.stemmers.IteratedLovinsStemmer;
import weka.core.stemmers.LovinsStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.NGramTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=3.482054796187831
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      Capabilities capabilities0 = new Capabilities(naiveBayesMultinomialText0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      TestInstances testInstances2 = new TestInstances();
      testInstances1.listOptions();
      Instances instances0 = testInstances0.generate();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.buildClassifier(instances0);
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (double) 38;
      int[] intArray0 = new int[8];
      intArray0[0] = (-1);
      intArray0[1] = 38;
      intArray0[2] = (-2);
      intArray0[3] = (-2);
      intArray0[4] = 499;
      intArray0[5] = 38;
      intArray0[6] = Integer.MAX_VALUE;
      intArray0[7] = (-1);
      SparseInstance sparseInstance0 = new SparseInstance(38, doubleArray0, intArray0, (-1175));
      double[] doubleArray1 = naiveBayesMultinomialText1.distributionForInstance(sparseInstance0);
      assertArrayEquals(new double[] {0.5454545454545454, 0.4545454545454546}, doubleArray1, 0.01);
  }

  /**
  //Test case number: 1
  /*Coverage entropy=1.7156366916534471
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = sGDText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.listOptions();
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      int int0 = 38;
      int int1 = 1415;
      AdaBoostM1 adaBoostM1_0 = new AdaBoostM1();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      AbstractClassifier.makeCopies(sGDText0, 18);
      CostMatrix costMatrix0 = new CostMatrix(25);
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      try { 
        principalComponents0.transformedData(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Principal components hasn't been built yet
         //
         verifyException("weka.attributeSelection.PrincipalComponents", e);
      }
  }

  /**
  //Test case number: 2
  /*Coverage entropy=3.2808928011471843
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      TestInstances testInstances0 = new TestInstances();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.tokenizerTipText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.globalInfo();
      iteratedLovinsStemmer0.globalInfo();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      String[] stringArray1 = new String[0];
      naiveBayesMultinomialText0.setOptions(stringArray1);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.tokenizerTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getStopwords();
      assertEquals(0.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      SGDText sGDText0 = new SGDText();
      sGDText0.setLNorm(0.0);
      sGDText0.getStopwords();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.setStopwords((File) null);
      naiveBayesMultinomialText2.stemmerTipText();
      String string0 = naiveBayesMultinomialText2.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
  }

  /**
  //Test case number: 3
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getUseStopList();
      String[] stringArray0 = new String[14];
      stringArray0[0] = "P6[jkzr/ P9{T";
      stringArray0[1] = "";
      stringArray0[2] = "* <x-y,x-y>^2)";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[0];
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.m_periodicP = 1298;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.toString();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[5];
      intArray0[0] = (-1164);
      intArray0[1] = (-100);
      intArray0[2] = (-3152);
      intArray0[3] = (-3118);
      intArray0[4] = 260;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-30.94), intArray0, 1376);
      try { 
        naiveBayesMultinomialText0.updateClassifier(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=2.9813013333333287
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      SGDText sGDText0 = new SGDText();
      naiveBayesMultinomialText0.getOptions();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getStopwords();
      sGDText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.getMinWordFrequency();
      CoverTree coverTree0 = new CoverTree();
      DenseInstance denseInstance0 = null;
      try {
        denseInstance0 = new DenseInstance((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.DenseInstance", e);
      }
  }

  /**
  //Test case number: 7
  /*Coverage entropy=3.228046478522826
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 3634.0;
      naiveBayesMultinomialText0.toString();
      doubleArray0[2] = 385.009313239772;
      doubleArray0[3] = 0.0;
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.tokenizerTipText();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "NaiveBayesMultinomialText: No model built yet.\n";
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.tokenizerTipText();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      SGDText sGDText0 = new SGDText();
      sGDText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setPeriodicPruning((-1));
      assertEquals((-1), naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 8
  /*Coverage entropy=2.1341286000959614
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.listOptions();
      SGDText sGDText0 = new SGDText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      sGDText0.getStopwords();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setPeriodicPruning(1);
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      Capabilities capabilities0 = multilayerPerceptron0.getCapabilities();
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.RELATIONAL_CLASS;
      capabilities0.disableDependency(capabilities_Capability0);
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.normTipText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      naiveBayesMultinomialText0.m_stopwordsFile = file0;
      ZeroR zeroR0 = new ZeroR();
      Capabilities capabilities0 = zeroR0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.getRelationalClassFormat();
      naiveBayesMultinomialText0.pruneDictionary();
      int int0 = 2537;
      testInstances0.clone();
      Instances instances0 = testInstances0.generate("@data");
      long long0 = 0L;
      instances0.getRandomNumberGenerator(42L);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Cannot handle relational attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("NaiveBayesMultinomialText: No model built yet.\n");
      SnowballStemmer.listStemmers();
      snowballStemmer0.getOptions();
      DenseInstance denseInstance0 = new DenseInstance(508.8788192064, (double[]) null);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) denseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=3.413448417610051
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      SimpleLogistic simpleLogistic0 = new SimpleLogistic();
      Capabilities capabilities0 = simpleLogistic0.getCapabilities();
      TestInstances.forCapabilities(capabilities0);
      LinearRegression linearRegression0 = new LinearRegression();
      Capabilities capabilities1 = linearRegression0.getCapabilities();
      RandomTree randomTree0 = new RandomTree();
      Capabilities capabilities2 = randomTree0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities2);
      testInstances0.getRelationalClassFormat();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setPeriodicPruning(1473);
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.STRING_ATTRIBUTES;
      capabilities1.disableDependency(capabilities_Capability0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setPeriodicPruning((-2));
      Random.setNextRandom((-427));
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      assertEquals((-2), naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 12
  /*Coverage entropy=2.8877683153087337
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setMinWordFrequency(5566.4729228);
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setMinWordFrequency((-930.510985532739));
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.setMinWordFrequency(3.0);
      naiveBayesMultinomialText0.getTokenizer();
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 13
  /*Coverage entropy=3.46965394924235
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      Capabilities capabilities0 = new Capabilities(naiveBayesMultinomialText0);
      TestInstances testInstances2 = new TestInstances();
      testInstances0.listOptions();
      Instances instances0 = testInstances2.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      double double0 = (-0.5);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, " ");
      int[] intArray0 = new int[9];
      intArray0[0] = (-1);
      intArray0[1] = (-2);
      intArray0[2] = (-2);
      intArray0[3] = 38;
      intArray0[4] = (-1);
      intArray0[5] = (-2);
      intArray0[6] = (-2);
      intArray0[7] = (-1);
      intArray0[8] = (-3279);
      int int0 = (-1834);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=3.513704951247211
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 3634.0;
      naiveBayesMultinomialText0.toString();
      doubleArray0[2] = 385.009313239772;
      doubleArray0[3] = 0.0;
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "NaiveBayesMultinomialText: No model built yet.\n";
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.globalInfo();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.tokenizerTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.getStopwords();
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText1.stemmerTipText();
      naiveBayesMultinomialText0.LNormTipText();
      assertEquals(0.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 15
  /*Coverage entropy=2.678706058817701
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 3634.0;
      naiveBayesMultinomialText0.toString();
      doubleArray0[2] = 385.009313239772;
      doubleArray0[3] = 0.0;
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.tokenizerTipText();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "NaiveBayesMultinomialText: No model built yet.\n";
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setPeriodicPruning(2537);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setNormalizeDocLength(true);
      naiveBayesMultinomialText1.normTipText();
      naiveBayesMultinomialText1.pruneDictionary();
      naiveBayesMultinomialText0.setPeriodicPruning(2537);
      assertEquals(2537, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 16
  /*Coverage entropy=3.481739134392555
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[0];
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.tokenizerTipText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      IteratedLovinsStemmer iteratedLovinsStemmer1 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer1.globalInfo();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      String[] stringArray0 = new String[1];
      stringArray0[0] = "NaiveBayesMultinomialText: No model built yet.\n";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getOptions();
      int[] intArray0 = new int[3];
      intArray0[0] = 2504;
      intArray0[1] = 1;
      intArray0[2] = (-5958);
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0, intArray0, 0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText1.distributionForInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 17
  /*Coverage entropy=2.5323204850794725
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "w,@-(XU!mqAt_";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "?KC'";
      stringArray0[4] = "h\",;&B(j\"5Dr`4>>UrY";
      stringArray0[5] = "what";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, double0, 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 18
  /*Coverage entropy=3.0286739949790262
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getUseStopList();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "P6[jkzr/ P9{T";
      stringArray0[1] = "";
      stringArray0[2] = "* <x-y,x-y>^2)";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setMinWordFrequency((-1.0));
      naiveBayesMultinomialText0.setLNorm(668.4447);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.setLNorm((-1.0));
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals((-1.0), naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 19
  /*Coverage entropy=3.4405818014570047
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      InfoGainAttributeEval infoGainAttributeEval0 = new InfoGainAttributeEval();
      Capabilities capabilities0 = infoGainAttributeEval0.getCapabilities();
      capabilities0.getClassCapabilities();
      TestInstances.forCapabilities(capabilities0);
      LinearRegression linearRegression0 = new LinearRegression();
      LinearRegression linearRegression1 = new LinearRegression();
      Capabilities capabilities1 = linearRegression1.getCapabilities();
      TestInstances.forCapabilities(capabilities1);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.getRelationalClassFormat();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.STRING_ATTRIBUTES;
      SMO sMO0 = new SMO();
      Kernel kernel0 = sMO0.getKernel();
      Capabilities capabilities2 = kernel0.getCapabilities();
      capabilities2.disableDependency(capabilities_Capability0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      naiveBayesMultinomialText0.getStemmer();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.9109827590181396
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      sGDText0.getStopwords();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("TXuG[ASueBA?PSU lj");
      sGDText0.setStemmer(snowballStemmer0);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray0.length);
      
      naiveBayesMultinomialText0.getStopwords();
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      
      naiveBayesMultinomialText0.getStopwords();
      File file0 = sGDText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      String string1 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string1);
      
      boolean boolean0 = naiveBayesMultinomialText0.getNormalizeDocLength();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(boolean0);
  }

  /**
  //Test case number: 21
  /*Coverage entropy=2.419594359581629
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.getUseWordFrequencies();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-stopwords";
      stringArray0[1] = "dic";
      stringArray0[2] = "@*90P5QDky";
      WordTokenizer.main(stringArray0);
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.pruneDictionary();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setTokenizer((Tokenizer) null);
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      Stemmer stemmer0 = naiveBayesMultinomialText1.getStemmer();
      naiveBayesMultinomialText0.setStemmer(stemmer0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText1.pruneDictionary();
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 22
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_leplace = (-1.0);
      naiveBayesMultinomialText0.setUseStopList(true);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 23
  /*Coverage entropy=3.1105413215861804
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.m_leplace = (-2236.6340948);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumClasses((-3279));
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getOptions();
      int[] intArray0 = new int[6];
      intArray0[0] = (-2);
      intArray0[1] = (-2);
      intArray0[2] = (-2);
      intArray0[3] = (-1);
      intArray0[4] = 2732;
      intArray0[5] = 17;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(234.0280348997, intArray0, 10);
      // Undeclared exception!
      try { 
        binarySparseInstance0.relationalValue(1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.4164983843494308
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = (-2910.705567732504);
      naiveBayesMultinomialText0.m_periodicP = 31;
      naiveBayesMultinomialText0.setNorm((-1.0));
      naiveBayesMultinomialText0.setNorm(0.0);
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.reset();
      try { 
        MockURI.URI("The stemming algorithm to use on the words.", "If true, ignores all words that are on the stoplist.", "If true, ignores all words that are on the stoplist.", "If true, ignores all words that are on the stoplist.", "How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances");
        fail("Expecting exception: URISyntaxException");
      
      } catch(URISyntaxException e) {
         //
         // Relative path in absolute URI: The stemming algorithm to use on the words.://If%20true,%20ignores%20all%20words%20that%20are%20on%20the%20stoplist.If%20true,%20ignores%20all%20words%20that%20are%20on%20the%20stoplist.?If%20true,%20ignores%20all%20words%20that%20are%20on%20the%20stoplist.#How%20often%20(number%20of%20instances)%20to%20prune%20the%20dictionary%20of%20low%20frequency%20terms.%200%20means%20don't%20prune.%20Setting%20a%20positive%20integer%20n%20means%20prune%20after%20every%20n%20instances
         //
         verifyException("java.net.URI", e);
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=2.070976373972562
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[6];
      naiveBayesMultinomialText0.setMinWordFrequency(48);
      intArray0[0] = 48;
      intArray0[2] = 1271;
      naiveBayesMultinomialText1.useStopListTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.listOptions();
      assertEquals(48.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 26
  /*Coverage entropy=1.9296217656001493
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 3634.0;
      doubleArray0[2] = 385.009313239772;
      doubleArray0[3] = 0.0;
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      SGDText sGDText0 = new SGDText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "A/,0)IFaj!n";
      stringArray0[3] = "u/Jelji9";
      stringArray0[4] = "c";
      stringArray0[5] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[6] = "0$|";
      stringArray0[7] = "gu";
      stringArray0[8] = "{]vC\u0002L[K#7";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      sGDText0.getStopwords();
      MockFile mockFile0 = new MockFile("yQLfw|NT_2cD|>ctcT");
      mockFile0.mkdirs();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      String string0 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string0);
      
      String string1 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", string1);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.getNorm();
      BIFReader bIFReader0 = new BIFReader();
      bIFReader0.measureDivergence();
      bIFReader0.enumerateMeasures();
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      gaussianProcesses0.getCapabilities();
      SGDText sGDText0 = new SGDText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      File file0 = sGDText0.getStopwords();
      MockFile mockFile0 = new MockFile(file0, "+dvpY2y");
      mockFile0.mkdirs();
      naiveBayesMultinomialText0.setStopwords(file0);
      int[] intArray0 = new int[7];
      intArray0[0] = 1;
      intArray0[1] = (-3279);
      intArray0[2] = 2;
      intArray0[3] = (-3279);
      intArray0[4] = 0;
      intArray0[5] = 1;
      intArray0[6] = 1;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(6.7, intArray0, 1);
      // Undeclared exception!
      try { 
        binarySparseInstance0.relationalValue(2633);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=1.543056733112554
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.listOptions();
      SGDText sGDText0 = new SGDText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      Stemmer stemmer0 = sGDText0.getStemmer();
      naiveBayesMultinomialText1.setStemmer(stemmer0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      KDTree kDTree0 = new KDTree();
      int int0 = (-1301);
      SparseInstance sparseInstance0 = new SparseInstance(0);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      try { 
        kDTree0.nearestNeighbour(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.KDTree", e);
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.getNorm();
      BIFReader bIFReader0 = new BIFReader();
      bIFReader0.measureDivergence();
      bIFReader0.enumerateMeasures();
      bIFReader0.getOptions();
      bIFReader0.getCapabilities();
      Instances instances0 = bIFReader0.m_Instances;
      int int0 = 1817;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1817);
      DenseInstance denseInstance0 = new DenseInstance(binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(denseInstance0);
      // Undeclared exception!
      try { 
        binarySparseInstance1.relationalValue(6);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 3634.0;
      doubleArray0[2] = 385.009313239772;
      doubleArray0[3] = 0.0;
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      int[] intArray0 = new int[4];
      intArray0[0] = 1496;
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.UNARY_CLASS;
      capabilities0.disableDependency(capabilities_Capability0);
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setPeriodicPruning(1);
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 31
  /*Coverage entropy=2.675485446901437
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_normalize = false;
      File file0 = naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.m_stopwordsFile = file0;
      naiveBayesMultinomialText0.m_t = 0.0;
      naiveBayesMultinomialText0.m_lnorm = 0.0;
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      MockFile.createTempFile("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value");
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.setMinWordFrequency(1000.0);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getLowercaseTokens();
      assertEquals(1000.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 32
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "`:%,");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.m_wordFrequencies = false;
      FileSystemHandling.shouldAllThrowIOExceptions();
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      naiveBayesMultinomialText0.getUseWordFrequencies();
      String string1 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string1);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 33
  /*Coverage entropy=2.49649273994102
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 3634.0;
      naiveBayesMultinomialText0.toString();
      doubleArray0[2] = 385.009313239772;
      doubleArray0[3] = 0.0;
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.tokenizerTipText();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "NaiveBayesMultinomialText: No model built yet.\n";
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.globalInfo();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      int[] intArray0 = new int[3];
      intArray0[0] = 20;
      intArray0[1] = (-1800);
      intArray0[2] = 5;
      SparseInstance sparseInstance0 = new SparseInstance(1.0, doubleArray0, intArray0, (-2));
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 34
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "hE7g>cF";
      stringArray0[1] = "";
      stringArray0[2] = "\"5BLHo/D^j";
      stringArray0[3] = "";
      stringArray0[4] = "";
      stringArray0[5] = "z]2?p&r4VM8x\"_x";
      stringArray0[6] = "";
      stringArray0[7] = "";
      Tokenizer.runTokenizer(nGramTokenizer0, stringArray0);
      nGramTokenizer0.nextElement();
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      String string1 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string1);
      
      naiveBayesMultinomialText0.getLowercaseTokens();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 35
  /*Coverage entropy=3.0286739949790262
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getUseStopList();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "P6[jkzr/ P9{T";
      stringArray0[1] = "";
      stringArray0[2] = "P6[jkzr/ P9{T";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setMinWordFrequency((-1.0));
      naiveBayesMultinomialText0.setLNorm(668.4447);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.setLNorm((-1.0));
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.normTipText();
      assertEquals((-1.0), naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 36
  /*Coverage entropy=3.2224320758879763
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      TestInstances testInstances0 = new TestInstances();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getOptions();
      double[] doubleArray0 = new double[0];
      int[] intArray0 = new int[5];
      intArray0[0] = (-3279);
      intArray0[1] = (-3279);
      intArray0[2] = (-5958);
      intArray0[3] = (-1);
      intArray0[4] = (-5958);
      SparseInstance sparseInstance0 = new SparseInstance(3577.2230171, doubleArray0, intArray0, 2914);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 37
  /*Coverage entropy=2.070976373972562
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "j=]&\"(9|");
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "JXwh]U2QimA!}@fA|T4");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText.main((String[]) null);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 38
  /*Coverage entropy=3.062087453187681
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      naiveBayesMultinomialText0.m_normalize = false;
      doubleArray0[0] = (-1.0);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      MockFile mockFile0 = new MockFile("If true then document length is normalized according to the settings for norm and lnorm", "The file containing the stopwords (if this is a directory then the default ones are used).");
      mockFile0.toURI();
      SystemInUtil.addInputLine("The file containing the stopwords (if this is a directory then the default ones are used).");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      int int0 = (-3497);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      Random.setNextRandom((-3497));
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 39
  /*Coverage entropy=0.9004024235381879
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(6);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(sparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }
}
