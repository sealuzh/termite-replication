/*
 * This file was automatically generated by EvoSuite
 * Tue Dec 03 20:19:09 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;
import weka.attributeSelection.CfsSubsetEval;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.Classifier;
import weka.classifiers.CostMatrix;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.meta.FilteredClassifier;
import weka.classifiers.misc.InputMappedClassifier;
import weka.classifiers.misc.SerializedClassifier;
import weka.classifiers.trees.DecisionStump;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.FindWithCapabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.Stopwords;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.core.stemmers.IteratedLovinsStemmer;
import weka.core.stemmers.LovinsStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.AlphabeticTokenizer;
import weka.core.tokenizers.NGramTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.filters.unsupervised.attribute.ReplaceMissingValues;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=1.4682921994113465
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)68;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_periodicP = 30;
      naiveBayesMultinomialText0.getStopwords();
      ArrayList<Locale.LanguageRange> arrayList0 = new ArrayList<Locale.LanguageRange>();
      ArrayList<String> arrayList1 = new ArrayList<String>();
      arrayList1.add("!)WA_");
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.AUTOSELECT_FILTERING;
      Locale.filterTags((List<Locale.LanguageRange>) arrayList0, (Collection<String>) arrayList1, locale_FilteringMode0);
      Attribute attribute0 = new Attribute((String) null, arrayList1, 30);
      attribute0.copy("3zXEJzpd={ jWp");
      Stopwords stopwords0 = naiveBayesMultinomialText0.m_stopwords;
      naiveBayesMultinomialText0.m_stopwords = null;
      Attribute.typeToString(1);
      int[] intArray0 = new int[6];
      intArray0[0] = 3;
      intArray0[1] = 2;
      intArray0[2] = 0;
      intArray0[3] = 30;
      intArray0[4] = 10000;
      intArray0[5] = 30;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2, intArray0, 2);
      double[] doubleArray0 = naiveBayesMultinomialText0.m_probOfClass;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=2.6482234916146403
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setMinWordFrequency((-2.147483648E9));
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.toString();
      CostSensitiveClassifier costSensitiveClassifier1 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      File file1 = MockFile.createTempFile("PHYtFiWz*J4", "K+{tcM3o :+j{W", file0);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "M{~eN ]s3QMa");
      naiveBayesMultinomialText0.setStopwords(file1);
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.getStopwords();
      MockFile mockFile0 = new MockFile("rbJ", " ");
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-M";
      stringArray0[1] = " ";
      stringArray0[2] = "K+{tcM3o :+j{W";
      stringArray0[3] = "K+{tcM3o :+j{W";
      stringArray0[4] = "-M";
      stringArray0[5] = "PHYtFiWz*J4";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 2
  /*Coverage entropy=3.026522790307467
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_leplace = 0.0;
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.listOptions();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.getNorm();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      MockFile mockFile0 = new MockFile("The stemming algorithm to use on the words.");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, double0, 0.01);
  }

  /**
  //Test case number: 3
  /*Coverage entropy=2.4435896416877303
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      naiveBayesMultinomialText0.setPeriodicPruning((-1261));
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      doubleArray0[0] = (-1637.6812174319);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.setMinWordFrequency((-2.147483648E9));
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setStopwords((File) null);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.toString();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.8933644088171127
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getMinWordFrequency();
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (-285.92829987010697);
      doubleArray0[1] = 3.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-285.92829987010697), doubleArray0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[11];
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.toString();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=3.238271687713534
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "-nominal-class";
      stringArray0[2] = "SpQjp&N9wt[t0gk+";
      stringArray0[3] = "";
      stringArray0[4] = "OLmsB(J";
      stringArray0[5] = "-string";
      stringArray0[6] = "Q?`nt_nv{JQKXAG";
      stringArray0[7] = "$Revision: 9122 $";
      stringArray0[8] = "";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setNorm(733.1474234);
      naiveBayesMultinomialText0.tokenizerTipText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      String[] stringArray1 = new String[5];
      Capabilities capabilities1 = capabilities0.getClassCapabilities();
      stringArray1[0] = "weka/core/Capabilities.props";
      stringArray1[1] = "weka/core/Capabilities.props";
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      stringArray1[2] = "";
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      stringArray1[3] = "The tokenizing algorithm to use on the strings.";
      capabilities0.and(capabilities1);
      capabilities0.enableAllClasses();
      String[] stringArray2 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray2);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals(733.1474234, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 7
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "The independent probability of a class\n";
      stringArray0[1] = "";
      stringArray0[3] = "";
      stringArray0[4] = "-lowercase";
      stringArray0[5] = ")foMn-:";
      stringArray0[6] = "";
      stringArray0[7] = "nqF";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=2.8827437576468555
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer((String) null);
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      naiveBayesMultinomialText0.getCapabilities();
      IteratedLovinsStemmer iteratedLovinsStemmer1 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.toString();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getMinWordFrequency();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.stemmerTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText1.globalInfo();
      naiveBayesMultinomialText1.LNormTipText();
      naiveBayesMultinomialText1.stopwordsTipText();
      try { 
        naiveBayesMultinomialText1.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=1.3788419678046633
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.m_normalize = false;
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      naiveBayesMultinomialText0.m_stopwordsFile = file0;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      ArrayList<Locale.LanguageRange> arrayList0 = new ArrayList<Locale.LanguageRange>();
      ArrayList<String> arrayList1 = new ArrayList<String>();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      MockFile mockFile0 = new MockFile("a)l*hkslj>j@<l!Z");
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "themselves");
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(12, stringArray0.length);
      
      boolean boolean0 = naiveBayesMultinomialText0.getLowercaseTokens();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(boolean0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 11
  /*Coverage entropy=3.31256258775114
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      SparseInstance sparseInstance0 = new SparseInstance(1);
      ArrayList<Locale.LanguageRange> arrayList0 = new ArrayList<Locale.LanguageRange>();
      ArrayList<String> arrayList1 = new ArrayList<String>();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.REJECT_EXTENDED_RANGES;
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      MockFile mockFile0 = new MockFile("a)l*hkslj>j@<l!Z");
      mockFile0.getAbsoluteFile();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) arrayList0, (Collection<String>) arrayList1, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("If true then document length is normalized according to the settings for norm and lnorm", list0, 6);
      sparseInstance0.setMissing(119);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "real");
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(14, stringArray0.length);
      
      naiveBayesMultinomialText0.pruneDictionary();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 12
  /*Coverage entropy=2.3072109573039925
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      naiveBayesMultinomialText0.pruneDictionary();
      AbstractClassifier.makeCopy((Classifier) null);
      naiveBayesMultinomialText0.toString();
      CostSensitiveClassifier costSensitiveClassifier1 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      File file1 = MockFile.createTempFile("NaiveBayesMultinomialText: No model built yet.\n", "_X;f-a1)xyQ$> ", file0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setStopwords(file1);
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText1.getStopwords();
      MockFile mockFile0 = new MockFile("", "N1^tSZ");
      mockFile0.setLastModified(1);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "w9-y.-~O/5Qoed:0}P@");
      naiveBayesMultinomialText0.setStopwords(file1);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 13
  /*Coverage entropy=2.555632017870312
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.stemString("measureMinCoordsPerPoint");
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("");
      IteratedLovinsStemmer iteratedLovinsStemmer1 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer1);
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.setMinWordFrequency(3.0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2074);
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.globalInfo();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizerTipText();
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      Capabilities capabilities0 = filteredClassifier0.getCapabilities();
      Capabilities capabilities1 = capabilities0.getClassCapabilities();
      capabilities0.dependencies();
      CfsSubsetEval cfsSubsetEval0 = new CfsSubsetEval();
      Capabilities capabilities2 = cfsSubsetEval0.getCapabilities();
      capabilities2.disableAll();
      capabilities1.and(capabilities2);
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.getTokenizer();
      DenseInstance denseInstance0 = new DenseInstance(950);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) denseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 15
  /*Coverage entropy=3.1946531330062844
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      ArrayList<Locale.LanguageRange> arrayList0 = new ArrayList<Locale.LanguageRange>();
      ArrayList<String> arrayList1 = new ArrayList<String>();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "\tConvert all tokens to lowercase before adding to the dictionary.";
      stringArray0[1] = "-lowercase";
      stringArray0[2] = "\tConvert all tokens to lowercase before adding to the dictionary.";
      stringArray0[3] = "-lowercase";
      stringArray0[4] = ")foMn-:";
      stringArray0[5] = "lnorm";
      stringArray0[6] = "-lowercase";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getOptions();
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 16
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.globalInfo();
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string0);
      
      naiveBayesMultinomialText0.m_useStopList = false;
      byte[] byteArray0 = new byte[4];
      byteArray0[0] = (byte)1;
      byteArray0[1] = (byte)26;
      byteArray0[2] = (byte)111;
      byteArray0[3] = (byte)116;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      naiveBayesMultinomialText0.getUseStopList();
      String string1 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string1);
      
      String string2 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", string2);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 17
  /*Coverage entropy=2.9676652704776565
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_lnorm = 0.0;
      naiveBayesMultinomialText0.m_stopwords = null;
      naiveBayesMultinomialText0.setLNorm(1.0E10);
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      SnowballStemmer snowballStemmer0 = new SnowballStemmer((String) null);
      SnowballStemmer.listStemmers();
      naiveBayesMultinomialText0.m_normalize = false;
      snowballStemmer0.stemmerTipText();
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      naiveBayesMultinomialText0.setPeriodicPruning((-2396));
      naiveBayesMultinomialText0.getUseWordFrequencies();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 1.0E10;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = (double) (-2396);
      doubleArray0[3] = 1057.448;
      doubleArray0[4] = (-2492.2963175486);
      doubleArray0[5] = 1.0E10;
      doubleArray0[6] = 1.0E10;
      doubleArray0[7] = 1.0E10;
      doubleArray0[8] = (double) (-2396);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.setMinWordFrequency((-2396));
      naiveBayesMultinomialText0.globalInfo();
      NaiveBayesMultinomialText.main((String[]) null);
      naiveBayesMultinomialText0.setLNorm(2.147483647E9);
      assertEquals((-2396.0), naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.675485446901437
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[1] = "@p;14.%dW_c";
      stringArray0[2] = "";
      stringArray0[3] = "^,dj:DtSA";
      stringArray0[4] = ":kv/]Fd#B8}P";
      AlphabeticTokenizer.main(stringArray0);
      alphabeticTokenizer0.setOptions(stringArray0);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "8_+");
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setTokenizer(alphabeticTokenizer0);
      String string0 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string0);
      
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getPeriodicPruning();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertEquals(1.0, double0, 0.01);
      
      naiveBayesMultinomialText0.getMinWordFrequency();
      double double1 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertEquals(3.0, double1, 0.01);
      
      int int0 = naiveBayesMultinomialText0.getPeriodicPruning();
      assertEquals(0, int0);
      
      String string1 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string1);
      
      String string2 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string2);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 19
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)68;
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_periodicP = 30;
      File file0 = naiveBayesMultinomialText0.getStopwords();
      file0.setLastModified(30);
      boolean boolean0 = naiveBayesMultinomialText0.getNormalizeDocLength();
      assertFalse(boolean0);
      
      naiveBayesMultinomialText0.setStopwords(file0);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)8;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "=X.W?pc0e";
      stringArray0[1] = "L. Breiman and J.H. Friedman and R.A. Olshen and C.J. Stone";
      stringArray0[2] = "";
      stringArray0[3] = "";
      stringArray0[4] = " packages are missing:";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 21
  /*Coverage entropy=3.2090464751913745
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_t = (-3.0);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.normTipText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setPeriodicPruning(100);
      boolean boolean0 = true;
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      NaiveBayesMultinomialText.main(stringArray0);
      int[] intArray0 = new int[7];
      intArray0[0] = 100;
      intArray0[1] = 100;
      intArray0[2] = 100;
      intArray0[3] = 100;
      intArray0[4] = 0;
      intArray0[5] = 100;
      intArray0[6] = 100;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(100, intArray0, 162);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[11];
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      SparseInstance sparseInstance0 = new SparseInstance(1);
      ArrayList<Locale.LanguageRange> arrayList0 = new ArrayList<Locale.LanguageRange>();
      ArrayList<String> arrayList1 = new ArrayList<String>();
      ArrayList<Locale.LanguageRange> arrayList2 = new ArrayList<Locale.LanguageRange>();
      Locale.LanguageRange locale_LanguageRange0 = null;
      try {
        locale_LanguageRange0 = new Locale.LanguageRange("Use word frequencies rather than binary bag of words representation", (-2540.875));
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // weight=-2540.875
         //
         verifyException("java.util.Locale$LanguageRange", e);
      }
  }

  /**
  //Test case number: 23
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      ArrayList<Locale.LanguageRange> arrayList0 = new ArrayList<Locale.LanguageRange>();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizerTipText();
      int[] intArray0 = null;
      int int0 = 68;
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.0, (int[]) null, 68);
      try { 
        naiveBayesMultinomialText0.updateClassifier(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 24
  /*Coverage entropy=3.2458473814062927
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      naiveBayesMultinomialText0.pruneDictionary();
      AbstractClassifier.makeCopy((Classifier) null);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "1TAR|7]x0[J!";
      stringArray0[1] = "w9-y.-~O/5Qoed:0}P@";
      stringArray0[2] = "et";
      costSensitiveClassifier0.setOptions(stringArray0);
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray1.length);
      
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getTokenizer();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 25
  /*Coverage entropy=2.784066574475527
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int int0 = 0;
      Stopwords stopwords0 = new Stopwords();
      stopwords0.getRevision();
      stopwords0.toString();
      Stopwords.isStopword("8034");
      String[] stringArray0 = new String[0];
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.m_stopwords = stopwords0;
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.setLNorm(0);
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      naiveBayesMultinomialText0.useStopListTipText();
      double double0 = 2459.3972787852;
      naiveBayesMultinomialText0.setMinWordFrequency(2459.3972787852);
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      try { 
        CostMatrix.parseMatlab("8034");
        fail("Expecting exception: StringIndexOutOfBoundsException");
      
      } catch(StringIndexOutOfBoundsException e) {
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=2.45126227595883
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.setMinWordFrequency((-2.147483648E9));
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setPeriodicPruning(82);
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      File file1 = MockFile.createTempFile("_X;f-a1)xyQ$> ", "-M", file0);
      naiveBayesMultinomialText0.setStopwords(file1);
      naiveBayesMultinomialText0.listOptions();
      File file2 = naiveBayesMultinomialText0.getStopwords();
      MockFile mockFile0 = new MockFile((String) null, "Whether to convert all tokens to lowercase");
      mockFile0.setLastModified(30);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "");
      naiveBayesMultinomialText0.setStopwords(file2);
      assertEquals(82, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.5981863871455346
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.shouldAllThrowIOExceptions();
      int int0 = 0;
      SparseInstance sparseInstance0 = new SparseInstance(0);
      naiveBayesMultinomialText0.getRevision();
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=1.9366147725931562
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      ArrayList<Locale.LanguageRange> arrayList0 = new ArrayList<Locale.LanguageRange>();
      ArrayList<String> arrayList1 = new ArrayList<String>();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.setStopwords((File) null);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.listOptions();
      ReplaceMissingValues replaceMissingValues0 = new ReplaceMissingValues();
      ArrayList<Locale.LanguageRange> arrayList2 = new ArrayList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      findWithCapabilities0.find();
      LinkedList<String> linkedList0 = new LinkedList<String>();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.AUTOSELECT_FILTERING;
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) arrayList0, (Collection<String>) linkedList0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("lnorm", list0, 168);
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (double) 2;
      doubleArray0[1] = (double) 0;
      doubleArray0[2] = (double) 3;
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      SparseInstance sparseInstance1 = new SparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance1);
      binarySparseInstance0.setMissing(4);
      Attribute attribute1 = attribute0.copy("P");
      binarySparseInstance0.setValue(3, (double) 0);
      // Undeclared exception!
      try { 
        sparseInstance1.setValue(attribute1, "date");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Value not defined for given nominal attribute!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.5179872908529677
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      ArrayList<Locale.LanguageRange> arrayList0 = new ArrayList<Locale.LanguageRange>();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      MockFile mockFile0 = new MockFile("a)l*hkslj>j@<l!Z", "a)l*hkslj>j@<l!Z");
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      BallNode ballNode0 = new BallNode(89, 30, 2);
      int[] intArray0 = new int[6];
      intArray0[0] = (-2805);
      intArray0[1] = (-58);
      intArray0[2] = (-58);
      intArray0[3] = (-1);
      intArray0[4] = 89;
      intArray0[5] = (-1);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(89, intArray0, (-58));
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance1);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(sparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      
      String string1 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals("If true, ignores all words that are on the stoplist.", string1);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 31
  /*Coverage entropy=1.6675530205253588
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      iteratedLovinsStemmer0.getRevision();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("\t");
      IteratedLovinsStemmer iteratedLovinsStemmer1 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.getRevision();
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      int int0 = 2234;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2234);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 32
  /*Coverage entropy=3.195315165445874
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getStopwords();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "2MveSa";
      CostSensitiveClassifier costSensitiveClassifier1 = (CostSensitiveClassifier)AbstractClassifier.makeCopy(costSensitiveClassifier0);
      stringArray0[1] = "uFMM6&?$wio-oE;P{>`";
      costSensitiveClassifier0.setOptions(stringArray0);
      costSensitiveClassifier1.setOptions(stringArray0);
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray1.length);
      
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getStemmer();
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 33
  /*Coverage entropy=2.8897593556273002
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "-nominal-class";
      stringArray0[2] = "SpQjp&N9wt[t0gk+";
      stringArray0[3] = "";
      stringArray0[4] = "OLmsB(J";
      stringArray0[5] = "-string";
      stringArray0[6] = "Q?`nt_nv{JQKXAG";
      stringArray0[7] = "$Revision: 9122 $";
      stringArray0[8] = "";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setNorm(733.1474234);
      naiveBayesMultinomialText0.tokenizerTipText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      String[] stringArray1 = new String[5];
      Capabilities capabilities1 = capabilities0.getClassCapabilities();
      stringArray1[0] = "weka/core/Capabilities.props";
      stringArray1[1] = "weka/core/Capabilities.props";
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      stringArray1[2] = "";
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      stringArray1[3] = "The tokenizing algorithm to use on the strings.";
      capabilities0.and(capabilities1);
      capabilities0.enableAllClasses();
      stringArray1[4] = "weka/core/Capabilities.props";
      naiveBayesMultinomialText0.setOptions(stringArray1);
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.LNormTipText();
      assertEquals(733.1474234, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      ArrayList<String> arrayList0 = new ArrayList<String>();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      MockFile mockFile0 = new MockFile("a)l*hkslj>j@<l!Z", "a)l*hkslj>j@<l!Z");
      Instances instances0 = null;
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 35
  /*Coverage entropy=2.3643764676852554
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.LNormTipText();
      SparseInstance sparseInstance0 = new SparseInstance(1878);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setUseStopList(false);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      
      naiveBayesMultinomialText0.setMinWordFrequency(2.0);
      naiveBayesMultinomialText0.pruneDictionary();
      assertEquals(2.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 37
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)68;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.m_periodicP = (int) (byte)68;
      File file0 = naiveBayesMultinomialText0.getStopwords();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      file0.setLastModified(30);
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "%");
      naiveBayesMultinomialText0.setStopwords(file0);
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 38
  /*Coverage entropy=1.5981863871455346
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_minWordP = 0.0;
      naiveBayesMultinomialText0.getNorm();
      SparseInstance sparseInstance0 = new SparseInstance(0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 39
  /*Coverage entropy=2.4221006252457893
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("");
      IteratedLovinsStemmer iteratedLovinsStemmer1 = new IteratedLovinsStemmer();
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertFalse(boolean0);
      
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertEquals(3.0, double0, 0.01);
      
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      String string1 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string1);
      
      String string2 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", string2);
  }

  /**
  //Test case number: 40
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.m_useStopList = true;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 41
  /*Coverage entropy=3.1101658142767286
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      naiveBayesMultinomialText0.pruneDictionary();
      DecisionStump decisionStump0 = new DecisionStump();
      costSensitiveClassifier0.getOnDemandDirectory();
      naiveBayesMultinomialText0.setStopwords((File) null);
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.getOptions();
      boolean boolean0 = true;
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      Instances instances0 = naiveBayesMultinomialText0.m_data;
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.tokenizerTipText();
      naiveBayesMultinomialText1.getCapabilities();
      try { 
        Capabilities.forInstances((Instances) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 42
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 43
  /*Coverage entropy=3.270128309864819
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getStopwords();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getLNorm();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(1.0, double0, 0.01);
  }
}
