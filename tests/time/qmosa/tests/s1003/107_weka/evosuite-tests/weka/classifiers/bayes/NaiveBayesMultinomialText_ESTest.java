/*
 * This file was automatically generated by EvoSuite
 * Tue Dec 03 16:18:20 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.util.Collection;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import java.util.Vector;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayes;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.lazy.IBk;
import weka.classifiers.meta.CVParameterSelection;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.meta.Vote;
import weka.classifiers.misc.InputMappedClassifier;
import weka.classifiers.misc.SerializedClassifier;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.FindWithCapabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.neighboursearch.CoverTree;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.core.neighboursearch.balltrees.MiddleOutConstructor;
import weka.core.neighboursearch.balltrees.TopDownConstructor;
import weka.core.stemmers.IteratedLovinsStemmer;
import weka.core.stemmers.LovinsStemmer;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.NGramTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.928810575777853
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.setNorm((-1390.028998));
      naiveBayesMultinomialText0.setLNorm((-1390.028998));
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getOptions();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (-67.6800782085721);
      doubleArray0[1] = (-1390.028998);
      doubleArray0[2] = 0.0;
      MockFile mockFile0 = (MockFile)naiveBayesMultinomialText0.m_stopwordsFile;
      MockFile mockFile1 = new MockFile(mockFile0, "weka/core/Capabilities.props");
      naiveBayesMultinomialText0.setStopwords(mockFile1);
      naiveBayesMultinomialText0.getStopwords();
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      TestInstances testInstances2 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances2.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals((-1390.028998), naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 1
  /*Coverage entropy=2.4506905220884194
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "{Td<");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getStopwords();
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      Instances instances0 = testInstances1.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      String string0 = naiveBayesMultinomialText0.toString();
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("The independent probability of a class\n--------------------------------------\nclass1\t12.0\nclass2\t10.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\t\n", string0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 2
  /*Coverage entropy=3.3994708522321613
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      MockFile mockFile0 = new MockFile("e9|]2)Zp15Orx[");
      mockFile0.getCanonicalPath();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.getStopwords();
      double double0 = naiveBayesMultinomialText0.m_t;
      naiveBayesMultinomialText0.normTipText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(true);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.LNormTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setOptions(stringArray0);
      naiveBayesMultinomialText2.pruneDictionary();
      Instances instances0 = naiveBayesMultinomialText2.m_data;
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      Instances instances1 = null;
      try {
        instances1 = new Instances((Instances) null, 247, (-360));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "Sum (doubles): ");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_periodicP = 0;
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.stem("Sum (doubles): ");
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      Random.setNextRandom(5);
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.388493900367311
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setStopwords((File) null);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.getStopwords();
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      Instances instances0 = testInstances1.generate();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.buildClassifier(instances0);
      assertEquals(2.0, naiveBayesMultinomialText2.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText2.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText2.getNorm(), 0.01);
  }

  /**
  //Test case number: 5
  /*Coverage entropy=3.108064289718111
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.find();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.AUTOSELECT_FILTERING;
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("stoplist", list0, 1384);
      NGramTokenizer nGramTokenizer1 = new NGramTokenizer();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "string";
      nGramTokenizer0.setOptions(stringArray0);
      nGramTokenizer1.setOptions(stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.toString();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=3.070402789859024
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.find();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.AUTOSELECT_FILTERING;
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("stoplist");
      String[] stringArray0 = new String[4];
      stringArray0[0] = "relational";
      stringArray0[1] = "@attribute";
      stringArray0[2] = "-stemmer <spec>";
      stringArray0[3] = "@attribute";
      Tokenizer.tokenize((Tokenizer) nGramTokenizer0, stringArray0);
      NGramTokenizer nGramTokenizer1 = new NGramTokenizer();
      String[] stringArray1 = new String[1];
      stringArray1[0] = "string";
      nGramTokenizer0.setOptions(stringArray1);
      nGramTokenizer1.setOptions(stringArray1);
      NGramTokenizer.main(stringArray1);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setDebug(false);
      double double0 = naiveBayesMultinomialText0.m_leplace;
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(true);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) 1384;
      int[] intArray0 = new int[4];
      intArray0[0] = 4;
      intArray0[1] = 1384;
      intArray0[2] = (-2);
      intArray0[3] = 2;
      SparseInstance sparseInstance0 = new SparseInstance(3, doubleArray0, intArray0, (-2105));
      try { 
        inputMappedClassifier0.constructMappedInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.misc.InputMappedClassifier", e);
      }
  }

  /**
  //Test case number: 7
  /*Coverage entropy=3.3194945659439474
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "?";
      stringArray0[1] = "Q,3";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      MockFile mockFile0 = new MockFile("Q,3");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setMinWordFrequency(3.0);
      CoverTree coverTree0 = new CoverTree();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      nGramTokenizer0.setOptions(stringArray0);
      NGramTokenizer.main(stringArray0);
      naiveBayesMultinomialText0.m_norm = 0.0;
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setDebug(false);
      naiveBayesMultinomialText0.getLNorm();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.normTipText();
      double double0 = naiveBayesMultinomialText2.m_leplace;
      naiveBayesMultinomialText1.normTipText();
      naiveBayesMultinomialText2.getOptions();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText1.setLowercaseTokens(false);
      naiveBayesMultinomialText0.LNormTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      boolean boolean0 = naiveBayesMultinomialText0.getUseStopList();
      assertTrue(boolean0);
  }

  /**
  //Test case number: 8
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      TestInstances testInstances0 = new TestInstances();
      Vote vote0 = new Vote();
      Capabilities capabilities0 = vote0.getCapabilities();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances1.generate();
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Cannot handle relational attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = "";
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      boolean boolean0 = true;
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.listOptions();
      Instance instance0 = null;
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=1.5981863871455346
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      naiveBayesMultinomialText0.toString();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props/Capabilities.props");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "NaiveBayesMultinomialText: No model built yet.\n");
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 0;
      doubleArray0[1] = (double) 0;
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.getMatches();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.MAP_EXTENDED_RANGES;
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("NaiveBayesMultinomialText: No model built yet.\n", vector0, (-471));
      SparseInstance sparseInstance0 = new SparseInstance(2, doubleArray0, intArray0, 1187);
      SparseInstance sparseInstance1 = new SparseInstance(3, doubleArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance1);
      binarySparseInstance0.setValue(attribute0, (double) 0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=2.209406559005219
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "Sum (doubles): ");
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      MockFile mockFile0 = new MockFile("Sum (doubles): ", "Sum (doubles): ");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getStopwords();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "The tokenizing algorithm to use on the strings.";
      stringArray0[1] = "Sum (doubles): ";
      stringArray0[2] = "The tokenizing algorithm to use on the strings.";
      stringArray0[3] = "The tokenizing algorithm to use on the strings.";
      stringArray0[4] = "The tokenizing algorithm to use on the strings.";
      stringArray0[5] = "Sum (doubles): ";
      stringArray0[6] = "The tokenizing algorithm to use on the strings.";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=3.0423434204195416
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      double[] doubleArray0 = new double[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.05, doubleArray0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.getMatches();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.MAP_EXTENDED_RANGES;
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("", vector0, 6);
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "relational";
      stringArray0[1] = "real";
      stringArray0[2] = "date";
      stringArray0[3] = "string";
      nGramTokenizer0.setOptions(stringArray0);
      String[] stringArray1 = new String[3];
      stringArray1[0] = "";
      stringArray1[1] = "real";
      stringArray1[2] = "@end";
      NGramTokenizer.main(stringArray1);
      naiveBayesMultinomialText0.setDebug(false);
      double double0 = naiveBayesMultinomialText0.m_leplace;
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.LNormTipText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) binarySparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SparseInstance sparseInstance0 = new SparseInstance(247);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance1);
      sparseInstance1.mergeInstance(binarySparseInstance0);
      DenseInstance denseInstance0 = new DenseInstance(sparseInstance1);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance1);
      String[] stringArray0 = new String[9];
      stringArray0[0] = "i.gU.O$B";
      stringArray0[1] = "    for (i = 0; i < data.numInstances(); i++)\n";
      stringArray0[2] = "";
      stringArray0[3] = "X`&v/";
      stringArray0[4] = "";
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)3;
      byteArray0[1] = (byte)113;
      byteArray0[2] = (byte)3;
      byteArray0[3] = (byte)97;
      byteArray0[4] = (byte)12;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      stringArray0[5] = "";
      stringArray0[6] = "g+aw";
      Random.setNextRandom((-3560));
      String string0 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 14
  /*Coverage entropy=3.0469997088933587
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.find();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.AUTOSELECT_FILTERING;
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("lr+VF62pBG!$W)w", list0, 1384);
      NGramTokenizer nGramTokenizer1 = new NGramTokenizer();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "string";
      nGramTokenizer0.setOptions(stringArray0);
      nGramTokenizer1.setOptions(stringArray0);
      NGramTokenizer.main(stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setDebug(true);
      double double0 = naiveBayesMultinomialText0.m_leplace;
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 15
  /*Coverage entropy=2.042632211710285
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      double[] doubleArray0 = new double[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.05, doubleArray0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      findWithCapabilities0.getMatches();
      double[] doubleArray1 = new double[2];
      doubleArray1[0] = (double) (-1902);
      doubleArray1[1] = (double) (-659);
      naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, false);
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      IteratedLovinsStemmer iteratedLovinsStemmer1 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer1);
      naiveBayesMultinomialText0.listOptions();
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertEquals(3.0, double0, 0.01);
      
      naiveBayesMultinomialText0.getStemmer();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 16
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "";
      stringArray0[1] = "";
      nGramTokenizer0.getOptions();
      stringArray0[2] = "\tConvert all tokens to lowercase before adding to the dictionary.";
      stringArray0[3] = "vgGwd^ slGR";
      stringArray0[4] = "";
      NGramTokenizer.main(stringArray0);
      stringArray0[5] = "";
      stringArray0[6] = "~XRTxq:RBmhgq2";
      nGramTokenizer0.setOptions(stringArray0);
      String[] stringArray1 = new String[2];
      stringArray0[6] = "5A'!t_sI-Ba6zn";
      nGramTokenizer0.tokenize("5A'!t_sI-Ba6zn");
      stringArray1[1] = "ehood";
      NGramTokenizer.main(stringArray1);
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) nGramTokenizer0;
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.setNorm((-1375.0259556975));
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      int int0 = naiveBayesMultinomialText0.getPeriodicPruning();
      assertEquals((-1375.0259556975), naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, int0);
  }

  /**
  //Test case number: 17
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      Locale.getISOLanguages();
      System.setCurrentTimeMillis(0L);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (double) 0L;
      doubleArray0[1] = (double) 0L;
      doubleArray0[2] = (double) 0L;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.2900365808953708, doubleArray0);
      try { 
        naiveBayesMultinomialText0.updateClassifier(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.1341286000959614
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "Sum (doubles): ");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getStopwords();
      String[] stringArray0 = new String[8];
      stringArray0[1] = "Sum (doubles): ";
      stringArray0[5] = "Sum (doubles): ";
      NaiveBayes naiveBayes0 = new NaiveBayes();
      Instances instances0 = naiveBayes0.m_Instances;
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      
      intArray0[0] = 1;
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 1;
      doubleArray0[1] = (double) 1;
      doubleArray0[2] = (double) 1;
      doubleArray0[3] = (double) 1;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, doubleArray0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities1 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities1.getMatches();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.MAP_EXTENDED_RANGES;
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("NaiveBayesMultinomialText: No model built yet.\n", vector0, 1);
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "real";
      stringArray0[1] = "NaiveBayesMultinomialText: No model built yet.\n";
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(1.0, doubleArray0);
      LinkedList<Locale.LanguageRange> linkedList1 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities2 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities3 = new FindWithCapabilities();
      findWithCapabilities2.getMatches();
      Locale.getISOLanguages();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, double0, 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 20
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      
      intArray0[0] = 1;
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 1;
      doubleArray0[1] = (double) 1;
      doubleArray0[2] = (double) 1;
      doubleArray0[3] = (double) 1;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, doubleArray0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities1 = new FindWithCapabilities();
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.BINARY_ATTRIBUTES;
      findWithCapabilities1.enableNot(capabilities_Capability0);
      findWithCapabilities1.getMatches();
      Locale.getISOLanguages();
      naiveBayesMultinomialText0.listOptions();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.9366147725931562
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "Sum (doubles): ");
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.m_leplace = 0.0;
      File file0 = naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      
      boolean boolean0 = naiveBayesMultinomialText0.getUseStopList();
      assertFalse(boolean0);
      
      naiveBayesMultinomialText0.getStopwords();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 22
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      naiveBayesMultinomialText0.toString();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props/Capabilities.props");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "NaiveBayesMultinomialText: No model built yet.\n");
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 0;
      doubleArray0[1] = (double) 0;
      doubleArray0[2] = (double) 1;
      doubleArray0[3] = (double) 0;
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      SystemInUtil.addInputLine("");
      Vector<String> vector0 = findWithCapabilities0.getMatches();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.MAP_EXTENDED_RANGES;
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("NaiveBayesMultinomialText: No model built yet.\n", vector0, 1187);
      SparseInstance sparseInstance0 = new SparseInstance(1, doubleArray0, intArray0, 370);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      binarySparseInstance0.setValue(attribute0, 0.0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 23
  /*Coverage entropy=3.2211691983427277
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_periodicP = 0;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.m_periodicP = (-3876);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.periodicPruningTipText();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "fox";
      stringArray0[1] = "weka/core/Capabilities.props";
      CVParameterSelection cVParameterSelection0 = new CVParameterSelection();
      cVParameterSelection0.getRevision();
      Capabilities capabilities1 = cVParameterSelection0.getCapabilities();
      capabilities1.enableAllClassDependencies();
      capabilities0.or(capabilities1);
      stringArray0[2] = "Whether to convert all tokens to lowercase";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.675485446901437
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = false;
      naiveBayesMultinomialText0.pruneDictionary();
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.setPeriodicPruning((-1));
      naiveBayesMultinomialText0.setNorm((-4696.514503));
      naiveBayesMultinomialText0.m_periodicP = 0;
      naiveBayesMultinomialText0.m_tokenizer = null;
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.m_stopwords = null;
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, (String[]) null);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.setNorm((-4696.514503));
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 25
  /*Coverage entropy=1.5981863871455346
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      SparseInstance sparseInstance0 = new SparseInstance(247);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance1);
      DenseInstance denseInstance0 = new DenseInstance(sparseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double double0 = naiveBayesMultinomialText0.m_leplace;
      naiveBayesMultinomialText0.normTipText();
      try { 
        naiveBayesMultinomialText0.classifyInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=0.8505612088663046
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      double[] doubleArray0 = new double[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-4151.3589), doubleArray0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.getMatches();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.MAP_EXTENDED_RANGES;
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("", vector0, 6);
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "relational";
      stringArray0[1] = "real";
      stringArray0[2] = "date";
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.2248830687452414
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[18];
      intArray0[0] = (-1902);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-3), intArray0, (-3));
      naiveBayesMultinomialText0.getStopwords();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=1.5981863871455346
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      SparseInstance sparseInstance0 = new SparseInstance(247);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance1);
      DenseInstance denseInstance0 = new DenseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(6);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_wordsPerClass = null;
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.toString();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      naiveBayesMultinomialText0.normTipText();
      IBk iBk0 = new IBk(113);
      TestInstances testInstances0 = new TestInstances();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      BallNode ballNode0 = new BallNode((-32));
      MiddleOutConstructor middleOutConstructor0 = new MiddleOutConstructor();
      try { 
        middleOutConstructor0.buildTree();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.balltrees.BallNode", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=2.9005822944550714
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.find();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.AUTOSELECT_FILTERING;
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("stoplist", list0, 1384);
      NGramTokenizer nGramTokenizer1 = new NGramTokenizer();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "string";
      nGramTokenizer0.setOptions(stringArray0);
      nGramTokenizer1.setOptions(stringArray0);
      NGramTokenizer.main(stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setDebug(false);
      double double0 = naiveBayesMultinomialText0.m_leplace;
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(true);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.generate();
      boolean boolean0 = naiveBayesMultinomialText0.getNormalizeDocLength();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(boolean0);
  }

  /**
  //Test case number: 31
  /*Coverage entropy=3.092239687046295
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      naiveBayesMultinomialText0.toString();
      intArray0[0] = 1;
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 1;
      doubleArray0[1] = (double) 1;
      doubleArray0[2] = (double) 1;
      doubleArray0[3] = (double) 1;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, doubleArray0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities1 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities1.getMatches();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.MAP_EXTENDED_RANGES;
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("NaiveBayesMultinomialText: No model built yet.\n", vector0, 1);
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "real";
      stringArray0[1] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[2] = "real";
      stringArray0[3] = "relational";
      stringArray0[4] = "integer";
      stringArray0[5] = "relational";
      stringArray0[6] = "string";
      stringArray0[7] = "string";
      stringArray0[8] = "real";
      nGramTokenizer0.setOptions(stringArray0);
      String[] stringArray1 = new String[4];
      stringArray1[0] = "date";
      stringArray1[1] = "real";
      stringArray1[2] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray1[3] = "integer";
      nGramTokenizer0.setOptions(stringArray1);
      NGramTokenizer.main(stringArray1);
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 32
  /*Coverage entropy=3.0423434204195408
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm(337.4781198);
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.stemmerTipText();
      SystemInUtil.addInputLine("");
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.pruneDictionary();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = 337.4781198;
      doubleArray0[1] = 337.4781198;
      doubleArray0[2] = (-3065.7401704);
      doubleArray0[3] = (double) 2;
      doubleArray0[4] = 337.4781198;
      doubleArray0[5] = (-3065.7401704);
      doubleArray0[6] = 337.4781198;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-3065.7401704), doubleArray0);
      // Undeclared exception!
      try { 
        binarySparseInstance0.relationalValue(2);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 33
  /*Coverage entropy=3.364078142723086
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      MockFile mockFile0 = new MockFile("{Td<", "&:9ikAbW>fG3>{S");
      mockFile0.getCanonicalPath();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.getStopwords();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      double double0 = naiveBayesMultinomialText1.m_t;
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(true);
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.setLowercaseTokens(true);
      assertTrue(naiveBayesMultinomialText2.getLowercaseTokens());
      
      naiveBayesMultinomialText1.LNormTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "{Td<";
      stringArray0[1] = "";
      stringArray0[2] = "/home/ubuntu/termite/projects/107_weka/{Td</&:9ikAbW>fG3>{S";
      stringArray0[3] = "{Td<";
      stringArray0[4] = "{Td<";
      stringArray0[5] = "The LNorm to use for document length normalization.";
      stringArray0[6] = "The LNorm to use for document length normalization.";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText3.lowercaseTokensTipText();
      assertEquals(2.0, naiveBayesMultinomialText3.getLNorm(), 0.01);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=3.110565974340754
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      nGramTokenizer0.getOptions();
      naiveBayesMultinomialText0.m_minWordP = 0.0;
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      File file0 = MockFile.createTempFile("The stemming algorithm to use on the words.", "The stemming algorithm to use on the words.");
      file0.toPath();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      naiveBayesMultinomialText0.getOptions();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 35
  /*Coverage entropy=1.543056733112554
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertFalse(boolean0);
      
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte) (-119);
      byteArray0[1] = (byte) (-1);
      byteArray0[2] = (byte)8;
      byteArray0[3] = (byte) (-1);
      byteArray0[4] = (byte) (-126);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      Random.setNextRandom(3468);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      String string0 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", string0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 36
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      
      naiveBayesMultinomialText0.pruneDictionary();
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      IBk iBk0 = new IBk((-1632));
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      IteratedLovinsStemmer iteratedLovinsStemmer1 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer1);
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      String string1 = naiveBayesMultinomialText0.stemmerTipText();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", string1);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 37
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SparseInstance sparseInstance0 = new SparseInstance(247);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance1);
      DenseInstance denseInstance0 = new DenseInstance(sparseInstance1);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance1);
      String[] stringArray0 = new String[9];
      stringArray0[0] = "i.gU.O$B";
      stringArray0[1] = "    for (i = 0; i < data.numInstances(); i++)\n";
      stringArray0[2] = "";
      stringArray0[3] = "X`&v/";
      stringArray0[4] = "";
      stringArray0[5] = "";
      stringArray0[6] = "g+aw";
      stringArray0[7] = "'CDP_wMh";
      String string0 = naiveBayesMultinomialText0.getRevision();
      assertEquals("9122", string0);
      
      String string1 = naiveBayesMultinomialText0.globalInfo();
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string1);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 38
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string0);
      
      String string1 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      
      String string2 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string2);
      
      NullStemmer nullStemmer0 = new NullStemmer();
      String string3 = naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string3);
  }

  /**
  //Test case number: 39
  /*Coverage entropy=1.6969987794394548
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "Sum (doubles): ");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getStopwords();
      String[] stringArray0 = new String[8];
      stringArray0[1] = "Sum (doubles): ";
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      testInstances1.generate();
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, double0, 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 40
  /*Coverage entropy=2.43052687404108
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      SparseInstance sparseInstance0 = new SparseInstance(247);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance1);
      DenseInstance denseInstance0 = new DenseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(6);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      
      String[] stringArray0 = new String[3];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "ers";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 41
  /*Coverage entropy=2.631353359565896
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-normalize";
      stringArray0[1] = "";
      stringArray0[2] = "";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0.0, double0, 0.01);
  }

  /**
  //Test case number: 42
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      double[] doubleArray0 = new double[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.05, doubleArray0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      findWithCapabilities0.getMatches();
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 43
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      boolean boolean0 = false;
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      TopDownConstructor topDownConstructor0 = new TopDownConstructor();
      try { 
        topDownConstructor0.buildTree();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.balltrees.TopDownConstructor", e);
      }
  }

  /**
  //Test case number: 44
  /*Coverage entropy=3.0116974187751637
  */
  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "Q,3";
      stringArray0[1] = "?";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      MockFile mockFile0 = new MockFile("?");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.getTokenizer();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      File file0 = naiveBayesMultinomialText1.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.getStopwords();
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      Instances instances0 = testInstances1.generate();
      naiveBayesMultinomialText2.buildClassifier(instances0);
      String string0 = naiveBayesMultinomialText2.lowercaseTokensTipText();
      assertEquals(1.0, naiveBayesMultinomialText2.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", string0);
      assertEquals(3.0, naiveBayesMultinomialText2.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 45
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test45()  throws Throwable  {
      SparseInstance sparseInstance0 = new SparseInstance(247);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance1);
      DenseInstance denseInstance0 = new DenseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(6);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(12, stringArray0.length);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 46
  /*Coverage entropy=1.6082873972465448
  */
  @Test(timeout = 4000)
  public void test46()  throws Throwable  {
      SparseInstance sparseInstance0 = new SparseInstance(303);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance1);
      binarySparseInstance0.setMissing((-2029));
      DenseInstance denseInstance0 = new DenseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(6);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getStemmer();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText1.classifyInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }
}
