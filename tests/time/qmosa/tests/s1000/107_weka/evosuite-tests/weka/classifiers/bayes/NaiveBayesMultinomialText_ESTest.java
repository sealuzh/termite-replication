/*
 * This file was automatically generated by EvoSuite
 * Tue Dec 03 14:01:03 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.util.ArrayList;
import java.util.Properties;
import java.util.Vector;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.util.MockRandom;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;
import org.xml.sax.SAXParseException;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.bayes.net.BIFReader;
import weka.classifiers.functions.SGDText;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.misc.InputMappedClassifier;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.FindWithCapabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.ProtectedProperties;
import weka.core.SparseInstance;
import weka.core.Stopwords;
import weka.core.TestInstances;
import weka.core.neighboursearch.BallTree;
import weka.core.neighboursearch.CoverTree;
import weka.core.neighboursearch.KDTree;
import weka.core.neighboursearch.LinearNNSearch;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.core.stemmers.IteratedLovinsStemmer;
import weka.core.stemmers.LovinsStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.AlphabeticTokenizer;
import weka.core.tokenizers.NGramTokenizer;
import weka.core.tokenizers.Tokenizer;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.7216997293944343
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/tmp");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "Development of a stemmin algorithm");
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "<=v6*");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)108;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      naiveBayesMultinomialText0.stemmerTipText();
      File file0 = MockFile.createTempFile("<=v6*", "-W <classname>");
      file0.mkdirs();
      MockFile mockFile0 = new MockFile(file0, "<=v6*");
      String[] stringArray0 = new String[9];
      stringArray0[0] = "Development of a stemmin algorithm";
      stringArray0[1] = "Development of a stemmin algorithm";
      stringArray0[2] = "The stemming algorithm to use on the words.";
      stringArray0[3] = "-W <classname>";
      stringArray0[4] = "Development of a stemmin algorithm";
      stringArray0[5] = "Development of a stemmin algorithm";
      stringArray0[6] = "<=v6*";
      stringArray0[7] = "<=v6*";
      stringArray0[8] = "Development of a stemmin algorithm";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      Instances instances0 = null;
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_periodicP = (-1543);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_norm = 1.0;
      naiveBayesMultinomialText0.pruneDictionary();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch();
      int[] intArray0 = new int[4];
      intArray0[0] = (-1543);
      intArray0[1] = (-1543);
      intArray0[2] = (-1543);
      intArray0[3] = (-1543);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1782.0251869131246, intArray0, (-1543));
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "IU0dF04;");
      try { 
        linearNNSearch0.nearestNeighbour(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.LinearNNSearch", e);
      }
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.297687147780183
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = tokenizer0;
      Stopwords stopwords0 = new Stopwords();
      naiveBayesMultinomialText0.m_stopwords = stopwords0;
      naiveBayesMultinomialText0.setNorm(114.01496379113);
      naiveBayesMultinomialText0.LNormTipText();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, false, false);
      Stopwords.isStopword("The LNorm to use for document length normalization.");
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=3.0440205692665008
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[9];
      naiveBayesMultinomialText0.setDebug(false);
      doubleArray0[0] = 5239.389;
      doubleArray0[1] = 5239.389;
      doubleArray0[2] = 5239.389;
      doubleArray0[3] = 5239.389;
      doubleArray0[4] = 5239.389;
      doubleArray0[5] = 5239.389;
      doubleArray0[6] = 5239.389;
      doubleArray0[7] = 5239.389;
      doubleArray0[3] = 5239.389;
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText1.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string0);
      
      naiveBayesMultinomialText1.setUseStopList(false);
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText1.setLowercaseTokens(false);
      assertFalse(naiveBayesMultinomialText1.getLowercaseTokens());
      assertFalse(naiveBayesMultinomialText1.getUseStopList());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      String string1 = naiveBayesMultinomialText2.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string1);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText3.setStemmer((Stemmer) null);
      String[] stringArray0 = naiveBayesMultinomialText3.getOptions();
      assertEquals(1.0, naiveBayesMultinomialText3.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText3.getPeriodicPruning());
      assertEquals(12, stringArray0.length);
      assertEquals(2.0, naiveBayesMultinomialText3.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText3.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 4
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      int[] intArray0 = new int[2];
      intArray0[0] = 1577;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-814.9168985159), intArray0, 1577);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.find();
      Properties properties0 = new Properties();
      findWithCapabilities0.setFilename("\"**t6qvjDt\"qBmt|");
      ProtectedProperties protectedProperties0 = new ProtectedProperties(properties0);
      ProtectedProperties protectedProperties1 = new ProtectedProperties(properties0);
      ProtectedProperties protectedProperties2 = new ProtectedProperties(properties0);
      ProtectedProperties protectedProperties3 = new ProtectedProperties(properties0);
      Attribute attribute0 = new Attribute("b/%wPZp!3:_m", vector0, protectedProperties3);
      binarySparseInstance0.value(attribute0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance1);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.updateClassifier(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=3.125827073718919
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      capabilities0.getClassCapabilities();
      naiveBayesMultinomialText0.m_lowercaseTokens = false;
      naiveBayesMultinomialText0.setMinWordFrequency((-1.0));
      naiveBayesMultinomialText0.stemmerTipText();
      Stemmer stemmer0 = naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.setStemmer(stemmer0);
      File file0 = MockFile.createTempFile("weka/core/Capabilities.props", "w**1hOOM>");
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.getMinWordFrequency();
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      BIFReader bIFReader0 = new BIFReader();
      try { 
        bIFReader0.processString("w**1hOOM>");
        fail("Expecting exception: SAXParseException");
      
      } catch(SAXParseException e) {
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=3.1084644497821365
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setLowercaseTokens(true);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText1.getOptions();
      assertTrue(naiveBayesMultinomialText1.getLowercaseTokens());
  }

  /**
  //Test case number: 7
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_minWordP = 0.0;
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.periodicPruningTipText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      costSensitiveClassifier0.getCostMatrix();
      int[] intArray0 = new int[7];
      FileSystemHandling.shouldAllThrowIOExceptions();
      intArray0[0] = 2;
      intArray0[1] = 1;
      intArray0[2] = 2;
      intArray0[3] = 2;
      intArray0[4] = 1;
      intArray0[5] = 2;
      intArray0[6] = 2;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.0, intArray0, 2);
      KDTree kDTree0 = new KDTree();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances");
      try { 
        kDTree0.nearestNeighbour(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (-265.86122199091665);
      doubleArray0[1] = (-265.86122199091665);
      doubleArray0[2] = (-265.86122199091665);
      doubleArray0[3] = (-265.86122199091665);
      doubleArray0[4] = (-265.86122199091665);
      doubleArray0[5] = (-265.86122199091665);
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[4];
      stringArray0[1] = "ipl&Sq ";
      stringArray0[2] = "D#{;qNs";
      stringArray0[3] = "ipl&Sq ";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.139040731301256
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      File file0 = MockFile.createTempFile("w**1hOOM>", "-W <classname>");
      MockFile mockFile0 = new MockFile(file0, "w**1hOOM>");
      mockFile0.getCanonicalFile();
      mockFile0.getAbsoluteFile();
      mockFile0.deleteOnExit();
      mockFile0.setReadable(true, false);
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.useStopListTipText();
      DenseInstance denseInstance0 = new DenseInstance(0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=2.2584261358947213
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (-264.9474023994686);
      doubleArray0[1] = (-264.9474023994686);
      doubleArray0[2] = (-264.9474023994686);
      doubleArray0[3] = (-264.9474023994686);
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      int[] intArray0 = new int[4];
      intArray0[0] = 1550;
      intArray0[1] = 6;
      intArray0[2] = 1550;
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.periodicPruningTipText();
      naiveBayesMultinomialText1.normTipText();
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
  }

  /**
  //Test case number: 11
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stopwordsTipText();
      double double0 = 608.4;
      naiveBayesMultinomialText0.setLNorm(608.4);
      Instance instance0 = null;
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=2.7787755691845217
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      
      naiveBayesMultinomialText0.m_useStopList = false;
      String string1 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string1);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      naiveBayesMultinomialText0.m_normalize = false;
      String string2 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string2);
      
      Random.setNextRandom((-1985));
      String string3 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string3);
      
      String string4 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string4);
      
      Random.setNextRandom((-1985));
      naiveBayesMultinomialText0.m_normalize = false;
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertFalse(boolean0);
      
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) (-1985);
      doubleArray0[1] = (double) (-1985);
      doubleArray0[2] = (double) (-1985);
      doubleArray0[3] = (double) (-1985);
      doubleArray0[4] = (double) (-1985);
      doubleArray0[5] = (double) (-1985);
      doubleArray0[6] = (double) (-1985);
      doubleArray0[7] = (double) (-1985);
      doubleArray0[8] = (double) (-1985);
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      String string5 = naiveBayesMultinomialText0.globalInfo();
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string5);
      
      naiveBayesMultinomialText0.getTokenizer();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 13
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      findWithCapabilities0.find();
      Properties properties0 = new Properties();
      ProtectedProperties protectedProperties0 = new ProtectedProperties(properties0);
      findWithCapabilities0.getMatches();
      naiveBayesMultinomialText0.getStopwords();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 14
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      testInstances0.getRelationalClassFormat();
      BallTree ballTree0 = new BallTree((Instances) null);
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (-1167.484107915171);
      SparseInstance sparseInstance0 = new SparseInstance((-1167.484107915171), doubleArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string1 = naiveBayesMultinomialText1.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string1);
      
      String string2 = naiveBayesMultinomialText1.globalInfo();
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string2);
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText1.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
  }

  /**
  //Test case number: 15
  /*Coverage entropy=2.7623766256291957
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      File file0 = MockFile.createTempFile("w**1hOOM>", "-W <classname>");
      MockFile mockFile0 = new MockFile("-W <classname>", "The LNorm to use for document length normalization.");
      FileSystemHandling.shouldAllThrowIOExceptions();
      file0.setExecutable(false, false);
      mockFile0.setReadable(false, false);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setStopwords(file0);
      boolean boolean0 = naiveBayesMultinomialText0.m_wordFrequencies;
      naiveBayesMultinomialText0.useStopListTipText();
      DenseInstance denseInstance0 = new DenseInstance(0);
      naiveBayesMultinomialText0.LNormTipText();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      
      String[] stringArray0 = new String[1];
      stringArray0[0] = "The stemming algorithm to use on the words.";
      naiveBayesMultinomialText0.setOptions((String[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.normTipText();
      String string0 = naiveBayesMultinomialText1.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
  }

  /**
  //Test case number: 16
  /*Coverage entropy=2.070976373972562
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      boolean boolean0 = true;
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.m_t = 0.0;
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.setNorm(0.0);
      naiveBayesMultinomialText0.getUseStopList();
      CoverTree coverTree0 = new CoverTree();
      double[] doubleArray0 = new double[0];
      DenseInstance denseInstance0 = new DenseInstance(0.0, doubleArray0);
      // Undeclared exception!
      try { 
        denseInstance0.setClassValue(0.0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 17
  /*Coverage entropy=2.9756246229366328
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (-265.86122199091665);
      doubleArray0[1] = (-265.86122199091665);
      doubleArray0[2] = (-265.86122199091665);
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.getMinWordFrequency();
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      LovinsStemmer lovinsStemmer1 = new LovinsStemmer();
      lovinsStemmer0.getTechnicalInformation();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setStemmer(lovinsStemmer0);
      naiveBayesMultinomialText1.periodicPruningTipText();
      naiveBayesMultinomialText1.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText1.getUseWordFrequencies();
      assertTrue(naiveBayesMultinomialText1.getNormalizeDocLength());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances";
      stringArray0[1] = "!NB";
      stringArray0[2] = "!NB";
      stringArray0[3] = "/O";
      stringArray0[4] = "How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances";
      stringArray0[5] = "How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances";
      stringArray0[6] = "How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances";
      naiveBayesMultinomialText1.setOptions(stringArray0);
      naiveBayesMultinomialText0.pruneDictionary();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.070976373972562
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      File file0 = MockFile.createTempFile("w**1hOOM>", "-W <classname>");
      MockFile mockFile0 = new MockFile("-W <classname>", "The LNorm to use for document length normalization.");
      FileSystemHandling.shouldAllThrowIOExceptions();
      file0.setExecutable(true, false);
      mockFile0.setReadable(true, true);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, false, true);
      naiveBayesMultinomialText0.useStopListTipText();
      DenseInstance denseInstance0 = new DenseInstance(72);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=1.5179872908529675
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning(774);
      naiveBayesMultinomialText0.stemmerTipText();
      int[] intArray0 = new int[0];
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("MEq", arrayList0, 1225);
      Instance instance0 = BallNode.calcCentroidPivot(intArray0, instances0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(instance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.535541096995737
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      File file0 = MockFile.createTempFile("w**1hOOM>", "-W <classname>");
      MockFile mockFile0 = new MockFile("-W <classname>", "The LNorm to use for document length normalization.");
      mockFile0.setReadable(false, false);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.useStopListTipText();
      DenseInstance denseInstance0 = new DenseInstance(0);
      naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, false);
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      findWithCapabilities0.find();
      Properties properties0 = new Properties();
      findWithCapabilities0.getMatches();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) denseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      int[] intArray0 = new int[2];
      intArray0[0] = 1577;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1), intArray0, 1577);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      findWithCapabilities0.getMisses();
      Properties properties0 = new Properties();
      findWithCapabilities0.setFilename("b/%wPZp!3:_m");
      ProtectedProperties protectedProperties0 = new ProtectedProperties(properties0);
      ProtectedProperties protectedProperties1 = new ProtectedProperties(protectedProperties0);
      ProtectedProperties protectedProperties2 = new ProtectedProperties(protectedProperties0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance1);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, double0, 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 23
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Stopwords stopwords0 = naiveBayesMultinomialText0.m_stopwords;
      naiveBayesMultinomialText0.m_stopwords = null;
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.setTokenizer(alphabeticTokenizer0);
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.setNorm(118.9395366369);
      naiveBayesMultinomialText0.setPeriodicPruning(101);
      assertEquals(118.9395366369, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.319564948514667
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      File file0 = MockFile.createTempFile("w**1hOOM>", "-W <classname>");
      MockFile mockFile0 = new MockFile("-W <classname>", "The LNorm to use for document length normalization.");
      FileSystemHandling.shouldAllThrowIOExceptions();
      file0.setExecutable(false, false);
      mockFile0.setReadable(false, false);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setStopwords(file0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      naiveBayesMultinomialText0.useStopListTipText();
      DenseInstance denseInstance0 = new DenseInstance(0);
      naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, false);
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.find();
      Properties properties0 = new Properties();
      findWithCapabilities0.getMatches();
      naiveBayesMultinomialText0.setStopwords(file0);
      Attribute attribute0 = null;
      try {
        attribute0 = new Attribute("-W <classname>", vector0, (ProtectedProperties) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Attribute", e);
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=1.9296217656001493
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      byte[] byteArray0 = new byte[3];
      byteArray0[0] = (byte)0;
      byteArray0[1] = (byte)59;
      byteArray0[2] = (byte)1;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (-265.86122199091665);
      doubleArray0[1] = (-265.86122199091665);
      doubleArray0[2] = (-265.86122199091665);
      doubleArray0[3] = (-265.86122199091665);
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.setLNorm(2170.467686602);
      Instance instance0 = null;
      try { 
        naiveBayesMultinomialText0.distributionForInstance((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=2.316344336598403
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      File file0 = MockFile.createTempFile("w**1hOOM>", "-W <classname>");
      MockFile mockFile0 = new MockFile("-W <classname>", "The LNorm to use for document length normalization.");
      FileSystemHandling.shouldAllThrowIOExceptions();
      file0.setExecutable(false, false);
      mockFile0.setReadable(false, false);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setStopwords(file0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      naiveBayesMultinomialText0.useStopListTipText();
      DenseInstance denseInstance0 = new DenseInstance(0);
      naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, false);
      Properties properties0 = new Properties();
      naiveBayesMultinomialText0.normTipText();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 27
  /*Coverage entropy=2.042632211710285
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      Tokenizer tokenizer0 = sGDText0.getTokenizer();
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      naiveBayesMultinomialText0.getUseStopList();
      double[] doubleArray0 = new double[0];
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.setLNorm(99.0);
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=2.823770781636355
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_inputVector = null;
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray0.length);
      
      String string0 = naiveBayesMultinomialText1.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      String string1 = naiveBayesMultinomialText1.normTipText();
      assertEquals("The norm of the instances after normalization.", string1);
      
      double double0 = naiveBayesMultinomialText2.getNorm();
      assertEquals(2.0, naiveBayesMultinomialText2.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText2.getPeriodicPruning());
      assertEquals(3.0, naiveBayesMultinomialText2.getMinWordFrequency(), 0.01);
      assertEquals(1.0, double0, 0.01);
  }

  /**
  //Test case number: 29
  /*Coverage entropy=2.0557051606564785
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      File file0 = MockFile.createTempFile("w**1hOOM>", "-W <classname>");
      MockFile mockFile0 = new MockFile("-W <classname>", "The LNorm to use for document length normalization.");
      FileSystemHandling.shouldAllThrowIOExceptions();
      file0.setExecutable(false, false);
      mockFile0.setReadable(false, false);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setStopwords((File) null);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      naiveBayesMultinomialText0.useStopListTipText();
      DenseInstance denseInstance0 = new DenseInstance(0);
      naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, false);
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.find();
      Properties properties0 = new Properties();
      findWithCapabilities0.getMatches();
      Attribute attribute0 = null;
      try {
        attribute0 = new Attribute("-W <classname>", vector0, (ProtectedProperties) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Attribute", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "lwKWJ ";
      stringArray0[1] = "%}tokenizer";
      stringArray0[2] = "lwKWJ ";
      stringArray0[3] = "";
      naiveBayesMultinomialText0.setNorm((-5754.0));
      naiveBayesMultinomialText0.stopwordsTipText();
      Stemmer stemmer0 = naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.setStemmer(stemmer0);
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      SparseInstance sparseInstance0 = new SparseInstance(1022);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      try { 
        inputMappedClassifier0.constructMappedInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.misc.InputMappedClassifier", e);
      }
  }

  /**
  //Test case number: 31
  /*Coverage entropy=2.803139031403012
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.setPeriodicPruning((-417));
      naiveBayesMultinomialText0.normTipText();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(6);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      DenseInstance denseInstance0 = new DenseInstance(binarySparseInstance1);
      try { 
        naiveBayesMultinomialText0.classifyInstance(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 32
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(true);
      String[] stringArray0 = new String[6];
      stringArray0[0] = "lwKWJ ";
      stringArray0[1] = "tokenizer";
      stringArray0[2] = "-----------------------------------------\n\t";
      stringArray0[3] = "";
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (-410.2682574081);
      doubleArray0[1] = (-410.2682574081);
      doubleArray0[2] = (-410.2682574081);
      doubleArray0[3] = (-410.2682574081);
      doubleArray0[4] = (-410.2682574081);
      doubleArray0[5] = (-410.2682574081);
      doubleArray0[6] = (-410.2682574081);
      doubleArray0[7] = (-410.2682574081);
      doubleArray0[8] = (-410.2682574081);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-410.2682574081), doubleArray0);
      // Undeclared exception!
      try { 
        binarySparseInstance0.enumerateAttributes();
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 33
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.getRelationalClassFormat();
      MockRandom mockRandom0 = new MockRandom();
      BallTree ballTree0 = new BallTree((Instances) null);
      naiveBayesMultinomialText0.setLNorm(520.75322504166);
      int[] intArray0 = new int[2];
      intArray0[0] = 10000;
      intArray0[1] = 62;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-2), intArray0, (-428));
      binarySparseInstance0.dataset();
      // Undeclared exception!
      try { 
        BallNode.calcCentroidPivot(intArray0, (Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.balltrees.BallNode", e);
      }
  }

  /**
  //Test case number: 34
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      Random.setNextRandom(781);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm(781);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      try { 
        inputMappedClassifier0.getModelHeader((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 35
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      String string0 = "w**1hOOM>";
      File file0 = MockFile.createTempFile("w**1hOOM>", "-W <classname>");
      MockFile mockFile0 = new MockFile("-W <classname>", "The LNorm to use for document length normalization.");
      FileSystemHandling.shouldAllThrowIOExceptions();
      file0.setExecutable(false, false);
      mockFile0.setReadable(false, false);
      Instance instance0 = null;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(false);
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      ArrayList<Attribute> arrayList1 = new ArrayList<Attribute>();
      int[] intArray0 = new int[2];
      intArray0[0] = 1225;
      intArray0[1] = 1225;
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.setTokenizer(alphabeticTokenizer0);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 37
  /*Coverage entropy=0.9004024235381879
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      int[] intArray0 = new int[2];
      intArray0[0] = 1577;
      intArray0[1] = 1577;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-156.13092072778616), intArray0, (-1));
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      findWithCapabilities0.find();
      Properties properties0 = new Properties();
      findWithCapabilities0.setFilename("");
      ProtectedProperties protectedProperties0 = new ProtectedProperties(properties0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance1, false);
      FindWithCapabilities findWithCapabilities1 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities1.find();
      Properties properties1 = new Properties();
      ProtectedProperties protectedProperties1 = new ProtectedProperties(protectedProperties0);
      FindWithCapabilities findWithCapabilities2 = new FindWithCapabilities();
      findWithCapabilities2.getMatches();
      Attribute attribute0 = null;
      try {
        attribute0 = new Attribute("Y>I", vector0, (ProtectedProperties) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Attribute", e);
      }
  }
}
