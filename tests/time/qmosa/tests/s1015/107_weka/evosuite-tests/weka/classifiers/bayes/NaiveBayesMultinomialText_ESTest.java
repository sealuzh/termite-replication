/*
 * This file was automatically generated by EvoSuite
 * Wed Dec 04 01:32:58 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.net.URI;
import java.net.URISyntaxException;
import java.util.ArrayList;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.net.MockURI;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.bayes.NaiveBayesUpdateable;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.misc.SerializedClassifier;
import weka.classifiers.trees.LMT;
import weka.classifiers.trees.REPTree;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.EuclideanDistance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.Stopwords;
import weka.core.TestInstances;
import weka.core.neighboursearch.BallTree;
import weka.core.neighboursearch.CoverTree;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.NGramTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.filters.supervised.attribute.Discretize;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.869075671914195
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[6];
      intArray0[0] = (-138);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "RH=q]ua&_&_CfV9i-");
      intArray0[1] = (-7);
      intArray0[2] = 175;
      String[] stringArray0 = new String[2];
      stringArray0[0] = "qq4_!<]Z&_lD]c%EtC";
      stringArray0[1] = "x";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      NaiveBayesUpdateable naiveBayesUpdateable0 = new NaiveBayesUpdateable();
      Capabilities capabilities0 = naiveBayesUpdateable0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      testInstances0.setNumRelationalString((-138));
      naiveBayesMultinomialText0.m_periodicP = 888;
      SystemInUtil.addInputLine((String) null);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      Random.setNextRandom(596);
  }

  /**
  //Test case number: 1
  /*Coverage entropy=2.197266695776701
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[4] = "ML";
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.m_normalize = true;
      testInstances0.setNumRelationalString(596);
      SystemInUtil.addInputLine("The tree has not been supplied with a set of instances or getDistances() has been called before calling kNearestNeighbours().");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("The independent probability of a class\n--------------------------------------\nclass1\t12.0\nclass2\t10.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\t\n", string0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.419594359581629
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      MockFile mockFile0 = new MockFile(file0, "Y=y!%[");
      MockFile mockFile1 = new MockFile(mockFile0, "lld");
      MockFile.createTempFile("cembr", "lld");
      file0.setReadOnly();
      file0.setReadable(true, false);
      file0.toURL();
      MockFile mockFile2 = new MockFile("", "m|hM:>RPw>");
      naiveBayesMultinomialText0.getStopwords();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setPeriodicPruning(0);
      naiveBayesMultinomialText0.getCapabilities();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      naiveBayesMultinomialText0.toString();
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) sparseInstance0);
      try { 
        naiveBayesMultinomialText1.updateClassifier(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=0.9004024235381879
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[4] = "ML";
      TestInstances testInstances0 = new TestInstances();
      testInstances0.generate();
      naiveBayesMultinomialText0.m_normalize = true;
      testInstances0.setNumRelationalString(596);
      SystemInUtil.addInputLine("The tree has not been supplied with a set of instances or getDistances() has been called before calling kNearestNeighbours().");
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) (-2);
      doubleArray0[1] = (double) 596;
      doubleArray0[2] = (double) (-1);
      doubleArray0[3] = (double) 596;
      doubleArray0[4] = (double) (-1);
      doubleArray0[5] = (double) (-1);
      doubleArray0[6] = (-1.0);
      doubleArray0[7] = (double) (-1);
      doubleArray0[8] = (double) 596;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1.0), doubleArray0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.68082764903455
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double double0 = 2.0;
      naiveBayesMultinomialText0.m_tokenizer = null;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.getOptions();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=0.9909065731902369
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("ML", arrayList0, 12);
      Capabilities capabilities0 = Capabilities.forInstances(instances0);
      TestInstances.forCapabilities(capabilities0);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.generate();
      DenseInstance denseInstance0 = new DenseInstance(1484);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText1.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=2.139786465613918
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.toString();
      double[] doubleArray0 = new double[0];
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      boolean boolean0 = false;
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      SparseInstance sparseInstance0 = new SparseInstance(496.273681028, naiveBayesMultinomialText0.m_probOfClass);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 7
  /*Coverage entropy=2.9005822944550714
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.getStopwords();
      NullStemmer nullStemmer0 = new NullStemmer();
      nullStemmer0.getRevision();
      naiveBayesMultinomialText0.setStemmer(nullStemmer0);
      naiveBayesMultinomialText0.getOptions();
      Instance instance0 = null;
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=3.3574036981168276
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>(175);
      Instances instances0 = new Instances((String) null, arrayList0, 175);
      Capabilities capabilities0 = Capabilities.forInstances(instances0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.setSeed(175);
      TestInstances testInstances1 = new TestInstances();
      testInstances0.setNumRelationalString(576);
      SystemInUtil.addInputLine("H'bZm");
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: No attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=3.3574036981168276
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "_");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      int[] intArray0 = new int[9];
      intArray0[0] = 0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(245.0, intArray0, (-1));
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) sparseInstance0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=1.9296217656001493
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file0 = MockFile.createTempFile("weka.classifiers.meta.AdditiveRegression", "The maximum Subsequence length (theta in the paper)");
      naiveBayesMultinomialText0.setStopwords(file0);
      Stopwords stopwords0 = new Stopwords();
      naiveBayesMultinomialText0.pruneDictionary();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 11
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = 0.05;
      doubleArray0[1] = 0.0;
      DenseInstance denseInstance0 = new DenseInstance(0.05, doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[6];
      int int0 = (-138);
      intArray0[0] = (-138);
      intArray0[1] = (-7);
      intArray0[2] = (-7);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "qq4_!<]Z&_lD]c%EtC";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=3.050469885856446
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "";
      stringArray0[1] = "R]o^c\"R4l(arzs";
      naiveBayesMultinomialText0.setUseStopList(true);
      stringArray0[2] = "9fZgy~gsga";
      nGramTokenizer0.setNGramMinSize(0);
      stringArray0[3] = "\tScore type (BAYES, BDeu, MDL, ENTROPY and AIC)";
      nGramTokenizer0.tokenize("weka.classifiers.functions.LinearRegression");
      naiveBayesMultinomialText0.setLNorm(0);
      stringArray0[4] = "#J";
      stringArray0[5] = "w;:X:ETaDn`iqT/`.";
      stringArray0[6] = "IE";
      Tokenizer.runTokenizer(nGramTokenizer0, stringArray0);
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.setStopwords((File) null);
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(boolean0);
  }

  /**
  //Test case number: 14
  /*Coverage entropy=1.3221086830269158
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "ML";
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file0 = serializedClassifier0.getModelFile();
      MockFile mockFile0 = new MockFile(file0, "ML");
      MockFile mockFile1 = new MockFile(file0, "lid");
      MockFile.createTempFile("1 EuDdQv5Bbx]LZt1", "|");
      mockFile0.setWritable(true, true);
      naiveBayesMultinomialText0.setStopwords(file0);
      int[] intArray0 = new int[6];
      intArray0[0] = 2930;
      intArray0[1] = 2930;
      intArray0[2] = 2930;
      intArray0[3] = 2930;
      intArray0[4] = 2930;
      intArray0[5] = 2930;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2930, intArray0, 2930);
      mockFile1.setWritable(false, true);
      naiveBayesMultinomialText0.setStopwords((File) null);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      Stopwords stopwords0 = new Stopwords();
      naiveBayesMultinomialText1.pruneDictionary();
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
  }

  /**
  //Test case number: 15
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) nGramTokenizer0;
      String[] stringArray0 = new String[2];
      stringArray0[0] = "publisher";
      stringArray0[1] = "?9p$N\"xshXSd}iC[";
      nGramTokenizer0.setOptions(stringArray0);
      NullStemmer nullStemmer0 = new NullStemmer();
      naiveBayesMultinomialText0.setStemmer(nullStemmer0);
      String[] stringArray1 = new String[9];
      stringArray1[0] = "";
      stringArray1[1] = "The norm of the instances after normalization.";
      stringArray1[2] = "Node ";
      stringArray1[3] = "";
      stringArray1[4] = "j,T CQ:i,a[9cOV&'s";
      stringArray1[5] = "An adaptation of Relief for attribute estimation in regression";
      stringArray1[6] = "yVTMFo}Y)}W>;QtgOww";
      stringArray1[7] = "Px";
      stringArray1[8] = "]V&+_y?";
      NGramTokenizer.main(stringArray1);
      String string0 = naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string0);
      
      Stemmer stemmer0 = naiveBayesMultinomialText0.getStemmer();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertSame(stemmer0, nullStemmer0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 16
  /*Coverage entropy=2.108838365573966
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "ML";
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate((String) null);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      Random.setNextRandom((-1211));
  }

  /**
  //Test case number: 17
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_minWordP = (-1359.0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      BallTree ballTree0 = new BallTree();
      try { 
        ballTree0.nearestNeighbour((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.BallTree", e);
      }
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.7787755691845217
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.getLNorm();
      MockFile mockFile0 = new MockFile(" ");
      mockFile0.getCanonicalFile();
      MockFile mockFile1 = new MockFile(mockFile0, " ");
      naiveBayesMultinomialText0.m_stopwordsFile = (File) mockFile1;
      mockFile1.setLastModified(0L);
      mockFile1.mkdir();
      mockFile0.delete();
      mockFile0.getCanonicalFile();
      mockFile0.getCanonicalFile();
      mockFile0.getCanonicalFile();
      mockFile1.getAbsolutePath();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      mockFile1.getAbsolutePath();
      mockFile1.setReadable(false);
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.useStopListTipText();
      CoverTree coverTree0 = new CoverTree();
      try { 
        coverTree0.kNearestNeighbours((Instance) null, 794);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "ML";
      int int0 = 343;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(343);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Capabilities.props");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, (String) null);
      binarySparseInstance0.dataset();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 20
  /*Coverage entropy=0.9004024235381879
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[6];
      intArray0[0] = (-138);
      intArray0[1] = (-7);
      intArray0[2] = 175;
      intArray0[3] = 0;
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("Node ", arrayList0, 0);
      Capabilities capabilities0 = Capabilities.forInstances(instances0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      instances0.containsAll(arrayList0);
      Instances instances1 = testInstances0.generate();
      EuclideanDistance[] euclideanDistanceArray0 = new EuclideanDistance[3];
      EuclideanDistance euclideanDistance0 = new EuclideanDistance();
      euclideanDistanceArray0[0] = euclideanDistance0;
      EuclideanDistance euclideanDistance1 = new EuclideanDistance(instances1);
      euclideanDistanceArray0[1] = euclideanDistance1;
      EuclideanDistance euclideanDistance2 = new EuclideanDistance(instances1);
      euclideanDistanceArray0[2] = euclideanDistance2;
      arrayList0.toArray(euclideanDistanceArray0);
      Instance instance0 = BallNode.calcCentroidPivot(0, (-711), intArray0, instances1);
      naiveBayesMultinomialText0.tokenizeInstance(instance0, false);
      Random.setNextRandom(85);
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.toString();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = 2.0;
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      SystemInUtil.addInputLine("NaiveBayesMultinomialText: No model built yet.\n");
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) sparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=2.2584261358947213
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      REPTree rEPTree0 = new REPTree();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "amongst");
      rEPTree0.setNumFolds(1479);
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "Gof@+z_{jhWNWD8=s");
      naiveBayesMultinomialText0.stemmerTipText();
      assertEquals(0.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 23
  /*Coverage entropy=2.41257681572198
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = (-2.0);
      naiveBayesMultinomialText0.m_useStopList = true;
      URI uRI0 = MockURI.aFileURI;
      MockFile mockFile0 = new MockFile(uRI0);
      naiveBayesMultinomialText0.m_stopwordsFile = (File) mockFile0;
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      String[] stringArray0 = new String[5];
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      stringArray0[0] = "*U>1";
      stringArray0[1] = "|s^dVdmli";
      stringArray0[2] = "All class and attribute options can be prefixed with 'not',\ne.g., '-not-numeric-class'. This makes sure that the returned\nschemes 'cannot' handle numeric classes.";
      stringArray0[3] = "[.>7W {>]mT9s>(6a-";
      stringArray0[4] = "G.hF{;n<%";
      Tokenizer.tokenize((Tokenizer) wordTokenizer0, stringArray0);
      naiveBayesMultinomialText0.setPeriodicPruning(1349);
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("[.>7W {>]mT9s>(6a-", arrayList0, 1349);
      try { 
        BallNode.calcPivot((BallNode) null, (BallNode) null, instances0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.balltrees.BallNode", e);
      }
  }

  /**
  //Test case number: 24
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "ML";
      REPTree rEPTree0 = new REPTree();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "ML");
      rEPTree0.setNumFolds(15);
      AbstractClassifier.makeCopies(rEPTree0, 2489);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "9RxTx=aB:Y4");
      naiveBayesMultinomialText0.toString();
      try { 
        naiveBayesMultinomialText0.distributionForInstance((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=1.6969987794394548
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      MockFile mockFile0 = new MockFile(file0, "Y=y!%[");
      MockFile mockFile1 = (MockFile)naiveBayesMultinomialText0.m_stopwordsFile;
      MockFile mockFile2 = new MockFile(mockFile1, "");
      MockFile.createTempFile("j:(", "");
      mockFile0.toURL();
      MockFile mockFile3 = new MockFile("", "");
      mockFile2.setWritable(true);
      mockFile3.setWritable(true, true);
      naiveBayesMultinomialText0.setStopwords(mockFile2);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      assertEquals(0, naiveBayesMultinomialText1.getPeriodicPruning());
      
      Stopwords stopwords0 = new Stopwords();
      naiveBayesMultinomialText0.pruneDictionary();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 26
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int int0 = naiveBayesMultinomialText0.getPeriodicPruning();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, int0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 27
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      String[] stringArray0 = new String[5];
      stringArray0[4] = "ML";
      TestInstances testInstances0 = new TestInstances();
      testInstances0.generate();
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      System.setCurrentTimeMillis(1L);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      String string0 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string0);
  }

  /**
  //Test case number: 28
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "";
      stringArray0[1] = "R]o^c\"R4l(arzs";
      boolean boolean0 = true;
      naiveBayesMultinomialText0.setUseStopList(true);
      stringArray0[2] = "";
      nGramTokenizer0.setNGramMinSize(0);
      stringArray0[3] = "\tScore type (BAYES, BDeu, MDL, ENTROPY and AIC)";
      nGramTokenizer0.tokenize("weka.classifiers.functions.LinearRegression");
      stringArray0[4] = "#J";
      stringArray0[5] = "w;:X:ETaDn`iqT/`.";
      stringArray0[6] = "IE";
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      Discretize discretize0 = new Discretize();
      // Undeclared exception!
      try { 
        discretize0.output();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // No output instance format defined
         //
         verifyException("weka.filters.Filter", e);
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      REPTree rEPTree0 = new REPTree();
      rEPTree0.setNumFolds(1479);
      rEPTree0.setNumFolds(1479);
      AbstractClassifier.makeCopies(rEPTree0, 68);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, (String) null);
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      
      String string1 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string1);
      
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 30
  /*Coverage entropy=2.108838365573966
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[4] = "ML";
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      testInstances0.setNumRelationalString(596);
      SystemInUtil.addInputLine("The tree has not been supplied with a set of instances or getDistances() has been called before calling kNearestNeighbours().");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      Random.setNextRandom((-2));
  }

  /**
  //Test case number: 31
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      naiveBayesMultinomialText0.setLNorm(1.0);
      naiveBayesMultinomialText0.getUseStopList();
      String string0 = "";
      URI uRI0 = MockURI.create("");
      MockFile mockFile0 = null;
      try {
        mockFile0 = new MockFile(uRI0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // URI is not absolute
         //
         verifyException("java.io.File", e);
      }
  }

  /**
  //Test case number: 32
  /*Coverage entropy=2.6522676908403224
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[6];
      int int0 = (-138);
      intArray0[0] = (-138);
      intArray0[1] = (-7);
      intArray0[2] = 175;
      String[] stringArray0 = new String[2];
      stringArray0[0] = "qq4_!<]Z&_lD]c%EtC";
      stringArray0[1] = "x";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 33
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 34
  /*Coverage entropy=1.543056733112554
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) nGramTokenizer0;
      NullStemmer nullStemmer0 = new NullStemmer();
      naiveBayesMultinomialText0.setStemmer(nullStemmer0);
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "The norm of the instances after normalization.";
      String string0 = "Node ";
      stringArray0[2] = "Node ";
      NaiveBayesMultinomialText.main(stringArray0);
      String string1 = "Y";
      try { 
        MockURI.URI("The norm of the instances after normalization.", "", "Y");
        fail("Expecting exception: URISyntaxException");
      
      } catch(URISyntaxException e) {
         //
         // Illegal character in scheme name at index 3: The norm of the instances after normalization.:#Y
         //
         verifyException("java.net.URI$Parser", e);
      }
  }

  /**
  //Test case number: 35
  /*Coverage entropy=2.5500297769739535
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.LNormTipText();
      Stopwords stopwords0 = naiveBayesMultinomialText0.m_stopwords;
      naiveBayesMultinomialText0.m_stopwords = null;
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.setMinWordFrequency(1.0E10);
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      naiveBayesMultinomialText0.getMinWordFrequency();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      int[] intArray0 = new int[4];
      intArray0[0] = (-1938);
      intArray0[1] = 867;
      intArray0[2] = 867;
      naiveBayesMultinomialText0.stemmerTipText();
      assertEquals(1.0E10, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 36
  /*Coverage entropy=2.070976373972562
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      String string1 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string1);
      
      naiveBayesMultinomialText0.getUseStopList();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string2 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", string2);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 37
  /*Coverage entropy=2.41257681572198
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "";
      stringArray0[1] = "R]o^c\"R4l(arzs";
      naiveBayesMultinomialText0.setUseStopList(true);
      stringArray0[2] = "9fZgy~gsga";
      nGramTokenizer0.setNGramMinSize(0);
      stringArray0[3] = "\tScore type (BAYES, BDeu, MDL, ENTROPY and AIC)";
      nGramTokenizer0.tokenize("weka.classifiers.functions.LinearRegression");
      stringArray0[4] = "#J";
      stringArray0[5] = "w;:X:ETaDn`iqT/`.";
      stringArray0[6] = "IE";
      Tokenizer.runTokenizer(nGramTokenizer0, stringArray0);
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 38
  /*Coverage entropy=2.8863990313046046
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string0);
      
      naiveBayesMultinomialText0.reset();
      String string1 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string1);
      
      Stopwords stopwords0 = naiveBayesMultinomialText0.m_stopwords;
      naiveBayesMultinomialText0.setUseStopList(false);
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      double double0 = naiveBayesMultinomialText0.m_lnorm;
      assertEquals(2.0, double0, 0.01);
      
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("");
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string2 = naiveBayesMultinomialText1.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string2);
      
      String string3 = naiveBayesMultinomialText1.normTipText();
      assertEquals("The norm of the instances after normalization.", string3);
      
      String string4 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string4);
      
      naiveBayesMultinomialText1.getLowercaseTokens();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      String string5 = naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string5);
      
      String string6 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string6);
      
      naiveBayesMultinomialText0.setStopwords((File) null);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 39
  /*Coverage entropy=2.7787755691845217
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.LNormTipText();
      Stopwords stopwords0 = naiveBayesMultinomialText0.m_stopwords;
      naiveBayesMultinomialText0.setUseStopList(true);
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      double double0 = naiveBayesMultinomialText0.m_lnorm;
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("");
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.toString();
      LMT lMT0 = new LMT();
      Capabilities capabilities0 = lMT0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      BallNode.calcCentroidPivot(100, (-553), (int[]) null, instances0);
      System.setCurrentTimeMillis((-553));
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 40
  /*Coverage entropy=2.5531257522061517
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(true);
      String[] stringArray0 = new String[0];
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getLowercaseTokens();
      boolean boolean0 = false;
      SparseInstance sparseInstance0 = null;
      try {
        sparseInstance0 = new SparseInstance((-3607));
        fail("Expecting exception: NegativeArraySizeException");
      
      } catch(NegativeArraySizeException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.SparseInstance", e);
      }
  }

  /**
  //Test case number: 41
  /*Coverage entropy=2.839938278694673
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      String[] stringArray0 = new String[6];
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (-45.0);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      stringArray0[0] = ":&eY|o`4FISHZ*QLH";
      stringArray0[1] = "CreGE7;n3jr\"-";
      stringArray0[2] = "_>6H9nCPdo3jU#PR:";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      stringArray0[3] = "'b";
      stringArray0[4] = "";
      stringArray0[5] = "DP";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, ")OxGYz]Om");
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 42
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_normalize = true;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances((String) null, arrayList0, 175);
      Capabilities capabilities0 = Capabilities.forInstances(instances0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      TestInstances testInstances1 = new TestInstances();
      Instances instances1 = testInstances0.generate();
      ArrayList<Attribute> arrayList1 = new ArrayList<Attribute>();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 175;
      doubleArray0[1] = (double) 175;
      BallTree ballTree0 = new BallTree(instances1);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(175);
      int[] intArray0 = new int[2];
      intArray0[0] = 78;
      intArray0[1] = (-2);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(78, intArray0, 175);
      Random.setNextRandom((-2));
  }

  /**
  //Test case number: 43
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[6];
      intArray0[1] = (-7);
      intArray0[2] = 173;
      TestInstances testInstances0 = new TestInstances();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer(" ");
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      testInstances0.generate();
      SystemInUtil.addInputLine("@data");
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      
      String string1 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 44
  /*Coverage entropy=2.108838365573966
  */
  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[12];
      stringArray0[4] = "ML";
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      testInstances0.setNumRelationalString(596);
      SystemInUtil.addInputLine("The tree has not been supplied with a set of instances or getDistances() has been called before calling kNearestNeighbours().");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      Random.setNextRandom((-2));
  }
}
