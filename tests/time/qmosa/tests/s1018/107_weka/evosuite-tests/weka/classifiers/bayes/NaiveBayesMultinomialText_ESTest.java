/*
 * This file was automatically generated by EvoSuite
 * Wed Dec 04 03:21:19 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.attributeSelection.ASEvaluation;
import weka.attributeSelection.CfsSubsetEval;
import weka.attributeSelection.InfoGainAttributeEval;
import weka.attributeSelection.OneRAttributeEval;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.bayes.net.BIFReader;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.lazy.IBk;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.misc.InputMappedClassifier;
import weka.classifiers.rules.DecisionTable;
import weka.classifiers.rules.M5Rules;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.neighboursearch.BallTree;
import weka.core.neighboursearch.CoverTree;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.filters.supervised.attribute.Discretize;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.902406279863188
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "H0bxHRMZLa$k-S}G[");
      SystemInUtil.addInputLine("");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      Stemmer stemmer0 = sGDText0.getStemmer();
      naiveBayesMultinomialText0.m_stemmer = stemmer0;
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.stopwordsTipText();
      sGDText0.setEpochs((-17));
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      System.setCurrentTimeMillis(0);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.globalInfo();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      PrincipalComponents principalComponents1 = new PrincipalComponents();
      CoverTree coverTree0 = new CoverTree();
      try { 
        coverTree0.kNearestNeighbours((Instance) null, 4034);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=3.1390740212066346
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      naiveBayesMultinomialText0.setNorm((-1033.56638));
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      naiveBayesMultinomialText0.toString();
      doubleArray0[0] = (-1033.56638);
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      naiveBayesMultinomialText0.m_stemmer = null;
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.normTipText();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      SparseInstance sparseInstance0 = new SparseInstance((Instance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText1.distributionForInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 2
  /*Coverage entropy=1.5981863871455346
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0E-75;
      doubleArray0[1] = 1.0E-75;
      doubleArray0[2] = 1.0E-75;
      doubleArray0[3] = 1.0E-75;
      doubleArray0[4] = 1.0E-75;
      SparseInstance sparseInstance0 = new SparseInstance(1.0E-75, doubleArray0);
      naiveBayesMultinomialText0.setPeriodicPruning(1110);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance1);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=3.1706151297490246
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      AbstractClassifier.makeCopies(naiveBayesMultinomialText0, 68);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      DenseInstance denseInstance0 = new DenseInstance(11);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) denseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.7746000829682944
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      DecisionTable decisionTable0 = new DecisionTable();
      String[] stringArray0 = null;
      AbstractClassifier.runClassifier(decisionTable0, (String[]) null);
      AbstractClassifier.runClassifier(decisionTable0, (String[]) null);
      DenseInstance denseInstance0 = new DenseInstance(68);
      DenseInstance denseInstance1 = new DenseInstance(denseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(6);
      denseInstance0.insertAttributeAt(4);
      DenseInstance denseInstance2 = new DenseInstance(denseInstance1);
      CfsSubsetEval cfsSubsetEval0 = new CfsSubsetEval();
      ASEvaluation.runEvaluator(cfsSubsetEval0, (String[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setTokenizer((Tokenizer) null);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.getOptions();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=2.63263049877407
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setOptions((String[]) null);
      System.setCurrentTimeMillis(0L);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=2.5500249372732666
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      DecisionTable decisionTable0 = new DecisionTable();
      AbstractClassifier.runClassifier(decisionTable0, (String[]) null);
      AbstractClassifier.runClassifier(decisionTable0, (String[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 4;
      doubleArray0[1] = (double) 2;
      doubleArray0[2] = 9.223372036854776E18;
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      doubleArray0[3] = 2250.0654967;
      SparseInstance sparseInstance0 = new SparseInstance((-2942.4827269499087), doubleArray0);
      FileSystemHandling.shouldAllThrowIOExceptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setOptions((String[]) null);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(sparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 7
  /*Coverage entropy=2.688514447186191
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = (-10.0);
      doubleArray0[2] = (-1459.78709900131);
      doubleArray0[3] = 0.0;
      doubleArray0[4] = 0.0;
      doubleArray0[5] = 1.0;
      doubleArray0[6] = 0.0;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.setTokenizer((Tokenizer) null);
      BIFReader bIFReader0 = new BIFReader();
      BIFReader bIFReader1 = new BIFReader();
      bIFReader1.missingArcs(bIFReader0);
      bIFReader1.measureDivergence();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)60;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.LNormTipText();
      File file0 = MockFile.createTempFile("The LNorm to use for document length normalization.", "The LNorm to use for document length normalization.", (File) null);
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.globalInfo();
      System.setCurrentTimeMillis(0);
      naiveBayesMultinomialText0.getRevision();
      CoverTree coverTree0 = new CoverTree();
      BallTree ballTree0 = new BallTree((Instances) null);
      try { 
        ballTree0.nearestNeighbour((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.BallTree", e);
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=2.782775889348351
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      BIFReader bIFReader0 = new BIFReader();
      bIFReader0.setUseADTree(true);
      BIFReader bIFReader1 = new BIFReader();
      bIFReader0.missingArcs(bIFReader1);
      Integer integer0 = new Integer(0);
      BIFReader bIFReader2 = new BIFReader();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      assertSame(tokenizer0, wordTokenizer0);
      
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(9.223372036854776E18, doubleArray0);
      naiveBayesMultinomialText0.tokenizeInstance(sparseInstance0, false);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.tokenizeInstance(sparseInstance0, false);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.7914234446919735
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.setTokenizer((Tokenizer) null);
      BIFReader bIFReader0 = new BIFReader();
      BIFReader bIFReader1 = new BIFReader();
      bIFReader1.missingArcs(bIFReader0);
      bIFReader1.measureDivergence();
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)60;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.LNormTipText();
      File file0 = MockFile.createTempFile("The LNorm to use for document length normalization.", "The LNorm to use for document length normalization.", (File) null);
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.globalInfo();
      System.setCurrentTimeMillis(0);
  }

  /**
  //Test case number: 10
  /*Coverage entropy=2.4466856169199285
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[1] = ")S";
      stringArray0[2] = "";
      stringArray0[3] = "";
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setStopwords((File) null);
      naiveBayesMultinomialText0.globalInfo();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      M5Rules m5Rules0 = new M5Rules();
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("Expected upper bound in range, found: ");
      try { 
        naiveBayesMultinomialText1.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Cannot handle numeric class!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=2.492686218411152
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      String[] stringArray1 = new String[7];
      stringArray1[0] = "W*";
      stringArray1[1] = "dNf;|_IYKw^|GE+<";
      stringArray1[2] = "dNf;|_IYKw^|GE+<";
      stringArray1[3] = "";
      stringArray1[4] = "";
      stringArray1[5] = "dNf;|_IYKw^|GE+<";
      stringArray1[6] = "";
      naiveBayesMultinomialText0.setOptions(stringArray1);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 12
  /*Coverage entropy=2.297687147780183
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      naiveBayesMultinomialText0.m_lnorm = 0.0;
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setStopwords((File) null);
      assertEquals(0.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 13
  /*Coverage entropy=0.9623351446188083
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      byte[] byteArray0 = new byte[2];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      byteArray0[0] = (byte)68;
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      byteArray0[1] = (byte) (-4);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=2.209406559005219
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      byte[] byteArray0 = new byte[4];
      byteArray0[0] = (byte)79;
      byteArray0[1] = (byte) (-60);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      byteArray0[2] = (byte) (-28);
      byteArray0[3] = (byte)112;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_t = 0.0;
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      naiveBayesMultinomialText0.setPeriodicPruning(80);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 15
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      byte[] byteArray0 = new byte[2];
      byte byte0 = (byte)68;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = (double) (byte)68;
      doubleArray0[1] = (double) (byte)68;
      doubleArray0[2] = (double) (byte)68;
      doubleArray0[3] = (double) (byte)68;
      doubleArray0[4] = (double) (byte)68;
      doubleArray0[5] = (double) (byte)68;
      DenseInstance denseInstance0 = new DenseInstance((byte)68, doubleArray0);
      DenseInstance denseInstance1 = new DenseInstance(denseInstance0);
      DenseInstance denseInstance2 = new DenseInstance(denseInstance1);
      denseInstance0.copy();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 16
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[1] = ")S";
      stringArray0[2] = "";
      stringArray0[3] = "";
      byte[] byteArray0 = new byte[7];
      byteArray0[0] = (byte)64;
      byteArray0[1] = (byte)5;
      byteArray0[2] = (byte)6;
      byteArray0[3] = (byte)51;
      NullStemmer nullStemmer0 = (NullStemmer)naiveBayesMultinomialText0.m_stemmer;
      naiveBayesMultinomialText0.setStemmer(nullStemmer0);
      byteArray0[4] = (byte)0;
      byteArray0[5] = (byte)30;
      byteArray0[6] = (byte)57;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 17
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      DenseInstance denseInstance0 = new DenseInstance(45);
      DenseInstance denseInstance1 = new DenseInstance(denseInstance0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(110);
      InfoGainAttributeEval infoGainAttributeEval0 = new InfoGainAttributeEval();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "og__(DOU*4";
      stringArray0[1] = "og__(DOU*4";
      ASEvaluation.runEvaluator(infoGainAttributeEval0, stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(110, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      int[] intArray0 = new int[5];
      intArray0[0] = 39;
      intArray0[1] = 6;
      intArray0[2] = 86;
      intArray0[3] = 45;
      intArray0[4] = 6;
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(45, intArray0, 45);
      try { 
        naiveBayesMultinomialText0.updateClassifier(denseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 18
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      
      IBk iBk0 = new IBk((-587));
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      naiveBayesMultinomialText0.pruneDictionary();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (double) 1;
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.setStopwords((File) null);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 19
  /*Coverage entropy=2.1290003949677563
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      byte[] byteArray0 = new byte[7];
      byteArray0[0] = (byte) (-1);
      byteArray0[1] = (byte)30;
      byteArray0[2] = (byte)110;
      byteArray0[3] = (byte)95;
      byteArray0[4] = (byte)1;
      byteArray0[5] = (byte)48;
      byteArray0[6] = (byte)24;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      costSensitiveClassifier0.toString();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      naiveBayesMultinomialText0.setStopwords(file0);
      String string1 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string1);
      
      String string2 = naiveBayesMultinomialText0.stopwordsTipText();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string2);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.297687147780183
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_lnorm = 0.0;
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.m_lnorm = (-3277.910059999902);
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setStopwords((File) null);
      assertEquals((-3277.910059999902), naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.listOptions();
      assertEquals(0.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 22
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("XN<,$Ug#\"{5f0zaN'");
      naiveBayesMultinomialText0.setLNorm((-1467.0));
      int int0 = 0;
      // Undeclared exception!
      try { 
        Instances.mergeInstances(instances0, instances0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Attribute names are not unique! Causes: 'XN<,$Ug#\"{5f0zaN'Nominal1' 'XN<,$Ug#\"{5f0zaN'Class' 
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 23
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.reset();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 24
  /*Coverage entropy=3.4395082641515833
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      DecisionTable decisionTable0 = new DecisionTable();
      AbstractClassifier.runClassifier(decisionTable0, (String[]) null);
      AbstractClassifier.runClassifier(decisionTable0, (String[]) null);
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      String string1 = naiveBayesMultinomialText0.getRevision();
      assertEquals("9122", string1);
      
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte) (-2);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(12, stringArray0.length);
      
      System.setCurrentTimeMillis((-425L));
      String string2 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string2);
      
      String string3 = naiveBayesMultinomialText0.normTipText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", string3);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 25
  /*Coverage entropy=3.3574036981168276
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      byte[] byteArray0 = new byte[2];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      byteArray0[0] = (byte)68;
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(12, stringArray0.length);
      
      System.setCurrentTimeMillis((-1431L));
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      
      String string1 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string1);
      
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, double0, 0.01);
  }

  /**
  //Test case number: 26
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      Tokenizer tokenizer0 = sGDText0.getTokenizer();
      naiveBayesMultinomialText0.m_lowercaseTokens = false;
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      naiveBayesMultinomialText0.setPeriodicPruning((-381));
      assertEquals((-381), naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 27
  /*Coverage entropy=3.0497978423100225
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.listOptions();
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "If true, ignores all words that are on the stoplist.";
      stringArray0[1] = "Use word frequencies rather than binary bag of words representation";
      stringArray0[2] = "Use word frequencies rather than binary bag of words representation";
      stringArray0[3] = "Use word frequencies rather than binary bag of words representation";
      stringArray0[4] = "Specify the number of attributes to retain. The default value (-1) indicates that all attributes are to be retained. Use either this option or a threshold to reduce the attribute set.";
      stringArray0[5] = "If true, ignores all words that are on the stoplist.";
      stringArray0[6] = "If true, ignores all words that are on the stoplist.";
      stringArray0[7] = "Use word frequencies rather than binary bag of words representation";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, double0, 0.01);
  }

  /**
  //Test case number: 28
  /*Coverage entropy=3.2737397514782507
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      naiveBayesMultinomialText0.setNorm((-1033.56638));
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      naiveBayesMultinomialText0.toString();
      doubleArray0[0] = (-1033.56638);
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      naiveBayesMultinomialText0.m_stemmer = null;
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.normTipText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[1] = "The norm of the instances after normalization.";
      stringArray0[2] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[3] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[4] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[5] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[6] = "The norm of the instances after normalization.";
      stringArray0[7] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[8] = "If true then document length is normalized according to the settings for norm and lnorm";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals((-1033.56638), naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 29
  /*Coverage entropy=3.128051039802716
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.m_t = (-327.40976914);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.m_useStopList = false;
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.setLNorm(1.0);
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
      
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      Discretize discretize0 = new Discretize();
      // Undeclared exception!
      try { 
        discretize0.output();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // No output instance format defined
         //
         verifyException("weka.filters.Filter", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      naiveBayesMultinomialText0.setMinWordFrequency(1324.72);
      stringArray0[1] = ")S";
      stringArray0[2] = "";
      stringArray0[3] = "";
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals(1324.72, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 31
  /*Coverage entropy=3.2990745085122564
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      naiveBayesMultinomialText0.getOptions();
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "");
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      BIFReader bIFReader0 = new BIFReader();
      bIFReader0.measureExtraArcs();
      BIFReader bIFReader1 = new BIFReader();
      bIFReader0.missingArcs(bIFReader1);
      Integer integer0 = new Integer(0);
      BIFReader bIFReader2 = new BIFReader();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(9.223372036854776E18, doubleArray0);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.tokenizeInstance(sparseInstance0, false);
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 32
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      BIFReader bIFReader0 = new BIFReader();
      bIFReader0.measureExtraArcs();
      BIFReader bIFReader1 = new BIFReader();
      bIFReader0.missingArcs(bIFReader1);
      Integer integer0 = new Integer(0);
      BIFReader bIFReader2 = new BIFReader();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      assertSame(tokenizer0, wordTokenizer0);
      
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(9.223372036854776E18, doubleArray0);
      System.setCurrentTimeMillis((-577L));
      String string1 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 33
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[1] = ")S";
      stringArray0[2] = "";
      String string0 = naiveBayesMultinomialText0.getRevision();
      assertEquals("9122", string0);
      
      String string1 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string1);
      
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(2.0, double0, 0.01);
      
      String string2 = naiveBayesMultinomialText0.globalInfo();
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string2);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      byte[] byteArray0 = new byte[4];
      byteArray0[0] = (byte)49;
      byteArray0[1] = (byte)68;
      byteArray0[2] = (byte)91;
      byteArray0[3] = (byte)0;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, double0, 0.01);
  }

  /**
  //Test case number: 35
  /*Coverage entropy=3.3421244401066743
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      DecisionTable decisionTable0 = new DecisionTable();
      AbstractClassifier.runClassifier(decisionTable0, (String[]) null);
      AbstractClassifier.runClassifier(decisionTable0, (String[]) null);
      OneRAttributeEval oneRAttributeEval0 = new OneRAttributeEval();
      AbstractClassifier.runClassifier(decisionTable0, (String[]) null);
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray0.length);
      
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte) (-2);
      byteArray0[1] = (byte) (-2);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setOptions((String[]) null);
      System.setCurrentTimeMillis(4960L);
      String string1 = naiveBayesMultinomialText1.tokenizerTipText();
      assertFalse(naiveBayesMultinomialText1.getLowercaseTokens());
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText1.getUseStopList());
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      
      String string2 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string2);
      
      naiveBayesMultinomialText0.getLowercaseTokens();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 36
  /*Coverage entropy=3.3994042323820763
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      BIFReader bIFReader0 = new BIFReader();
      BIFReader bIFReader1 = new BIFReader();
      bIFReader1.getTechnicalInformation();
      bIFReader0.missingArcs(bIFReader1);
      bIFReader0.measureDivergence();
      BIFReader bIFReader2 = new BIFReader();
      WordTokenizer wordTokenizer1 = new WordTokenizer();
      naiveBayesMultinomialText0.LNormTipText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      
      naiveBayesMultinomialText0.setNorm(3.0);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      System.setCurrentTimeMillis(0L);
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 37
  /*Coverage entropy=1.847832822658352
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "{Gb$x$W]SbSe%oeL";
      stringArray0[1] = "fP;Bh";
      stringArray0[2] = "";
      stringArray0[3] = "XYZd^";
      NaiveBayesMultinomialText.main(stringArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(139);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 38
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-lowercase";
      stringArray0[1] = "-stemmer";
      stringArray0[2] = "Ty$_C+9^Z5";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }
}
