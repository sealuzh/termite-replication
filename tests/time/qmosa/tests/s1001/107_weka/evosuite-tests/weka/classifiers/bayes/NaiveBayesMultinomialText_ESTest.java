/*
 * This file was automatically generated by EvoSuite
 * Tue Dec 03 14:58:56 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import java.util.Vector;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayes;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.supportVector.Kernel;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.lazy.IBk;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.misc.SerializedClassifier;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.FindWithCapabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.neighboursearch.BallTree;
import weka.core.stemmers.IteratedLovinsStemmer;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.AlphabeticTokenizer;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=3.118927840978749
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useStopListTipText();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      Kernel.makeCopy(precomputedKernelMatrixKernel0);
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "If true, ignores all words that are on the stoplist.");
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getNorm();
      precomputedKernelMatrixKernel0.getCapabilities();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 1.0;
      doubleArray0[1] = (-621.3209372187256);
      doubleArray0[2] = (-621.3209372187256);
      doubleArray0[3] = (-4659.4096604240585);
      doubleArray0[4] = 1.0;
      doubleArray0[5] = (-621.3209372187256);
      doubleArray0[6] = (-621.3209372187256);
      doubleArray0[7] = 1.0;
      doubleArray0[8] = (-621.3209372187256);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-621.3209372187256), doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      try { 
        principalComponents0.convertInstance(sparseInstance0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // convertInstance: Principal components not built yet
         //
         verifyException("weka.attributeSelection.PrincipalComponents", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=2.90942593493926
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.reset();
      double[] doubleArray0 = new double[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1394.063, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      ArrayList<String> arrayList0 = new ArrayList<String>();
      ArrayList<Locale.LanguageRange> arrayList1 = new ArrayList<Locale.LanguageRange>();
      SGDText sGDText0 = new SGDText();
      SGDText sGDText1 = new SGDText();
      sGDText1.getStopwords();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      costSensitiveClassifier0.distributionForInstance(binarySparseInstance1);
      MockFile mockFile0 = new MockFile(file0, "");
      MockFile mockFile1 = new MockFile(mockFile0, "");
      naiveBayesMultinomialText0.setStopwords((File) null);
      System.setCurrentTimeMillis((-3013L));
      Random.setNextRandom(0);
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.2891901844336733
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      Capabilities capabilities1 = capabilities0.getAttributeCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities1);
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      double[] doubleArray0 = new double[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1), doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(6, doubleArray0);
      capabilities1.assign(capabilities0);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      naiveBayesMultinomialText0.m_lnorm = 3120.66550439;
      ArrayList<String> arrayList0 = new ArrayList<String>();
      FileSystemHandling.shouldAllThrowIOExceptions();
      ArrayList<Locale.LanguageRange> arrayList1 = new ArrayList<Locale.LanguageRange>();
      arrayList0.removeAll(arrayList1);
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.AUTOSELECT_FILTERING;
      Locale.filterTags((List<Locale.LanguageRange>) arrayList1, (Collection<String>) arrayList0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("@data", arrayList0);
      SGDText sGDText0 = new SGDText();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file0 = serializedClassifier0.getModelFile();
      file0.setExecutable(true, true);
      MockFile mockFile0 = new MockFile(file0, " ");
      naiveBayesMultinomialText0.setStopwords(file0);
      System.setCurrentTimeMillis((-2785L));
      naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 3
  /*Coverage entropy=1.543056733112554
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = (-52.0);
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "Michael I. Jordan and Michael J. Kearns and Sara A. Solla");
      naiveBayesMultinomialText0.toString();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getNorm();
      NaiveBayes naiveBayes0 = new NaiveBayes();
      Instances instances0 = naiveBayes0.m_Instances;
      int int0 = 1;
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (-52.0);
      doubleArray0[1] = (-52.0);
      doubleArray0[2] = (double) 1;
      doubleArray0[3] = (double) 1;
      doubleArray0[4] = (-52.0);
      doubleArray0[5] = (-52.0);
      doubleArray0[6] = (-52.0);
      int[] intArray0 = new int[3];
      intArray0[0] = 1;
      intArray0[1] = 1;
      intArray0[2] = 1;
      SparseInstance sparseInstance0 = null;
      try {
        sparseInstance0 = new SparseInstance((-52.0), doubleArray0, intArray0, 1);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 3
         //
         verifyException("weka.core.SparseInstance", e);
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=3.0587557763626614
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_stemmer = null;
      String string1 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      naiveBayesMultinomialText0.getUseWordFrequencies();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[1] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[2] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[3] = "The tokenizing algorithm to use on the strings.";
      stringArray0[4] = "NaiveBayesMultinomialText: No model built yet.\n";
      String string2 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string2);
      
      naiveBayesMultinomialText0.getOptions();
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      assertEquals(10, stringArray1.length);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.pruneDictionary();
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText1.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 5
  /*Coverage entropy=3.172243352272769
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_stemmer = null;
      naiveBayesMultinomialText0.tokenizerTipText();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getPeriodicPruning();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.stopwordsTipText();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText1.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText1.getLowercaseTokens();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = 4.9E-324;
      doubleArray0[1] = (-870.586686);
      int[] intArray0 = new int[1];
      intArray0[0] = 12;
      SparseInstance sparseInstance0 = null;
      try {
        sparseInstance0 = new SparseInstance(1.0, doubleArray0, intArray0, 12);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 1
         //
         verifyException("weka.core.SparseInstance", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=2.7244547079196284
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      byte[] byteArray0 = new byte[8];
      byteArray0[0] = (byte)7;
      byteArray0[1] = (byte)116;
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.stopwordsTipText();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.stopwordsTipText();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (-1301.201);
      doubleArray0[1] = (double) 0;
      doubleArray0[2] = (double) (byte)116;
      doubleArray0[3] = 1.0;
      doubleArray0[4] = (double) (byte)7;
      int[] intArray0 = new int[5];
      intArray0[0] = (int) (byte)1;
      intArray0[1] = (int) (byte)7;
      intArray0[2] = 0;
      intArray0[3] = (int) (byte)116;
      intArray0[4] = 0;
      SparseInstance sparseInstance0 = new SparseInstance(3248.3720730176015, doubleArray0, intArray0, (-1));
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 7
  /*Coverage entropy=0.9623351446188083
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=3.334502545267738
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.m_minWordP = (-522.624719760915);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.m_wordFrequencies = false;
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.pruneDictionary();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = 4.9E-324;
      doubleArray0[1] = 1.0;
      doubleArray0[2] = 1.0;
      doubleArray0[3] = (double) 0;
      doubleArray0[4] = (-522.624719760915);
      doubleArray0[5] = (double) 0;
      doubleArray0[6] = (double) 0;
      int[] intArray0 = new int[7];
      intArray0[0] = 0;
      intArray0[1] = 0;
      intArray0[2] = 0;
      intArray0[3] = 0;
      intArray0[4] = 0;
      intArray0[5] = 0;
      intArray0[6] = 0;
      SparseInstance sparseInstance0 = new SparseInstance(1.0, doubleArray0, intArray0, 12);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=3.28612151380348
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.m_minWordP = (-522.624719760915);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.pruneDictionary();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, false);
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = 4.9E-324;
      doubleArray0[1] = 1.0;
      doubleArray0[2] = 1.0;
      doubleArray0[3] = (double) 0;
      doubleArray0[4] = (-522.624719760915);
      doubleArray0[5] = (double) 0;
      doubleArray0[6] = (double) 0;
      int[] intArray0 = new int[7];
      intArray0[0] = 0;
      intArray0[1] = 0;
      intArray0[2] = 0;
      intArray0[3] = 0;
      intArray0[4] = 0;
      intArray0[5] = 0;
      intArray0[6] = 0;
      SparseInstance sparseInstance0 = new SparseInstance(1.0, doubleArray0, intArray0, 12);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=3.29681878647832
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.setPeriodicPruning(16);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals(16, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 11
  /*Coverage entropy=3.5656488901063708
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_stemmer = null;
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      naiveBayesMultinomialText0.getUseWordFrequencies();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[1] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[2] = "The tokenizing algorithm to use on the strings.";
      stringArray0[3] = "The tokenizing algorithm to use on the strings.";
      stringArray0[4] = "NaiveBayesMultinomialText: No model built yet.\n";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.setPeriodicPruning(2744);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getPeriodicPruning();
      int int0 = naiveBayesMultinomialText0.getPeriodicPruning();
      assertEquals(2744, int0);
  }

  /**
  //Test case number: 12
  /*Coverage entropy=3.194996186179526
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = (double) 0;
      doubleArray0[1] = (double) 2125;
      doubleArray0[2] = (double) 864;
      doubleArray0[3] = (double) 0;
      doubleArray0[4] = 0.0;
      naiveBayesMultinomialText0.m_leplace = 2021.50260859474;
      doubleArray0[5] = (double) 0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(109, doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(0.0, doubleArray0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      ArrayList<String> arrayList0 = new ArrayList<String>();
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.debugTipText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray0.length);
      
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, double0, 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 13
  /*Coverage entropy=3.608719287938979
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_stemmer = null;
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.normTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setPeriodicPruning(10000);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText1.lowercaseTokensTipText();
      naiveBayesMultinomialText1.getNorm();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.getPeriodicPruning();
      File file0 = MockFile.createTempFile("The stemming algorithm to use on the words.", (String) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText3.setStopwords(file0);
      assertTrue(naiveBayesMultinomialText3.getUseStopList());
  }

  /**
  //Test case number: 14
  /*Coverage entropy=3.4305796491377345
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[7];
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.getUseWordFrequencies();
      NullStemmer nullStemmer0 = new NullStemmer();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "{.~rB[nGLi@'`Xhh6";
      stringArray0[1] = "The tokenizing algorithm to use on the strings.";
      stringArray0[2] = "The tokenizing algorithm to use on the strings.";
      stringArray0[3] = "The tokenizing algorithm to use on the strings.";
      stringArray0[4] = "{.~rB[nGLi@'`Xhh6";
      stringArray0[5] = "j4)H@<FgZ*\"";
      stringArray0[6] = "{.~rB[nGLi@'`Xhh6";
      stringArray0[7] = "The tokenizing algorithm to use on the strings.";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.setPeriodicPruning(1512);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.getPeriodicPruning();
      naiveBayesMultinomialText1.setOptions(stringArray0);
      naiveBayesMultinomialText1.getPeriodicPruning();
      naiveBayesMultinomialText0.toString();
      assertEquals(1512, naiveBayesMultinomialText0.getPeriodicPruning());
      
      String string0 = naiveBayesMultinomialText1.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string0);
  }

  /**
  //Test case number: 15
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "normalize";
      stringArray0[1] = "normalize";
      stringArray0[2] = "8YlRz";
      stringArray0[5] = "public class WekaWrapper\n";
      stringArray0[4] = "p;'M^9S-8";
      stringArray0[5] = "YJSW";
      stringArray0[6] = "p;'M^9S-8";
      stringArray0[7] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 16
  /*Coverage entropy=3.1702033153336044
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray0.length);
      
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_stemmer = null;
      String string1 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertFalse(boolean0);
      
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      String[] stringArray1 = new String[6];
      stringArray1[0] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray1[1] = "{.~rB[nGLi@'`Xhh6";
      stringArray1[3] = "The tokenizing algorithm to use on the strings.";
      MockFile mockFile0 = new MockFile("weka.classifiers.functions.SimpleLinearRegression");
      File file0 = MockFile.createTempFile("8S\"~<%", "%ZZ`DFo", (File) mockFile0);
      MockFile mockFile1 = new MockFile(file0, "{.~rB[nGLi@'`Xhh6");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      String string2 = naiveBayesMultinomialText0.normTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("The norm of the instances after normalization.", string2);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 17
  /*Coverage entropy=3.2458473814062927
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.m_minWordP = (-522.624719760915);
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.getOptions();
      double[] doubleArray0 = new double[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1.0, doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(1.0, doubleArray0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      ArrayList<String> arrayList0 = new ArrayList<String>();
      ArrayList<Locale.LanguageRange> arrayList1 = new ArrayList<Locale.LanguageRange>();
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.debugTipText();
      assertEquals((-522.624719760915), naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 18
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (-768.08);
      naiveBayesMultinomialText0.listOptions();
      doubleArray0[1] = 2397.8763;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.m_normalize = false;
      String string0 = null;
      naiveBayesMultinomialText0.m_norm = 1981.5641422571607;
      MockFile mockFile0 = null;
      try {
        mockFile0 = new MockFile((String) null, (String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.evosuite.runtime.mock.java.io.MockFile", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=3.482275096105515
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.tokenizerTipText();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      naiveBayesMultinomialText1.getUseWordFrequencies();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "If true, ignores all words that are on the stoplist.";
      stringArray0[1] = "The file containing the stopwords (if this is a directory then the default ones are used).";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText1.normTipText();
      naiveBayesMultinomialText1.setPeriodicPruning((-100));
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText1.lowercaseTokensTipText();
      naiveBayesMultinomialText1.getNorm();
      assertEquals((-100), naiveBayesMultinomialText1.getPeriodicPruning());
      
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.globalInfo();
      naiveBayesMultinomialText2.normalizeDocLengthTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText3.getPeriodicPruning();
      naiveBayesMultinomialText2.setOptions(stringArray0);
      naiveBayesMultinomialText3.getPeriodicPruning();
      naiveBayesMultinomialText0.toString();
      String string0 = naiveBayesMultinomialText2.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
  }

  /**
  //Test case number: 20
  /*Coverage entropy=1.7214787039105834
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      byte[] byteArray0 = new byte[8];
      byteArray0[1] = (byte)116;
      byteArray0[2] = (byte)1;
      byteArray0[3] = (byte)14;
      byteArray0[4] = (byte)9;
      byteArray0[5] = (byte)10;
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      costSensitiveClassifier0.getOnDemandDirectory();
      MockFile mockFile0 = new MockFile(file0, "]E`kaVB5Q");
      MockFile mockFile1 = new MockFile(mockFile0, "fSGq} #o<<tzMo-q");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      System.setCurrentTimeMillis(486L);
      try { 
        naiveBayesMultinomialText0.distributionForInstance((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.setMinWordFrequency(645.976769);
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      costSensitiveClassifier0.getCostMatrix();
      IBk iBk0 = new IBk();
      TestInstances testInstances0 = new TestInstances();
      // Undeclared exception!
      try { 
        testInstances0.getRelationalFormat(1);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 1
         //
         verifyException("weka.core.TestInstances", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=3.0514474029629954
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setNorm((-2154.21249004));
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getLNorm();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.getUseStopList();
      Instance instance0 = null;
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 23
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      SparseInstance sparseInstance0 = new SparseInstance(0);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("then");
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.getMinWordFrequency();
      double[] doubleArray0 = new double[4];
      doubleArray0[1] = (double) 6;
      doubleArray0[2] = (double) 6;
      int[] intArray0 = new int[5];
      intArray0[0] = 12;
      intArray0[4] = 0;
      SparseInstance sparseInstance1 = new SparseInstance((-1753.42159492982), doubleArray0, intArray0, 12);
      System.setCurrentTimeMillis(6);
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.96321798534069
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.reset();
      double[] doubleArray0 = new double[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1394.063, doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      ArrayList<String> arrayList0 = new ArrayList<String>();
      naiveBayesMultinomialText0.toString();
      arrayList0.add("");
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.REJECT_EXTENDED_RANGES;
      ArrayList<Locale.LanguageRange> arrayList1 = new ArrayList<Locale.LanguageRange>();
      Locale.filterTags((List<Locale.LanguageRange>) arrayList1, (Collection<String>) arrayList0, locale_FilteringMode0);
      binarySparseInstance0.copy();
      int[] intArray0 = new int[6];
      SparseInstance sparseInstance1 = new SparseInstance(6, doubleArray0, intArray0, 0);
      naiveBayesMultinomialText0.getLowercaseTokens();
      SparseInstance sparseInstance2 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance2);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      byte[] byteArray0 = new byte[8];
      byteArray0[0] = (byte)7;
      byteArray0[1] = (byte)116;
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.ONLY_MULTIINSTANCE;
      findWithCapabilities0.enableNot(capabilities_Capability0);
      Vector<String> vector0 = findWithCapabilities0.find();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.REJECT_EXTENDED_RANGES;
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Capabilities.props");
      FileSystemHandling.createFolder(evoSuiteFile0);
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Locale.FilteringMode locale_FilteringMode1 = Locale.FilteringMode.REJECT_EXTENDED_RANGES;
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) list0, locale_FilteringMode1);
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      File file1 = costSensitiveClassifier0.getOnDemandDirectory();
      MockFile mockFile0 = new MockFile(file1, "-class-index <num>");
      MockFile mockFile1 = new MockFile(mockFile0, "\"(B");
      naiveBayesMultinomialText0.setStopwords(file0);
      System.setCurrentTimeMillis(486L);
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      
      naiveBayesMultinomialText0.listOptions();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 26
  /*Coverage entropy=3.297279708899315
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setPeriodicPruning(16);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.useStopListTipText();
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      byte[] byteArray0 = new byte[8];
      byteArray0[0] = (byte)7;
      byteArray0[1] = (byte)116;
      byteArray0[3] = (byte)1;
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.ONLY_MULTIINSTANCE;
      findWithCapabilities0.enableNot(capabilities_Capability0);
      Vector<String> vector0 = findWithCapabilities0.find();
      findWithCapabilities0.setHandler(naiveBayesMultinomialText0);
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.REJECT_EXTENDED_RANGES;
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      MockFile mockFile0 = new MockFile(file0, "\"(B");
      naiveBayesMultinomialText0.setStopwords(file0);
      System.setCurrentTimeMillis((byte)7);
      String string0 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string0);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 28
  /*Coverage entropy=3.2461447349596675
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "normalize";
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      alphabeticTokenizer0.getOptions();
      naiveBayesMultinomialText0.setTokenizer(alphabeticTokenizer0);
      stringArray0[1] = "";
      stringArray0[2] = "8YlRz";
      stringArray0[3] = "public class WekaWrapper\n";
      stringArray0[4] = "p;'M^9S-8";
      stringArray0[5] = "YJSW";
      stringArray0[6] = "c~\"UOkRgw";
      stringArray0[7] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[8] = ".xQV";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      
      naiveBayesMultinomialText0.m_lowercaseTokens = false;
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray1.length);
      
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, double0, 0.01);
  }

  /**
  //Test case number: 29
  /*Coverage entropy=3.2458473814062927
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "normalize";
      stringArray0[1] = "";
      stringArray0[2] = "8YlRz";
      stringArray0[3] = "public class WekaWrapper\n";
      stringArray0[4] = "p;'M^9S-8";
      naiveBayesMultinomialText0.m_leplace = (-6303.67295);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      stringArray0[5] = "YJSW";
      stringArray0[6] = "c~\"UOkRgw";
      stringArray0[7] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[8] = ".xQV";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      
      naiveBayesMultinomialText0.m_lowercaseTokens = false;
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray1.length);
      
      File file0 = naiveBayesMultinomialText0.getStopwords();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals("107_weka", file0.getName());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 30
  /*Coverage entropy=2.8403086265802937
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray0.length);
      
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_stemmer = null;
      File file0 = MockFile.createTempFile("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification");
      MockFile mockFile0 = new MockFile(file0, "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.getStopwords();
      int[] intArray0 = new int[6];
      intArray0[1] = 718;
      intArray0[2] = (-348);
      intArray0[3] = (-3006);
      intArray0[4] = 1;
      intArray0[5] = (-2993);
      File file1 = naiveBayesMultinomialText0.getStopwords();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(file1.canExecute());
  }

  /**
  //Test case number: 31
  /*Coverage entropy=3.5434225061008373
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setNorm((-2154.21249004));
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getLNorm();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.getLowercaseTokens();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "";
      stringArray0[1] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[2] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[3] = "\tThe name of the data set.";
      stringArray0[4] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[5] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[6] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[7] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.normTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setPeriodicPruning(0);
      naiveBayesMultinomialText1.setOptions(stringArray0);
      naiveBayesMultinomialText1.lowercaseTokensTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.getNorm();
      naiveBayesMultinomialText1.useStopListTipText();
      naiveBayesMultinomialText1.pruneDictionary();
      naiveBayesMultinomialText0.m_periodicP = (-164);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1.0, (int[]) null, 0);
      try { 
        naiveBayesMultinomialText1.updateClassifier(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 32
  /*Coverage entropy=1.786724494755577
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.NO_CLASS;
      findWithCapabilities0.enableNot(capabilities_Capability0);
      FindWithCapabilities findWithCapabilities1 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities1.find();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.REJECT_EXTENDED_RANGES;
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) vector0, locale_FilteringMode0);
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) list0, locale_FilteringMode0);
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      MockFile mockFile0 = new MockFile(file0, "\"(B");
      naiveBayesMultinomialText1.setStopwords(mockFile0);
      System.setCurrentTimeMillis((-1471L));
      naiveBayesMultinomialText1.getTokenizer();
      String string0 = naiveBayesMultinomialText1.useWordFrequenciesTipText();
      assertFalse(naiveBayesMultinomialText1.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", string0);
  }

  /**
  //Test case number: 33
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stopwordsTipText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      SnowballStemmer.listStemmers();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      snowballStemmer0.getStemmer();
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      naiveBayesMultinomialText0.listOptions();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 34
  /*Coverage entropy=3.2455284021399446
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "normalize";
      stringArray0[1] = "";
      stringArray0[2] = "8YlRz";
      stringArray0[3] = "public class WekaWrapper\n";
      stringArray0[4] = "p;'M^9S-8";
      naiveBayesMultinomialText0.m_normalize = true;
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      stringArray0[5] = "YJSW";
      stringArray0[6] = "c~\"UOkRgw";
      stringArray0[7] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[8] = ".xQV";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.m_lowercaseTokens = false;
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.getOptions();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 35
  /*Coverage entropy=1.6593340983935647
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = (double) 0;
      doubleArray0[1] = (double) 2125;
      doubleArray0[2] = (double) 864;
      doubleArray0[3] = (double) 0;
      doubleArray0[4] = 0.0;
      doubleArray0[5] = (double) 0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(109, doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(0.0, doubleArray0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      ArrayList<String> arrayList0 = new ArrayList<String>();
      ArrayList<Locale.LanguageRange> arrayList1 = new ArrayList<Locale.LanguageRange>();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.EXTENDED_FILTERING;
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) arrayList1, (Collection<String>) arrayList0, locale_FilteringMode0);
      Attribute attribute0 = new Attribute("\"(B", list0);
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      MockFile mockFile0 = new MockFile(file0, "string");
      naiveBayesMultinomialText0.setStopwords(file0);
      System.setCurrentTimeMillis((-1498L));
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=2.070976373972562
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-min";
      stringArray0[1] = "normalize";
      stringArray0[2] = "O4L";
      stringArray0[3] = "22]dX6ZmRh[";
      naiveBayesMultinomialText0.m_minWordP = (-358.848499);
      stringArray0[4] = "";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.m_periodicP = (-302);
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.getStemmer();
      assertEquals("If true, ignores all words that are on the stoplist.", naiveBayesMultinomialText0.useStopListTipText());
  }

  /**
  //Test case number: 37
  /*Coverage entropy=3.22701448677876
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte)0;
      byteArray0[1] = (byte)1;
      byteArray0[2] = (byte) (-126);
      byteArray0[3] = (byte) (-121);
      byteArray0[4] = (byte)119;
      byteArray0[5] = (byte)5;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.LNormTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      SGDText sGDText0 = new SGDText();
      naiveBayesMultinomialText0.m_lnorm = (double) (byte)0;
      naiveBayesMultinomialText0.getOptions();
      File file0 = sGDText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      System.setCurrentTimeMillis((byte) (-121));
      Random.setNextRandom(1);
      naiveBayesMultinomialText0.setNorm((byte)1);
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.normTipText();
      String string0 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string0);
  }

  /**
  //Test case number: 38
  /*Coverage entropy=3.473223150177871
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      byte[] byteArray0 = new byte[6];
      byteArray0[1] = (byte)0;
      byteArray0[2] = (byte) (-126);
      byteArray0[3] = (byte) (-121);
      byteArray0[4] = (byte)119;
      byteArray0[5] = (byte)5;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.LNormTipText();
      SGDText sGDText0 = new SGDText();
      naiveBayesMultinomialText0.m_lnorm = (double) (byte)0;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      sGDText0.setNormalizeDocLength(false);
      File file0 = sGDText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      System.setCurrentTimeMillis((byte) (-121));
      Random.setNextRandom(1);
      naiveBayesMultinomialText0.setNorm((byte)0);
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(0.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 39
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.m_norm = (-135.0);
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.getUseStopList();
      BallTree ballTree0 = new BallTree();
      try { 
        ballTree0.nearestNeighbour((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.BallTree", e);
      }
  }

  /**
  //Test case number: 40
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IBk iBk0 = new IBk(0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      Instances instances0 = naiveBayesMultinomialText1.m_data;
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = (double) 1;
      doubleArray0[1] = (double) 4;
      doubleArray0[2] = (double) 2;
      doubleArray0[3] = (double) 1;
      doubleArray0[4] = 0.0;
      doubleArray0[5] = 1132.97257868;
      iBk0.pruneToK((Instances) null, doubleArray0, 0);
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }
}
