/*
 * This file was automatically generated by EvoSuite
 * Thu Dec 05 07:11:44 GMT 2019
 */

package weka.classifiers;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.PipedReader;
import java.util.Comparator;
import java.util.Enumeration;
import java.util.Random;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.evosuite.runtime.mock.java.util.MockRandom;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;
import weka.attributeSelection.GainRatioAttributeEval;
import weka.attributeSelection.InfoGainAttributeEval;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.Classifier;
import weka.classifiers.CostMatrix;
import weka.classifiers.Evaluation;
import weka.classifiers.bayes.BayesNet;
import weka.classifiers.bayes.NaiveBayes;
import weka.classifiers.bayes.NaiveBayesMultinomial;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.bayes.NaiveBayesUpdateable;
import weka.classifiers.evaluation.output.prediction.PlainText;
import weka.classifiers.functions.GaussianProcesses;
import weka.classifiers.functions.LinearRegression;
import weka.classifiers.functions.MultilayerPerceptron;
import weka.classifiers.functions.SMOreg;
import weka.classifiers.functions.SimpleLinearRegression;
import weka.classifiers.functions.SimpleLogistic;
import weka.classifiers.functions.supportVector.PolyKernel;
import weka.classifiers.functions.supportVector.StringKernel;
import weka.classifiers.meta.AdditiveRegression;
import weka.classifiers.meta.Bagging;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.meta.FilteredClassifier;
import weka.classifiers.meta.LogitBoost;
import weka.classifiers.meta.RegressionByDiscretization;
import weka.classifiers.meta.Stacking;
import weka.classifiers.misc.InputMappedClassifier;
import weka.classifiers.misc.SerializedClassifier;
import weka.classifiers.rules.JRip;
import weka.classifiers.rules.OneR;
import weka.classifiers.rules.ZeroR;
import weka.classifiers.trees.DecisionStump;
import weka.classifiers.trees.J48;
import weka.classifiers.trees.RandomForest;
import weka.classifiers.trees.RandomTree;
import weka.clusterers.Cobweb;
import weka.core.AbstractInstance;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.Version;
import weka.core.converters.ArffLoader;
import weka.core.converters.DatabaseLoader;
import weka.core.converters.LibSVMLoader;
import weka.core.converters.TextDirectoryLoader;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.core.tokenizers.NGramTokenizer;
import weka.estimators.PoissonEstimator;
import weka.filters.AllFilter;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class Evaluation_ESTest extends Evaluation_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=0.3333333333333333
  */
  @Test(timeout = 4000)
  public void test000()  throws Throwable  {
      String string0 = "numIterationsTipText";
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("numIterationsTipText");
      boolean boolean0 = FileSystemHandling.appendStringToFile(evoSuiteFile0, "numIterationsTipText");
      assertTrue(boolean0);
      
      try { 
        Evaluation.handleCostOption("numIterationsTipText", 87);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
         //
         // For input string: \"numIterationsTipText\"
         //
         verifyException("java.lang.NumberFormatException", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=1.7659767920186922
  */
  @Test(timeout = 4000)
  public void test001()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      
      multilayerPerceptron0.setTrainingTime(18);
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(18, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(18, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      
      double double0 = evaluation0.meanPriorAbsoluteError();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      try { 
        evaluation0.updatePriors((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.1955230216918316
  */
  @Test(timeout = 4000)
  public void test002()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      evaluation0.setPriors(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(2, doubleArray0.length);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      Capabilities capabilities0 = Capabilities.forInstances(instances0);
      assertNotNull(capabilities0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      EvoSuiteFile evoSuiteFile0 = null;
      boolean boolean0 = true;
      double[] doubleArray1 = new double[3];
      doubleArray1[0] = (double) (-2);
      doubleArray1[1] = (double) (-2);
      doubleArray1[2] = 3072.4622854;
      DenseInstance denseInstance0 = new DenseInstance(1558.124, doubleArray1);
      assertNotNull(denseInstance0);
      assertEquals(3, doubleArray1.length);
      assertArrayEquals(new double[] {(-2.0), (-2.0), 3072.4622854}, doubleArray1, 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(3, denseInstance0.numValues());
      assertEquals(3, denseInstance0.numAttributes());
      assertEquals(1558.124, denseInstance0.weight(), 0.01);
      
      try { 
        evaluation0.evaluateModelOnce(doubleArray1, (Instance) denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=2.009653988412479
  */
  @Test(timeout = 4000)
  public void test003()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      double double0 = evaluation0.meanPriorAbsoluteError();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      LogitBoost logitBoost0 = new LogitBoost();
      assertNotNull(logitBoost0);
      assertEquals(1, logitBoost0.getSeed());
      assertEquals("Threshold on improvement in likelihood.", logitBoost0.likelihoodThresholdTipText());
      assertEquals(0, logitBoost0.getNumFolds());
      assertEquals("Whether resampling is used instead of reweighting.", logitBoost0.useResamplingTipText());
      assertEquals(1, logitBoost0.getNumRuns());
      assertFalse(logitBoost0.getUseResampling());
      assertFalse(logitBoost0.getDebug());
      assertEquals(100, logitBoost0.getWeightThreshold());
      assertEquals(10, logitBoost0.getNumIterations());
      assertEquals("Weight threshold for weight pruning (reduce to 90 for speeding up learning process).", logitBoost0.weightThresholdTipText());
      assertEquals(1.0, logitBoost0.getShrinkage(), 0.01);
      assertEquals("Shrinkage parameter (use small value like 0.1 to reduce overfitting).", logitBoost0.shrinkageTipText());
      assertEquals("The base classifier to be used.", logitBoost0.classifierTipText());
      assertEquals("The number of iterations to be performed.", logitBoost0.numIterationsTipText());
      assertEquals("Number of folds for internal cross-validation (default 0 means no cross-validation is performed).", logitBoost0.numFoldsTipText());
      assertEquals((-1.7976931348623157E308), logitBoost0.getLikelihoodThreshold(), 0.01);
      assertEquals("The random number seed to be used.", logitBoost0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", logitBoost0.debugTipText());
      assertEquals("Number of runs for internal cross-validation.", logitBoost0.numRunsTipText());
      
      String string0 = Evaluation.getGlobalInfo(logitBoost0);
      assertNotNull(string0);
      assertEquals(1, logitBoost0.getSeed());
      assertEquals("Threshold on improvement in likelihood.", logitBoost0.likelihoodThresholdTipText());
      assertEquals(0, logitBoost0.getNumFolds());
      assertEquals("Whether resampling is used instead of reweighting.", logitBoost0.useResamplingTipText());
      assertEquals(1, logitBoost0.getNumRuns());
      assertFalse(logitBoost0.getUseResampling());
      assertFalse(logitBoost0.getDebug());
      assertEquals(100, logitBoost0.getWeightThreshold());
      assertEquals(10, logitBoost0.getNumIterations());
      assertEquals("Weight threshold for weight pruning (reduce to 90 for speeding up learning process).", logitBoost0.weightThresholdTipText());
      assertEquals(1.0, logitBoost0.getShrinkage(), 0.01);
      assertEquals("Shrinkage parameter (use small value like 0.1 to reduce overfitting).", logitBoost0.shrinkageTipText());
      assertEquals("The base classifier to be used.", logitBoost0.classifierTipText());
      assertEquals("The number of iterations to be performed.", logitBoost0.numIterationsTipText());
      assertEquals("Number of folds for internal cross-validation (default 0 means no cross-validation is performed).", logitBoost0.numFoldsTipText());
      assertEquals((-1.7976931348623157E308), logitBoost0.getLikelihoodThreshold(), 0.01);
      assertEquals("The random number seed to be used.", logitBoost0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", logitBoost0.debugTipText());
      assertEquals("Number of runs for internal cross-validation.", logitBoost0.numRunsTipText());
      assertEquals("\nSynopsis for weka.classifiers.meta.LogitBoost:\n\nClass for performing additive logistic regression. \nThis class performs classification using a regression scheme as the base learner, and can handle multi-class problems.  For more information, see\n\nJ. Friedman, T. Hastie, R. Tibshirani (1998). Additive Logistic Regression: a Statistical View of Boosting. Stanford University.\n\nCan do efficient internal cross-validation to determine appropriate number of iterations.", string0);
      
      double double1 = evaluation0.unclassified();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, double1, 0.01);
  }

  /**
  //Test case number: 4
  /*Coverage entropy=0.4947368421052632
  */
  @Test(timeout = 4000)
  public void test004()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      
      testInstances0.setNumNominal(111);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      
      LinearRegression linearRegression0 = new LinearRegression();
      assertNotNull(linearRegression0);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertFalse(linearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertFalse(linearRegression0.getMinimal());
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      
      Capabilities capabilities0 = linearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertFalse(linearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertFalse(linearRegression0.getMinimal());
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances1);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(linearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertFalse(linearRegression0.getMinimal());
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getSeed());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertFalse(testInstances1.getNoClass());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, testInstances1.getNumAttributes());
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      
      Instances instances0 = testInstances1.generate(" ");
      assertNotNull(instances0);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(linearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertFalse(linearRegression0.getMinimal());
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getSeed());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertFalse(testInstances1.getNoClass());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, testInstances1.getNumAttributes());
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(linearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertFalse(linearRegression0.getMinimal());
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getSeed());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertFalse(testInstances1.getNoClass());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, testInstances1.getNumAttributes());
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(linearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertFalse(linearRegression0.getMinimal());
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getSeed());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertFalse(testInstances1.getNoClass());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, testInstances1.getNumAttributes());
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      Instances instances1 = new Instances(instances0);
      assertNotNull(instances1);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertFalse(instances1.equals((Object)instances0));
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(linearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertFalse(linearRegression0.getMinimal());
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getSeed());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertFalse(testInstances1.getNoClass());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, testInstances1.getNumAttributes());
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(1, instances1.numClasses());
      assertEquals(20, instances1.numInstances());
      assertEquals(20, instances1.size());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(3, instances1.classIndex());
      assertEquals(4, instances1.numAttributes());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances1.relationName());
      
      Evaluation evaluation1 = new Evaluation(instances0, (CostMatrix) null);
      assertNotNull(evaluation1);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertFalse(instances0.equals((Object)instances1));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(linearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertFalse(linearRegression0.getMinimal());
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getSeed());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertFalse(testInstances1.getNoClass());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, testInstances1.getNumAttributes());
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      
      try { 
        evaluation1.toMatrixString(".bsi");
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Evaluation: No confusion matrix possible!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=1.163735415854063
  */
  @Test(timeout = 4000)
  public void test005()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.rootRelativeSquaredError();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double[] doubleArray0 = new double[0];
      DenseInstance denseInstance0 = new DenseInstance(0.0, doubleArray0);
      assertNotNull(denseInstance0);
      assertEquals(0, doubleArray0.length);
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(0, denseInstance0.numAttributes());
      assertEquals(0, denseInstance0.numValues());
      assertEquals(0.0, denseInstance0.weight(), 0.01);
      
      SparseInstance sparseInstance0 = new SparseInstance(denseInstance0);
      assertNotNull(sparseInstance0);
      assertEquals(0, doubleArray0.length);
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(0, denseInstance0.numAttributes());
      assertEquals(0, denseInstance0.numValues());
      assertEquals(0.0, denseInstance0.weight(), 0.01);
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(0.0, sparseInstance0.weight(), 0.01);
      assertEquals(0, sparseInstance0.numAttributes());
      
      try { 
        evaluation0.updatePriors(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=1.1693376567504215
  */
  @Test(timeout = 4000)
  public void test006()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      Instances instances1 = new Instances(instances0);
      assertNotNull(instances1);
      assertFalse(instances1.equals((Object)instances0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances1.numAttributes());
      assertEquals(1, instances1.classIndex());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(2, instances1.numClasses());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.numInstances());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.size());
      
      String string0 = instances0.toSummaryString();
      assertNotNull(string0);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals("Relation Name:  Testdata\nNum Instances:  20\nNum Attributes: 2\n\n     Name                      Type  Nom  Int Real     Missing      Unique  Dist\n   1  Nominal1                  Nom 100%   0%   0%     0 /  0%     0 /  0%     2 \n   2  Class                     Nom 100%   0%   0%     0 /  0%     0 /  0%     2 \n", string0);
      
      evaluation0.m_NumClasses = 92;
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      
      double[] doubleArray0 = evaluation0.m_MarginCounts;
      assertNotNull(doubleArray0);
      assertEquals(501, doubleArray0.length);
      
      ZeroR zeroR0 = new ZeroR();
      assertNotNull(zeroR0);
      assertEquals("Class for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).", zeroR0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", zeroR0.debugTipText());
      assertFalse(zeroR0.getDebug());
      
      Capabilities capabilities0 = zeroR0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("Class for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).", zeroR0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", zeroR0.debugTipText());
      assertFalse(zeroR0.getDebug());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      NaiveBayesUpdateable naiveBayesUpdateable0 = new NaiveBayesUpdateable();
      assertNotNull(naiveBayesUpdateable0);
      assertFalse(naiveBayesUpdateable0.getDebug());
      assertEquals("Use supervised discretization to convert numeric attributes to nominal ones.", naiveBayesUpdateable0.useSupervisedDiscretizationTipText());
      assertEquals("Use a kernel estimator for numeric attributes rather than a normal distribution.", naiveBayesUpdateable0.useKernelEstimatorTipText());
      assertFalse(naiveBayesUpdateable0.getDisplayModelInOldFormat());
      assertFalse(naiveBayesUpdateable0.getUseSupervisedDiscretization());
      assertFalse(naiveBayesUpdateable0.getUseKernelEstimator());
      assertEquals("Use old format for model output. The old format is better when there are many class values. The new format is better when there are fewer classes and many attributes.", naiveBayesUpdateable0.displayModelInOldFormatTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", naiveBayesUpdateable0.debugTipText());
      
      Capabilities capabilities1 = naiveBayesUpdateable0.getCapabilities();
      assertNotNull(capabilities1);
      assertFalse(capabilities1.equals((Object)capabilities0));
      assertNotSame(capabilities1, capabilities0);
      assertFalse(naiveBayesUpdateable0.getDebug());
      assertEquals("Use supervised discretization to convert numeric attributes to nominal ones.", naiveBayesUpdateable0.useSupervisedDiscretizationTipText());
      assertEquals("Use a kernel estimator for numeric attributes rather than a normal distribution.", naiveBayesUpdateable0.useKernelEstimatorTipText());
      assertFalse(naiveBayesUpdateable0.getDisplayModelInOldFormat());
      assertFalse(naiveBayesUpdateable0.getUseSupervisedDiscretization());
      assertFalse(naiveBayesUpdateable0.getUseKernelEstimator());
      assertEquals("Use old format for model output. The old format is better when there are many class values. The new format is better when there are fewer classes and many attributes.", naiveBayesUpdateable0.displayModelInOldFormatTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", naiveBayesUpdateable0.debugTipText());
      assertFalse(capabilities1.hasDependencies());
      assertEquals(0, capabilities1.getMinimumNumberInstances());
      
      capabilities0.or(capabilities1);
      assertFalse(capabilities0.equals((Object)capabilities1));
      assertFalse(capabilities1.equals((Object)capabilities0));
      assertNotSame(capabilities0, capabilities1);
      assertNotSame(capabilities1, capabilities0);
      assertEquals("Class for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).", zeroR0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", zeroR0.debugTipText());
      assertFalse(zeroR0.getDebug());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(naiveBayesUpdateable0.getDebug());
      assertEquals("Use supervised discretization to convert numeric attributes to nominal ones.", naiveBayesUpdateable0.useSupervisedDiscretizationTipText());
      assertEquals("Use a kernel estimator for numeric attributes rather than a normal distribution.", naiveBayesUpdateable0.useKernelEstimatorTipText());
      assertFalse(naiveBayesUpdateable0.getDisplayModelInOldFormat());
      assertFalse(naiveBayesUpdateable0.getUseSupervisedDiscretization());
      assertFalse(naiveBayesUpdateable0.getUseKernelEstimator());
      assertEquals("Use old format for model output. The old format is better when there are many class values. The new format is better when there are fewer classes and many attributes.", naiveBayesUpdateable0.displayModelInOldFormatTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", naiveBayesUpdateable0.debugTipText());
      assertFalse(capabilities1.hasDependencies());
      assertEquals(0, capabilities1.getMinimumNumberInstances());
      
      Capabilities capabilities2 = capabilities0.getAttributeCapabilities();
      assertNotNull(capabilities2);
      assertFalse(capabilities0.equals((Object)capabilities1));
      assertFalse(capabilities2.equals((Object)capabilities0));
      assertFalse(capabilities2.equals((Object)capabilities1));
      assertNotSame(capabilities0, capabilities2);
      assertNotSame(capabilities0, capabilities1);
      assertNotSame(capabilities2, capabilities0);
      assertNotSame(capabilities2, capabilities1);
      assertEquals("Class for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).", zeroR0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", zeroR0.debugTipText());
      assertFalse(zeroR0.getDebug());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(capabilities2.hasDependencies());
      assertEquals(1, capabilities2.getMinimumNumberInstances());
      
      double double1 = evaluation0.SFMeanSchemeEntropy();
      assertFalse(instances0.equals((Object)instances1));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(instances0, instances1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.errorRate();
      assertEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation0.kappa();
      assertNotEquals(double3, double2, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1.0, double3, 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.unweightedMicroFmeasure();
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 2
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 7
  /*Coverage entropy=1.3813327519834604
  */
  @Test(timeout = 4000)
  public void test007()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      
      Instances instances1 = testInstances0.generate();
      assertNotNull(instances1);
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(1, instances1.classIndex());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.size());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(2, instances1.numClasses());
      assertEquals(2, instances1.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(instances0.equals((Object)instances1));
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      
      try { 
        evaluation0.setPriors(instances1);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=1.526900258019405
  */
  @Test(timeout = 4000)
  public void test008()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      
      testInstances0.setNumNominal(111);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(112, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(112, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(112, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.unweightedMacroFmeasure();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(112, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.numTruePositives((-1));
      assertEquals(double2, double0, 0.01);
      assertNotEquals(double2, double1, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(112, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      StringKernel stringKernel0 = new StringKernel();
      assertNotNull(stringKernel0);
      assertEquals(1, StringKernel.PRUNING_LAMBDA);
      assertEquals(0, StringKernel.PRUNING_NONE);
      assertEquals(3, stringKernel0.getSubsequenceLength());
      assertFalse(stringKernel0.getDebug());
      assertFalse(stringKernel0.getUseNormalization());
      assertFalse(stringKernel0.getChecksTurnedOff());
      assertEquals("Turns time-consuming checks off - use with caution.", stringKernel0.checksTurnedOffTipText());
      assertEquals("Whether to use normalization.", stringKernel0.useNormalizationTipText());
      assertEquals((-1), stringKernel0.numCacheHits());
      assertEquals(200003, stringKernel0.getInternalCacheSize());
      assertEquals(250007, stringKernel0.getCacheSize());
      assertEquals(0.5, stringKernel0.getLambda(), 0.01);
      assertEquals("The subsequence length.", stringKernel0.subsequenceLengthTipText());
      assertEquals("The size of the internal cache (a prime number).", stringKernel0.internalCacheSizeTipText());
      assertEquals("The pruning method.", stringKernel0.pruningMethodTipText());
      assertEquals("Penalizes non-continuous subsequence matches, from (0,1)", stringKernel0.lambdaTipText());
      assertEquals("The maximum subsequence length (theta in the paper)", stringKernel0.maxSubsequenceLengthTipText());
      assertEquals("The size of the cache (a prime number).", stringKernel0.cacheSizeTipText());
      assertEquals(9, stringKernel0.getMaxSubsequenceLength());
      assertEquals("Turns on the output of debugging information.", stringKernel0.debugTipText());
      assertEquals(0, stringKernel0.numEvals());
      
      Capabilities capabilities0 = stringKernel0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(1, StringKernel.PRUNING_LAMBDA);
      assertEquals(0, StringKernel.PRUNING_NONE);
      assertEquals(3, stringKernel0.getSubsequenceLength());
      assertFalse(stringKernel0.getDebug());
      assertFalse(stringKernel0.getUseNormalization());
      assertFalse(stringKernel0.getChecksTurnedOff());
      assertEquals("Turns time-consuming checks off - use with caution.", stringKernel0.checksTurnedOffTipText());
      assertEquals("Whether to use normalization.", stringKernel0.useNormalizationTipText());
      assertEquals((-1), stringKernel0.numCacheHits());
      assertEquals(200003, stringKernel0.getInternalCacheSize());
      assertEquals(250007, stringKernel0.getCacheSize());
      assertEquals(0.5, stringKernel0.getLambda(), 0.01);
      assertEquals("The subsequence length.", stringKernel0.subsequenceLengthTipText());
      assertEquals("The size of the internal cache (a prime number).", stringKernel0.internalCacheSizeTipText());
      assertEquals("The pruning method.", stringKernel0.pruningMethodTipText());
      assertEquals("Penalizes non-continuous subsequence matches, from (0,1)", stringKernel0.lambdaTipText());
      assertEquals("The maximum subsequence length (theta in the paper)", stringKernel0.maxSubsequenceLengthTipText());
      assertEquals("The size of the cache (a prime number).", stringKernel0.cacheSizeTipText());
      assertEquals(9, stringKernel0.getMaxSubsequenceLength());
      assertEquals("Turns on the output of debugging information.", stringKernel0.debugTipText());
      assertEquals(0, stringKernel0.numEvals());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      testInstances0.setRelation("setReset");
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("setReset", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      
      Capabilities capabilities1 = capabilities0.getAttributeCapabilities();
      assertNotNull(capabilities1);
      assertFalse(capabilities1.equals((Object)capabilities0));
      assertNotSame(capabilities0, capabilities1);
      assertNotSame(capabilities1, capabilities0);
      assertEquals(1, StringKernel.PRUNING_LAMBDA);
      assertEquals(0, StringKernel.PRUNING_NONE);
      assertEquals(3, stringKernel0.getSubsequenceLength());
      assertFalse(stringKernel0.getDebug());
      assertFalse(stringKernel0.getUseNormalization());
      assertFalse(stringKernel0.getChecksTurnedOff());
      assertEquals("Turns time-consuming checks off - use with caution.", stringKernel0.checksTurnedOffTipText());
      assertEquals("Whether to use normalization.", stringKernel0.useNormalizationTipText());
      assertEquals((-1), stringKernel0.numCacheHits());
      assertEquals(200003, stringKernel0.getInternalCacheSize());
      assertEquals(250007, stringKernel0.getCacheSize());
      assertEquals(0.5, stringKernel0.getLambda(), 0.01);
      assertEquals("The subsequence length.", stringKernel0.subsequenceLengthTipText());
      assertEquals("The size of the internal cache (a prime number).", stringKernel0.internalCacheSizeTipText());
      assertEquals("The pruning method.", stringKernel0.pruningMethodTipText());
      assertEquals("Penalizes non-continuous subsequence matches, from (0,1)", stringKernel0.lambdaTipText());
      assertEquals("The maximum subsequence length (theta in the paper)", stringKernel0.maxSubsequenceLengthTipText());
      assertEquals("The size of the cache (a prime number).", stringKernel0.cacheSizeTipText());
      assertEquals(9, stringKernel0.getMaxSubsequenceLength());
      assertEquals("Turns on the output of debugging information.", stringKernel0.debugTipText());
      assertEquals(0, stringKernel0.numEvals());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(capabilities1.hasDependencies());
      assertEquals(1, capabilities1.getMinimumNumberInstances());
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("setReset", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(112, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      
      double double3 = evaluation1.SFMeanSchemeEntropy();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals(double3, double1, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertNotEquals(double3, double2, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("setReset", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(112, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
      
      double double4 = evaluation1.errorRate();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotEquals(double4, double0, 0.01);
      assertEquals(double4, double3, 0.01);
      assertEquals(double4, double1, 0.01);
      assertNotEquals(double4, double2, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("setReset", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(112, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, double4, 0.01);
      
      double double5 = evaluation0.kappa();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotEquals(double5, double4, 0.01);
      assertNotEquals(double5, double3, 0.01);
      assertNotEquals(double5, double2, 0.01);
      assertNotEquals(double5, double1, 0.01);
      assertNotEquals(double5, double0, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("setReset", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(112, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(1.0, double5, 0.01);
      
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (double) 111;
      doubleArray0[1] = (double) 1;
      doubleArray0[2] = 0.0;
      try { 
        evaluation1.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=1.8564909139241832
  */
  @Test(timeout = 4000)
  public void test009()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      
      testInstances0.setNumNominal(111);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (double) (-1);
      int[] intArray0 = new int[4];
      intArray0[0] = 111;
      intArray0[1] = 111;
      intArray0[2] = (-1);
      intArray0[3] = (-1);
      SparseInstance sparseInstance0 = new SparseInstance(1933.04324, doubleArray0, intArray0, 111);
      assertNotNull(sparseInstance0);
      assertEquals(1, doubleArray0.length);
      assertEquals(4, intArray0.length);
      assertArrayEquals(new double[] {(-1.0)}, doubleArray0, 0.01);
      assertArrayEquals(new int[] {111, 111, (-1), (-1)}, intArray0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(4, sparseInstance0.numValues());
      assertEquals(1933.04324, sparseInstance0.weight(), 0.01);
      assertEquals(111, sparseInstance0.numAttributes());
      
      boolean boolean0 = true;
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray0, sparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=2.6648908922966137
  */
  @Test(timeout = 4000)
  public void test010()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      
      evaluation0.setPriors(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      
      double double0 = evaluation1.SFEntropyGain();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation1.falseNegativeRate(0);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals(double1, double0, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, double1, 0.01);
      
      double double2 = evaluation1.KBRelativeInformation();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      double double3 = evaluation0.SFMeanSchemeEntropy();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotEquals(double3, double2, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
      
      double double4 = evaluation0.rootRelativeSquaredError();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotEquals(double4, double2, 0.01);
      assertNotEquals(double4, double1, 0.01);
      assertEquals(double4, double3, 0.01);
      assertNotEquals(double4, double0, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, double4, 0.01);
  }

  /**
  //Test case number: 11
  /*Coverage entropy=2.8151324951264747
  */
  @Test(timeout = 4000)
  public void test011()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      String string0 = evaluation0.toMatrixString();
      assertNotNull(string0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals("=== Confusion Matrix ===\n\n   <-- classified as\n", string0);
      
      double[][] doubleArray0 = evaluation0.m_ConfusionMatrix;
      assertNotNull(doubleArray0);
      assertEquals(0, doubleArray0.length);
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertNotNull(regressionByDiscretization0);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      
      ArffLoader arffLoader0 = new ArffLoader();
      assertNotNull(arffLoader0);
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals(".arff", arffLoader0.getFileExtension());
      assertEquals("http://", arffLoader0.retrieveURL());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      
      double double0 = evaluation0.fMeasure((-1983214072));
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertTrue(multilayerPerceptron0.getReset());
      
      multilayerPerceptron0.setTrainingTime(1);
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getReset());
      
      double double1 = evaluation0.m_SumPriorAbsErr;
      assertEquals(double1, double0, 0.01);
      assertEquals(0.0, double1, 0.01);
      
      double double2 = evaluation0.weightedFalseNegativeRate();
      assertNotEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double[] doubleArray1 = new double[2];
      doubleArray1[0] = 0.0;
      doubleArray1[1] = 0.0;
      DenseInstance denseInstance0 = new DenseInstance(2463);
      assertNotNull(denseInstance0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(2463, denseInstance0.numValues());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertEquals(2463, denseInstance0.numAttributes());
      
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray1, denseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.1779956654084303
  */
  @Test(timeout = 4000)
  public void test012()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      
      testInstances0.setNumNominal(111);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      evaluation0.useNoPriors();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.weightedMatthewsCorrelation();
      assertEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, double1, 0.01);
      
      evaluation0.m_DiscardPredictions = false;
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      // Undeclared exception!
      try { 
        testInstances0.setRelationalFormat((-3381), instances0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -3381
         //
         verifyException("weka.core.TestInstances", e);
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=1.940671268968105
  */
  @Test(timeout = 4000)
  public void test013()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      
      LibSVMLoader libSVMLoader0 = new LibSVMLoader();
      assertNotNull(libSVMLoader0);
      assertEquals("Reads a source that is in libsvm format.\n\nFor more information about libsvm see:\n\nhttp://www.csie.ntu.edu.tw/~cjlin/libsvm/", libSVMLoader0.globalInfo());
      assertEquals(".libsvm", libSVMLoader0.getFileExtension());
      assertFalse(libSVMLoader0.getUseRelativePath());
      assertEquals("Use relative rather than absolute paths", libSVMLoader0.useRelativePathTipText());
      assertEquals("http://", libSVMLoader0.retrieveURL());
      assertEquals("libsvm data files", libSVMLoader0.getFileDescription());
      
      TextDirectoryLoader textDirectoryLoader1 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader1);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      
      JRip jRip0 = new JRip();
      assertNotNull(jRip0);
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", jRip0.foldsTipText());
      assertEquals("The seed used for randomizing the data.", jRip0.seedTipText());
      assertFalse(jRip0.getDebug());
      assertEquals("Whether pruning is performed.", jRip0.usePruningTipText());
      assertEquals(1L, jRip0.getSeed());
      assertTrue(jRip0.getCheckErrorRate());
      assertTrue(jRip0.getUsePruning());
      assertEquals(2.0, jRip0.getMinNo(), 0.01);
      assertEquals("Whether debug information is output to the console.", jRip0.debugTipText());
      assertEquals("The number of optimization runs.", jRip0.optimizationsTipText());
      assertEquals("The minimum total weight of the instances in a rule.", jRip0.minNoTipText());
      assertEquals(3, jRip0.getFolds());
      assertEquals("Whether check for error rate >= 1/2 is included in stopping criterion.", jRip0.checkErrorRateTipText());
      assertEquals(2, jRip0.getOptimizations());
      
      String string0 = Evaluation.getGlobalInfo(jRip0);
      assertNotNull(string0);
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", jRip0.foldsTipText());
      assertEquals("The seed used for randomizing the data.", jRip0.seedTipText());
      assertFalse(jRip0.getDebug());
      assertEquals("Whether pruning is performed.", jRip0.usePruningTipText());
      assertEquals(1L, jRip0.getSeed());
      assertTrue(jRip0.getCheckErrorRate());
      assertTrue(jRip0.getUsePruning());
      assertEquals(2.0, jRip0.getMinNo(), 0.01);
      assertEquals("Whether debug information is output to the console.", jRip0.debugTipText());
      assertEquals("The number of optimization runs.", jRip0.optimizationsTipText());
      assertEquals("The minimum total weight of the instances in a rule.", jRip0.minNoTipText());
      assertEquals(3, jRip0.getFolds());
      assertEquals("Whether check for error rate >= 1/2 is included in stopping criterion.", jRip0.checkErrorRateTipText());
      assertEquals(2, jRip0.getOptimizations());
      
      ZeroR zeroR0 = new ZeroR();
      assertNotNull(zeroR0);
      assertFalse(zeroR0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", zeroR0.debugTipText());
      assertEquals("Class for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).", zeroR0.globalInfo());
      
      StringKernel stringKernel0 = new StringKernel();
      assertNotNull(stringKernel0);
      assertEquals(0, StringKernel.PRUNING_NONE);
      assertEquals(1, StringKernel.PRUNING_LAMBDA);
      assertEquals("The maximum subsequence length (theta in the paper)", stringKernel0.maxSubsequenceLengthTipText());
      assertEquals("The pruning method.", stringKernel0.pruningMethodTipText());
      assertEquals((-1), stringKernel0.numCacheHits());
      assertEquals(200003, stringKernel0.getInternalCacheSize());
      assertEquals(250007, stringKernel0.getCacheSize());
      assertEquals(0, stringKernel0.numEvals());
      assertFalse(stringKernel0.getUseNormalization());
      assertEquals("The size of the internal cache (a prime number).", stringKernel0.internalCacheSizeTipText());
      assertEquals(9, stringKernel0.getMaxSubsequenceLength());
      assertFalse(stringKernel0.getDebug());
      assertEquals("Turns time-consuming checks off - use with caution.", stringKernel0.checksTurnedOffTipText());
      assertEquals("Whether to use normalization.", stringKernel0.useNormalizationTipText());
      assertEquals("Penalizes non-continuous subsequence matches, from (0,1)", stringKernel0.lambdaTipText());
      assertFalse(stringKernel0.getChecksTurnedOff());
      assertEquals("The subsequence length.", stringKernel0.subsequenceLengthTipText());
      assertEquals("Turns on the output of debugging information.", stringKernel0.debugTipText());
      assertEquals(3, stringKernel0.getSubsequenceLength());
      assertEquals("The size of the cache (a prime number).", stringKernel0.cacheSizeTipText());
      assertEquals(0.5, stringKernel0.getLambda(), 0.01);
      
      Capabilities capabilities0 = stringKernel0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(0, StringKernel.PRUNING_NONE);
      assertEquals(1, StringKernel.PRUNING_LAMBDA);
      assertEquals("The maximum subsequence length (theta in the paper)", stringKernel0.maxSubsequenceLengthTipText());
      assertEquals("The pruning method.", stringKernel0.pruningMethodTipText());
      assertEquals((-1), stringKernel0.numCacheHits());
      assertEquals(200003, stringKernel0.getInternalCacheSize());
      assertEquals(250007, stringKernel0.getCacheSize());
      assertEquals(0, stringKernel0.numEvals());
      assertFalse(stringKernel0.getUseNormalization());
      assertEquals("The size of the internal cache (a prime number).", stringKernel0.internalCacheSizeTipText());
      assertEquals(9, stringKernel0.getMaxSubsequenceLength());
      assertFalse(stringKernel0.getDebug());
      assertEquals("Turns time-consuming checks off - use with caution.", stringKernel0.checksTurnedOffTipText());
      assertEquals("Whether to use normalization.", stringKernel0.useNormalizationTipText());
      assertEquals("Penalizes non-continuous subsequence matches, from (0,1)", stringKernel0.lambdaTipText());
      assertFalse(stringKernel0.getChecksTurnedOff());
      assertEquals("The subsequence length.", stringKernel0.subsequenceLengthTipText());
      assertEquals("Turns on the output of debugging information.", stringKernel0.debugTipText());
      assertEquals(3, stringKernel0.getSubsequenceLength());
      assertEquals("The size of the cache (a prime number).", stringKernel0.cacheSizeTipText());
      assertEquals(0.5, stringKernel0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      CostMatrix costMatrix0 = new CostMatrix(0);
      assertNotNull(costMatrix0);
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(0, costMatrix0.numColumns());
      
      CostMatrix costMatrix1 = new CostMatrix(costMatrix0);
      assertNotNull(costMatrix1);
      assertFalse(costMatrix1.equals((Object)costMatrix0));
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix1.numColumns());
      assertEquals(0, costMatrix1.numRows());
      assertEquals(0, costMatrix1.size());
      
      Evaluation evaluation0 = new Evaluation(instances0, costMatrix1);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.equals((Object)textDirectoryLoader1));
      assertFalse(costMatrix0.equals((Object)costMatrix1));
      assertFalse(costMatrix1.equals((Object)costMatrix0));
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix1.numColumns());
      assertEquals(0, costMatrix1.numRows());
      assertEquals(0, costMatrix1.size());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      
      double double0 = evaluation0.weightedTrueNegativeRate();
      assertFalse(textDirectoryLoader0.equals((Object)textDirectoryLoader1));
      assertFalse(costMatrix0.equals((Object)costMatrix1));
      assertFalse(costMatrix1.equals((Object)costMatrix0));
      assertNotSame(textDirectoryLoader0, textDirectoryLoader1);
      assertNotSame(costMatrix0, costMatrix1);
      assertNotSame(costMatrix1, costMatrix0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix1.numColumns());
      assertEquals(0, costMatrix1.numRows());
      assertEquals(0, costMatrix1.size());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.trueNegativeRate(1);
      assertFalse(textDirectoryLoader0.equals((Object)textDirectoryLoader1));
      assertFalse(costMatrix0.equals((Object)costMatrix1));
      assertFalse(costMatrix1.equals((Object)costMatrix0));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(textDirectoryLoader0, textDirectoryLoader1);
      assertNotSame(costMatrix0, costMatrix1);
      assertNotSame(costMatrix1, costMatrix0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix1.numColumns());
      assertEquals(0, costMatrix1.numRows());
      assertEquals(0, costMatrix1.size());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, double1, 0.01);
      
      double double2 = evaluation0.pctIncorrect();
      assertFalse(textDirectoryLoader0.equals((Object)textDirectoryLoader1));
      assertFalse(costMatrix0.equals((Object)costMatrix1));
      assertFalse(costMatrix1.equals((Object)costMatrix0));
      assertEquals(double2, double0, 0.01);
      assertNotEquals(double2, double1, 0.01);
      assertNotSame(textDirectoryLoader0, textDirectoryLoader1);
      assertNotSame(costMatrix0, costMatrix1);
      assertNotSame(costMatrix1, costMatrix0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix1.numColumns());
      assertEquals(0, costMatrix1.numRows());
      assertEquals(0, costMatrix1.size());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
  }

  /**
  //Test case number: 14
  /*Coverage entropy=2.4282342922064575
  */
  @Test(timeout = 4000)
  public void test014()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      
      testInstances0.setNumNominal(111);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(112, instances0.numAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(112, instances0.numAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(112, instances0.numAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(112, instances0.numAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      
      double double1 = evaluation1.precision(0);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals(double1, double0, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(112, instances0.numAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(0.0, double1, 0.01);
      
      double double2 = evaluation0.weightedFalsePositiveRate();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(112, instances0.numAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation1.weightedPrecision();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals(double3, double2, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(112, instances0.numAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
  }

  /**
  //Test case number: 15
  /*Coverage entropy=3.673847673266463
  */
  @Test(timeout = 4000)
  public void test015()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      multilayerPerceptron0.setDebug(true);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      double double0 = evaluation0.m_ClassPriorsSum;
      assertEquals(22.0, double0, 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      
      double double1 = evaluation1.rootRelativeSquaredError();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation1.matthewsCorrelationCoefficient((-1));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertNotNull(costSensitiveClassifier0);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      assertNotNull(costMatrix0);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals(1, costMatrix0.size());
      assertEquals(1, costMatrix0.numColumns());
      assertEquals(1, costMatrix0.numRows());
      
      evaluation0.addNumericTrainClass((-1), 1);
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      Evaluation evaluation2 = new Evaluation(instances0);
      assertNotNull(evaluation2);
      assertTrue(evaluation2.equals((Object)evaluation0));
      assertTrue(evaluation2.equals((Object)evaluation1));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation2.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation2.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation2.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation2.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation2.incorrect(), 0.01);
      assertEquals(1.0, evaluation2.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation2.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation2.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation2.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation2.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation2.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation2.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation2.totalCost(), 0.01);
      assertEquals(0.0, evaluation2.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation2.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation2.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation2.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation2.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation2.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation2.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation2.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation2.correct(), 0.01);
      assertFalse(evaluation2.getDiscardPredictions());
      
      double double3 = evaluation1.meanAbsoluteError();
      assertTrue(evaluation1.equals((Object)evaluation2));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotEquals(double3, double2, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertEquals(double3, double1, 0.01);
      assertNotSame(evaluation1, evaluation2);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
      
      double[][] doubleArray0 = evaluation1.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(2, doubleArray0.length);
      assertTrue(evaluation1.equals((Object)evaluation2));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotSame(evaluation1, evaluation2);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      double double4 = evaluation0.SFMeanSchemeEntropy();
      assertEquals(double4, double3, 0.01);
      assertNotEquals(double4, double0, 0.01);
      assertEquals(double4, double1, 0.01);
      assertNotEquals(double4, double2, 0.01);
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertTrue(evaluation0.equals((Object)evaluation2));
      assertNotSame(evaluation0, evaluation2);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double4, 0.01);
      
      double double5 = evaluation1.numFalsePositives(1);
      assertNotEquals(double5, double4, 0.01);
      assertNotEquals(double5, double1, 0.01);
      assertEquals(double5, double2, 0.01);
      assertNotEquals(double5, double3, 0.01);
      assertNotEquals(double5, double0, 0.01);
      assertTrue(evaluation1.equals((Object)evaluation2));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotSame(evaluation1, evaluation2);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, double5, 0.01);
      
      String string0 = evaluation0.toClassDetailsString("weka/core/Capabilities.props");
      assertNotNull(string0);
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertTrue(evaluation0.equals((Object)evaluation2));
      assertNotSame(evaluation0, evaluation2);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals("weka/core/Capabilities.props\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\n                 0        0        0          0       0          0     ?         ?         class1\n                 0        0        0          0       0          0     ?         ?         class2\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
      
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertNotNull(gaussianProcesses0);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      assertNotNull(inputMappedClassifier0);
      assertEquals("Wrapper classifier that addresses incompatible training and test data by building a mapping between the training data that a classifier has been built with and the incoming test instances' structure. Model attributes that are not found in the incoming instances receive missing values, so do incoming nominal attribute values that the classifier has not seen before. A new classifier can be trained or an existing one loaded from a file.", inputMappedClassifier0.globalInfo());
      assertTrue(inputMappedClassifier0.getIgnoreCaseForNames());
      assertEquals("Trim white space from each end of attribute names and nominal values before matching.", inputMappedClassifier0.trimTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", inputMappedClassifier0.debugTipText());
      assertEquals(0, inputMappedClassifier0.graphType());
      assertEquals("Set the path from which to load a model. Loading occurs when the first test instance is received. Environment variables can be used in the supplied path.", inputMappedClassifier0.modelPathTipText());
      assertEquals("", inputMappedClassifier0.getModelPath());
      assertEquals("Don't output a report of model-to-input mappings.", inputMappedClassifier0.suppressMappingReportTipText());
      assertFalse(inputMappedClassifier0.getSuppressMappingReport());
      assertTrue(inputMappedClassifier0.getTrim());
      assertEquals("The base classifier to be used.", inputMappedClassifier0.classifierTipText());
      assertEquals("Ignore case when matching attribute names and nomina values.", inputMappedClassifier0.ignoreCaseForNamesTipText());
      assertFalse(inputMappedClassifier0.getDebug());
      
      int[] intArray0 = new int[2];
      intArray0[0] = (-2);
      intArray0[1] = 2;
      // Undeclared exception!
      try { 
        BallNode.calcCentroidPivot(intArray0, instances0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 16
  /*Coverage entropy=1.166831391086261
  */
  @Test(timeout = 4000)
  public void test016()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.meanPriorAbsoluteError();
      assertNotEquals(double1, double0, 0.01);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.priorEntropy();
      assertNotEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      double double3 = evaluation0.SFMeanPriorEntropy();
      assertNotEquals(double3, double2, 0.01);
      assertEquals(double3, double1, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
      
      String string0 = evaluation0.getRevision();
      assertNotNull(string0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals("9101", string0);
      
      double double4 = evaluation0.coverageOfTestCasesByPredictedRegions();
      assertEquals(double4, double1, 0.01);
      assertNotEquals(double4, double2, 0.01);
      assertNotEquals(double4, double0, 0.01);
      assertEquals(double4, double3, 0.01);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, double4, 0.01);
  }

  /**
  //Test case number: 17
  /*Coverage entropy=2.9581738010500374
  */
  @Test(timeout = 4000)
  public void test017()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.rootRelativeSquaredError();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.matthewsCorrelationCoefficient((-2));
      assertNotEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      evaluation0.addNumericTrainClass(0.0, 0.0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      
      double double3 = evaluation0.weightedFalsePositiveRate();
      assertEquals(double3, double1, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertNotEquals(double3, double2, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
      
      double double4 = evaluation0.m_SumClassPredicted;
      assertEquals(double4, double0, 0.01);
      assertNotEquals(double4, double3, 0.01);
      assertNotEquals(double4, double1, 0.01);
      assertEquals(double4, double2, 0.01);
      assertEquals(0.0, double4, 0.01);
  }

  /**
  //Test case number: 18
  /*Coverage entropy=1.9593337382266454
  */
  @Test(timeout = 4000)
  public void test018()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double double0 = evaluation0.m_SumPriorSqrErr;
      assertEquals(0.0, double0, 0.01);
      
      RandomForest randomForest0 = new RandomForest();
      assertNotNull(randomForest0);
      assertEquals("The number of trees to be generated.", randomForest0.numTreesTipText());
      assertEquals(10, randomForest0.getNumTrees());
      assertEquals("If set to true, classifier may output additional info to the console.", randomForest0.debugTipText());
      assertEquals(0, randomForest0.getMaxDepth());
      assertEquals(0, randomForest0.getNumFeatures());
      assertFalse(randomForest0.getPrintTrees());
      assertEquals("Print the individual trees in the output", randomForest0.printTreesTipText());
      assertEquals("The number of attributes to be used in random selection (see RandomTree).", randomForest0.numFeaturesTipText());
      assertFalse(randomForest0.getDebug());
      assertEquals("The random number seed to be used.", randomForest0.seedTipText());
      assertEquals(1, randomForest0.getNumExecutionSlots());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", randomForest0.numExecutionSlotsTipText());
      assertEquals(Double.NaN, randomForest0.measureOutOfBagError(), 0.01);
      assertEquals(1, randomForest0.getSeed());
      assertEquals("The maximum depth of the trees, 0 for unlimited.", randomForest0.maxDepthTipText());
      
      evaluation0.updateNumericScores((double[]) null, (double[]) null, 0.0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double double1 = evaluation0.weightedFalsePositiveRate();
      assertNotEquals(double1, double0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.m_SumClassPredicted;
      assertEquals(double2, double0, 0.01);
      assertNotEquals(double2, double1, 0.01);
      assertEquals(0.0, double2, 0.01);
  }

  /**
  //Test case number: 19
  /*Coverage entropy=2.4057906743854622
  */
  @Test(timeout = 4000)
  public void test019()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      
      Instances instances0 = testInstances0.generate("ov\"sW{?q%gG&ViI,$-");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.m_SumSqrErr;
      assertEquals(double1, double0, 0.01);
      assertEquals(0.0, double1, 0.01);
      
      int int0 = 6;
      double double2 = evaluation0.KBInformation();
      assertEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, double2, 0.01);
      
      Attribute attribute0 = new Attribute("@relation", 21);
      assertNotNull(attribute0);
      assertEquals(4, Attribute.RELATIONAL);
      assertEquals(2, Attribute.ORDERING_MODULO);
      assertEquals(1, Attribute.NOMINAL);
      assertEquals(2, Attribute.STRING);
      assertEquals(3, Attribute.DATE);
      assertEquals(0, Attribute.NUMERIC);
      assertEquals(0, Attribute.ORDERING_SYMBOLIC);
      assertEquals(1, Attribute.ORDERING_ORDERED);
      assertEquals(0, attribute0.numValues());
      assertTrue(attribute0.hasZeropoint());
      assertFalse(attribute0.isNominal());
      assertEquals(21, attribute0.index());
      assertEquals("@relation", attribute0.name());
      assertFalse(attribute0.isDate());
      assertFalse(attribute0.isRelationValued());
      assertEquals(0, attribute0.type());
      assertFalse(attribute0.isString());
      assertFalse(attribute0.lowerNumericBoundIsOpen());
      assertTrue(attribute0.isNumeric());
      assertFalse(attribute0.upperNumericBoundIsOpen());
      assertEquals(Double.NEGATIVE_INFINITY, attribute0.getLowerNumericBound(), 0.01);
      assertEquals(1.0, attribute0.weight(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, attribute0.getUpperNumericBound(), 0.01);
      assertEquals(1, attribute0.ordering());
      assertTrue(attribute0.isAveragable());
      assertEquals("", attribute0.getDateFormat());
      assertTrue(attribute0.isRegular());
      
      instances0.setClass(attribute0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(4, Attribute.RELATIONAL);
      assertEquals(2, Attribute.ORDERING_MODULO);
      assertEquals(1, Attribute.NOMINAL);
      assertEquals(2, Attribute.STRING);
      assertEquals(3, Attribute.DATE);
      assertEquals(0, Attribute.NUMERIC);
      assertEquals(0, Attribute.ORDERING_SYMBOLIC);
      assertEquals(1, Attribute.ORDERING_ORDERED);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(21, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, attribute0.numValues());
      assertTrue(attribute0.hasZeropoint());
      assertFalse(attribute0.isNominal());
      assertEquals(21, attribute0.index());
      assertEquals("@relation", attribute0.name());
      assertFalse(attribute0.isDate());
      assertFalse(attribute0.isRelationValued());
      assertEquals(0, attribute0.type());
      assertFalse(attribute0.isString());
      assertFalse(attribute0.lowerNumericBoundIsOpen());
      assertTrue(attribute0.isNumeric());
      assertFalse(attribute0.upperNumericBoundIsOpen());
      assertEquals(Double.NEGATIVE_INFINITY, attribute0.getLowerNumericBound(), 0.01);
      assertEquals(1.0, attribute0.weight(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, attribute0.getUpperNumericBound(), 0.01);
      assertEquals(1, attribute0.ordering());
      assertTrue(attribute0.isAveragable());
      assertEquals("", attribute0.getDateFormat());
      assertTrue(attribute0.isRegular());
      
      double double3 = evaluation0.trueNegativeRate(2);
      assertEquals(double3, double0, 0.01);
      assertEquals(double3, double2, 0.01);
      assertEquals(double3, double1, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(21, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, double3, 0.01);
      
      Enumeration enumeration0 = testInstances0.listOptions();
      assertNotNull(enumeration0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      
      double double4 = evaluation0.numTruePositives(1);
      assertEquals(double4, double2, 0.01);
      assertEquals(double4, double3, 0.01);
      assertEquals(double4, double0, 0.01);
      assertEquals(double4, double1, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(21, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, double4, 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.truePositiveRate(2);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 2
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.582160402760742
  */
  @Test(timeout = 4000)
  public void test020()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      evaluation0.m_SumErr = 0.0;
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      
      boolean boolean0 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertTrue(boolean0);
      
      double double1 = evaluation0.meanPriorAbsoluteError();
      assertNotEquals(double1, double0, 0.01);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = Double.NaN;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = (double) 2104;
      evaluation0.m_MarginCounts = doubleArray0;
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      
      double double2 = evaluation1.precision(2104);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      double double3 = evaluation1.relativeAbsoluteError();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotEquals(double3, double2, 0.01);
      assertEquals(double3, double1, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
      
      NaiveBayesMultinomial naiveBayesMultinomial0 = new NaiveBayesMultinomial();
      assertNotNull(naiveBayesMultinomial0);
      assertFalse(naiveBayesMultinomial0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", naiveBayesMultinomial0.debugTipText());
      
      RandomTree randomTree0 = new RandomTree();
      assertNotNull(randomTree0);
      assertEquals(0, randomTree0.getNumFolds());
      assertEquals("The maximum depth of the tree, 0 for unlimited.", randomTree0.maxDepthTipText());
      assertEquals("Determines the amount of data used for backfitting. One fold is used for backfitting, the rest for growing the tree. (Default: 0, no backfitting)", randomTree0.numFoldsTipText());
      assertEquals(1, randomTree0.numNodes());
      assertEquals("Whether to allow unclassified instances.", randomTree0.allowUnclassifiedInstancesTipText());
      assertEquals("Sets the number of randomly chosen attributes. If 0, log_2(number_of_attributes) + 1 is used.", randomTree0.KValueTipText());
      assertFalse(randomTree0.getAllowUnclassifiedInstances());
      assertEquals("The minimum total weight of the instances in a leaf.", randomTree0.minNumTipText());
      assertEquals("Class for constructing a tree that considers K randomly  chosen attributes at each node. Performs no pruning. Also has an option to allow estimation of class probabilities based on a hold-out set (backfitting).", randomTree0.globalInfo());
      assertEquals(1, randomTree0.graphType());
      assertEquals(1, randomTree0.getSeed());
      assertFalse(randomTree0.getDebug());
      assertEquals(1.0, randomTree0.getMinNum(), 0.01);
      assertEquals(1, randomTree0.numElements());
      assertEquals(0, randomTree0.getMaxDepth());
      assertEquals(0, randomTree0.getKValue());
      assertEquals("If set to true, classifier may output additional info to the console.", randomTree0.debugTipText());
      assertEquals("The random number seed used for selecting attributes.", randomTree0.seedTipText());
      
      AllFilter allFilter0 = new AllFilter();
      assertNotNull(allFilter0);
      assertEquals("An instance filter that passes all instances through unmodified. Primarily for testing purposes.", allFilter0.globalInfo());
      assertFalse(allFilter0.isFirstBatchDone());
      assertFalse(allFilter0.isOutputFormatDefined());
      assertTrue(allFilter0.isNewBatch());
      assertFalse(allFilter0.mayRemoveInstanceAfterFirstBatchDone());
      
      // Undeclared exception!
      try { 
        evaluation0.num2ShortID((-138), (char[]) null, 1344);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 21
  /*Coverage entropy=2.138275655767486
  */
  @Test(timeout = 4000)
  public void test021()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertNotNull(costSensitiveClassifier0);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      assertNotNull(costMatrix0);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals(1, costMatrix0.numColumns());
      assertEquals(1, costMatrix0.size());
      assertEquals(1, costMatrix0.numRows());
      
      double double0 = evaluation0.SFSchemeEntropy();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      MockRandom mockRandom0 = new MockRandom(2828L);
      assertNotNull(mockRandom0);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      
      Stacking stacking0 = new Stacking();
      assertNotNull(stacking0);
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertFalse(stacking0.getDebug());
      
      double double1 = evaluation0.weightedFalsePositiveRate();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      Instances instances1 = evaluation1.getHeader();
      assertNotNull(instances1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances0, instances1);
      assertNotSame(evaluation1, evaluation0);
      assertNotSame(instances1, instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(2, instances1.numClasses());
      assertEquals(0, instances1.numInstances());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals(2, instances1.numAttributes());
      assertEquals(1, instances1.classIndex());
      assertEquals("Testdata", instances1.relationName());
      assertFalse(instances1.checkForStringAttributes());
  }

  /**
  //Test case number: 22
  /*Coverage entropy=2.7973329543062766
  */
  @Test(timeout = 4000)
  public void test022()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      
      testInstances0.setNumNominal(111);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      
      double double0 = evaluation0.weightedAreaUnderROC();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.unweightedMacroFmeasure();
      assertEquals(double1, double0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.weightedAreaUnderPRC();
      assertEquals(double2, double0, 0.01);
      assertEquals(double2, double1, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation0.totalCost();
      assertNotEquals(double3, double0, 0.01);
      assertNotEquals(double3, double2, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, double3, 0.01);
      
      BayesNet bayesNet0 = new BayesNet();
      assertNotNull(bayesNet0);
      assertEquals("Select Estimator algorithm for finding the conditional probability tables of the Bayes Network.", bayesNet0.estimatorTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", bayesNet0.debugTipText());
      assertEquals("Set the name of a file in BIF XML format. A Bayes network learned from data can be compared with the Bayes network represented by the BIF file. Statistics calculated are o.a. the number of missing and extra arcs.", bayesNet0.BIFFileTipText());
      assertEquals(2, bayesNet0.graphType());
      assertEquals("Bayes Network learning using various search algorithms and quality measures.\nBase class for a Bayes Network classifier. Provides datastructures (network structure, conditional probability distributions, etc.) and facilities common to Bayes Network learning algorithms like K2 and B.\n\nFor more information see:\n\nhttp://www.cs.waikato.ac.nz/~remco/weka.pdf", bayesNet0.globalInfo());
      assertFalse(bayesNet0.getUseADTree());
      assertEquals("When ADTree (the data structure for increasing speed on counts, not to be confused with the classifier under the same name) is used learning time goes down typically. However, because ADTrees are memory intensive, memory problems may occur. Switching this option off makes the structure learning algorithms slower, and run with less memory. By default, ADTrees are used.", bayesNet0.useADTreeTipText());
      assertEquals("Select method used for searching network structures.", bayesNet0.searchAlgorithmTipText());
      assertFalse(bayesNet0.getDebug());
      
      String string0 = Evaluation.getGlobalInfo(bayesNet0);
      assertNotNull(string0);
      assertEquals("Select Estimator algorithm for finding the conditional probability tables of the Bayes Network.", bayesNet0.estimatorTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", bayesNet0.debugTipText());
      assertEquals("Set the name of a file in BIF XML format. A Bayes network learned from data can be compared with the Bayes network represented by the BIF file. Statistics calculated are o.a. the number of missing and extra arcs.", bayesNet0.BIFFileTipText());
      assertEquals(2, bayesNet0.graphType());
      assertEquals("Bayes Network learning using various search algorithms and quality measures.\nBase class for a Bayes Network classifier. Provides datastructures (network structure, conditional probability distributions, etc.) and facilities common to Bayes Network learning algorithms like K2 and B.\n\nFor more information see:\n\nhttp://www.cs.waikato.ac.nz/~remco/weka.pdf", bayesNet0.globalInfo());
      assertFalse(bayesNet0.getUseADTree());
      assertEquals("When ADTree (the data structure for increasing speed on counts, not to be confused with the classifier under the same name) is used learning time goes down typically. However, because ADTrees are memory intensive, memory problems may occur. Switching this option off makes the structure learning algorithms slower, and run with less memory. By default, ADTrees are used.", bayesNet0.useADTreeTipText());
      assertEquals("Select method used for searching network structures.", bayesNet0.searchAlgorithmTipText());
      assertFalse(bayesNet0.getDebug());
      assertEquals("\nSynopsis for weka.classifiers.bayes.BayesNet:\n\nBayes Network learning using various search algorithms and quality measures.\nBase class for a Bayes Network classifier. Provides datastructures (network structure, conditional probability distributions, etc.) and facilities common to Bayes Network learning algorithms like K2 and B.\n\nFor more information see:\n\nhttp://www.cs.waikato.ac.nz/~remco/weka.pdf", string0);
      
      double double4 = evaluation0.numInstances();
      assertNotEquals(double4, double1, 0.01);
      assertNotEquals(double4, double2, 0.01);
      assertNotEquals(double4, double0, 0.01);
      assertEquals(double4, double3, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, double4, 0.01);
  }

  /**
  //Test case number: 23
  /*Coverage entropy=3.2355606808791846
  */
  @Test(timeout = 4000)
  public void test023()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      
      testInstances0.setNumNominal(111);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      double double0 = evaluation0.weightedAreaUnderROC();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.unweightedMacroFmeasure();
      assertEquals(double1, double0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.weightedAreaUnderPRC();
      assertEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation0.totalCost();
      assertNotEquals(double3, double1, 0.01);
      assertNotEquals(double3, double2, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, double3, 0.01);
      
      BayesNet bayesNet0 = new BayesNet();
      assertNotNull(bayesNet0);
      assertEquals("Select Estimator algorithm for finding the conditional probability tables of the Bayes Network.", bayesNet0.estimatorTipText());
      assertEquals("Set the name of a file in BIF XML format. A Bayes network learned from data can be compared with the Bayes network represented by the BIF file. Statistics calculated are o.a. the number of missing and extra arcs.", bayesNet0.BIFFileTipText());
      assertEquals("Bayes Network learning using various search algorithms and quality measures.\nBase class for a Bayes Network classifier. Provides datastructures (network structure, conditional probability distributions, etc.) and facilities common to Bayes Network learning algorithms like K2 and B.\n\nFor more information see:\n\nhttp://www.cs.waikato.ac.nz/~remco/weka.pdf", bayesNet0.globalInfo());
      assertFalse(bayesNet0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", bayesNet0.debugTipText());
      assertFalse(bayesNet0.getUseADTree());
      assertEquals("When ADTree (the data structure for increasing speed on counts, not to be confused with the classifier under the same name) is used learning time goes down typically. However, because ADTrees are memory intensive, memory problems may occur. Switching this option off makes the structure learning algorithms slower, and run with less memory. By default, ADTrees are used.", bayesNet0.useADTreeTipText());
      assertEquals("Select method used for searching network structures.", bayesNet0.searchAlgorithmTipText());
      assertEquals(2, bayesNet0.graphType());
      
      double double4 = evaluation0.unweightedMicroFmeasure();
      assertEquals(double4, double0, 0.01);
      assertNotEquals(double4, double3, 0.01);
      assertEquals(double4, double1, 0.01);
      assertEquals(double4, double2, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double4, 0.01);
      
      double double5 = evaluation0.weightedFalsePositiveRate();
      assertEquals(double5, double2, 0.01);
      assertEquals(double5, double1, 0.01);
      assertNotEquals(double5, double3, 0.01);
      assertEquals(double5, double4, 0.01);
      assertEquals(double5, double0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double5, 0.01);
      
      String string0 = evaluation0.toCumulativeMarginDistributionString();
      assertNotNull(string0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(" -1       0    \n", string0);
      
      double double6 = evaluation0.avgCost();
      assertEquals(double6, double2, 0.01);
      assertEquals(double6, double4, 0.01);
      assertEquals(double6, double0, 0.01);
      assertEquals(double6, double5, 0.01);
      assertEquals(double6, double1, 0.01);
      assertNotEquals(double6, double3, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double6, 0.01);
      
      double double7 = evaluation0.weightedTruePositiveRate();
      assertEquals(double7, double2, 0.01);
      assertEquals(double7, double5, 0.01);
      assertEquals(double7, double1, 0.01);
      assertNotEquals(double7, double3, 0.01);
      assertEquals(double7, double6, 0.01);
      assertEquals(double7, double0, 0.01);
      assertEquals(double7, double4, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double7, 0.01);
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.6359220922659694
  */
  @Test(timeout = 4000)
  public void test024()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      TextDirectoryLoader textDirectoryLoader1 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader1);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      
      Instances instances0 = textDirectoryLoader1.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      double double0 = evaluation0.KBMeanInformation();
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.avgCost();
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertEquals(double1, double0, 0.01);
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      RandomForest randomForest0 = new RandomForest();
      assertNotNull(randomForest0);
      assertEquals(10, randomForest0.getNumTrees());
      assertEquals("The maximum depth of the trees, 0 for unlimited.", randomForest0.maxDepthTipText());
      assertFalse(randomForest0.getDebug());
      assertEquals("The number of attributes to be used in random selection (see RandomTree).", randomForest0.numFeaturesTipText());
      assertEquals(0, randomForest0.getMaxDepth());
      assertEquals(Double.NaN, randomForest0.measureOutOfBagError(), 0.01);
      assertFalse(randomForest0.getPrintTrees());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", randomForest0.numExecutionSlotsTipText());
      assertEquals(1, randomForest0.getNumExecutionSlots());
      assertEquals(1, randomForest0.getSeed());
      assertEquals("The random number seed to be used.", randomForest0.seedTipText());
      assertEquals(0, randomForest0.getNumFeatures());
      assertEquals("Print the individual trees in the output", randomForest0.printTreesTipText());
      assertEquals("The number of trees to be generated.", randomForest0.numTreesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", randomForest0.debugTipText());
      
      evaluation0.updateNumericScores((double[]) null, (double[]) null, Double.NaN);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      String string0 = evaluation0.toSummaryString();
      assertNotNull(string0);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals("\nTotal Number of Instances                0     \n", string0);
      
      double[] doubleArray0 = evaluation0.m_MarginCounts;
      assertNotNull(doubleArray0);
      assertEquals(501, doubleArray0.length);
      
      try { 
        evaluation0.evaluationForSingleInstance((double[]) null, (Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=2.7973329543062766
  */
  @Test(timeout = 4000)
  public void test025()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      testInstances0.setNumNominal(111);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      
      double double0 = evaluation0.weightedAreaUnderROC();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.unweightedMacroFmeasure();
      assertEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.weightedAreaUnderPRC();
      assertEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation0.totalCost();
      assertNotEquals(double3, double2, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, double3, 0.01);
      
      BayesNet bayesNet0 = new BayesNet();
      assertNotNull(bayesNet0);
      assertEquals("Select Estimator algorithm for finding the conditional probability tables of the Bayes Network.", bayesNet0.estimatorTipText());
      assertEquals("Select method used for searching network structures.", bayesNet0.searchAlgorithmTipText());
      assertEquals(2, bayesNet0.graphType());
      assertEquals("If set to true, classifier may output additional info to the console.", bayesNet0.debugTipText());
      assertFalse(bayesNet0.getDebug());
      assertEquals("Bayes Network learning using various search algorithms and quality measures.\nBase class for a Bayes Network classifier. Provides datastructures (network structure, conditional probability distributions, etc.) and facilities common to Bayes Network learning algorithms like K2 and B.\n\nFor more information see:\n\nhttp://www.cs.waikato.ac.nz/~remco/weka.pdf", bayesNet0.globalInfo());
      assertEquals("Set the name of a file in BIF XML format. A Bayes network learned from data can be compared with the Bayes network represented by the BIF file. Statistics calculated are o.a. the number of missing and extra arcs.", bayesNet0.BIFFileTipText());
      assertFalse(bayesNet0.getUseADTree());
      assertEquals("When ADTree (the data structure for increasing speed on counts, not to be confused with the classifier under the same name) is used learning time goes down typically. However, because ADTrees are memory intensive, memory problems may occur. Switching this option off makes the structure learning algorithms slower, and run with less memory. By default, ADTrees are used.", bayesNet0.useADTreeTipText());
      
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = Double.NaN;
      doubleArray0[2] = (double) 111;
      doubleArray0[3] = 0.0;
      doubleArray0[4] = (double) 111;
      doubleArray0[5] = (double) (-2);
      doubleArray0[6] = (double) (-2);
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray0, (Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=2.031298644335524
  */
  @Test(timeout = 4000)
  public void test026()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      double double0 = evaluation0.avgCost();
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      try { 
        evaluation0.evaluateModelOnce(Double.NaN, (Instance) null);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.1693376567504215
  */
  @Test(timeout = 4000)
  public void test027()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      evaluation0.m_SumErr = 0.0;
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      
      double double1 = evaluation0.meanPriorAbsoluteError();
      assertNotEquals(double1, double0, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = Double.NaN;
      doubleArray0[2] = (double) 2104;
      doubleArray0[3] = (double) 2104;
      evaluation0.m_MarginCounts = doubleArray0;
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      
      double double2 = evaluation0.falsePositiveRate(2104);
      assertNotEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      double double3 = evaluation0.unweightedMacroFmeasure();
      assertEquals(double3, double1, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertNotEquals(double3, double2, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
      
      double double4 = evaluation0.weightedAreaUnderPRC();
      assertEquals(double4, double1, 0.01);
      assertNotEquals(double4, double0, 0.01);
      assertEquals(double4, double3, 0.01);
      assertNotEquals(double4, double2, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, double4, 0.01);
      
      double double5 = evaluation0.totalCost();
      assertEquals(double5, double0, 0.01);
      assertNotEquals(double5, double3, 0.01);
      assertNotEquals(double5, double1, 0.01);
      assertNotEquals(double5, double4, 0.01);
      assertEquals(double5, double2, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, double5, 0.01);
      
      String string0 = instances0.toSummaryString();
      assertNotNull(string0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Relation Name:  _home_ubuntu_termite_projects_107_weka\nNum Instances:  0\nNum Attributes: 2\n\n     Name                      Type  Nom  Int Real     Missing      Unique  Dist\n   1 text                       Str   0%   0%   0%     0 /  0%     0 /  0%     0 \n   2 @@class@@                  Nom   0%   0%   0%     0 /  0%     0 /  0%     0 \n", string0);
      
      try { 
        evaluation0.updateStatsForPredictor((-1001.5553456715476), (Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=1.1746286620414268
  */
  @Test(timeout = 4000)
  public void test028()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      TextDirectoryLoader textDirectoryLoader1 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader1);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      
      Instances instances0 = textDirectoryLoader1.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      evaluation0.setPriors(instances0);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(0, doubleArray0.length);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.weightedMatthewsCorrelation();
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.numFalseNegatives(89);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      double double3 = evaluation0.SFMeanSchemeEntropy();
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertEquals(double3, double1, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertNotEquals(double3, double2, 0.01);
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
      
      double[] doubleArray1 = evaluation0.getClassPriors();
      assertNotNull(doubleArray1);
      assertEquals(0, doubleArray1.length);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertArrayEquals(new double[] {}, doubleArray1, 0.01);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double double4 = evaluation0.SFMeanSchemeEntropy();
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertEquals(double4, double1, 0.01);
      assertNotEquals(double4, double2, 0.01);
      assertNotEquals(double4, double0, 0.01);
      assertEquals(double4, double3, 0.01);
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double4, 0.01);
      
      double double5 = evaluation0.numTruePositives(89);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotEquals(double5, double1, 0.01);
      assertNotEquals(double5, double3, 0.01);
      assertEquals(double5, double2, 0.01);
      assertNotEquals(double5, double4, 0.01);
      assertEquals(double5, double0, 0.01);
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, double5, 0.01);
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(89);
      assertNotNull(binarySparseInstance0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(89, binarySparseInstance0.numAttributes());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(89, binarySparseInstance0.numValues());
      
      try { 
        evaluation0.updateStatsForPredictor(0.0, binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.1693376567504215
  */
  @Test(timeout = 4000)
  public void test029()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(0, doubleArray0.length);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      
      double double0 = evaluation0.precision((-351));
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.relativeAbsoluteError();
      assertNotEquals(double1, double0, 0.01);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      NaiveBayesMultinomial naiveBayesMultinomial0 = new NaiveBayesMultinomial();
      assertNotNull(naiveBayesMultinomial0);
      assertEquals("If set to true, classifier may output additional info to the console.", naiveBayesMultinomial0.debugTipText());
      assertFalse(naiveBayesMultinomial0.getDebug());
      
      double[] doubleArray1 = evaluation0.evaluateModel((Classifier) naiveBayesMultinomial0, instances0, (Object[]) doubleArray0);
      assertNotNull(doubleArray1);
      assertEquals(0, doubleArray0.length);
      assertEquals(0, doubleArray1.length);
      assertArrayEquals(new double[] {}, doubleArray1, 0.01);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", naiveBayesMultinomial0.debugTipText());
      assertFalse(naiveBayesMultinomial0.getDebug());
      
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray1, (Instance) null, true);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=2.3112881430321695
  */
  @Test(timeout = 4000)
  public void test030()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      double double0 = evaluation0.avgCost();
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.meanPriorAbsoluteError();
      assertEquals(double1, double0, 0.01);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, double1, 0.01);
      
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      boolean boolean0 = FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      assertTrue(boolean0);
      
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (double) 2104;
      doubleArray0[1] = Double.NaN;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(Double.NaN, doubleArray0);
      assertNotNull(binarySparseInstance0);
      assertEquals(2, doubleArray0.length);
      assertArrayEquals(new double[] {2104.0, Double.NaN}, doubleArray0, 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(2, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.numValues());
      assertEquals(Double.NaN, binarySparseInstance0.weight(), 0.01);
      
      boolean boolean1 = FileSystemHandling.createFolder(evoSuiteFile0);
      assertTrue(boolean1 == boolean0);
      assertTrue(boolean1);
      
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      assertNotNull(binarySparseInstance1);
      assertEquals(2, doubleArray0.length);
      assertFalse(binarySparseInstance1.equals((Object)binarySparseInstance0));
      assertArrayEquals(new double[] {2104.0, Double.NaN}, doubleArray0, 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(2, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.numValues());
      assertEquals(Double.NaN, binarySparseInstance0.weight(), 0.01);
      assertEquals(2, binarySparseInstance1.numValues());
      assertEquals(Double.NaN, binarySparseInstance1.weight(), 0.01);
      assertEquals(2, binarySparseInstance1.numAttributes());
      
      Instances instances1 = binarySparseInstance0.dataset();
      assertNull(instances1);
      assertEquals(2, doubleArray0.length);
      assertFalse(binarySparseInstance0.equals((Object)binarySparseInstance1));
      assertNotSame(binarySparseInstance0, binarySparseInstance1);
      assertArrayEquals(new double[] {2104.0, Double.NaN}, doubleArray0, 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(2, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.numValues());
      assertEquals(Double.NaN, binarySparseInstance0.weight(), 0.01);
      
      boolean boolean2 = evaluation0.equals(evoSuiteFile0);
      assertFalse(boolean2 == boolean1);
      assertFalse(boolean2 == boolean0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertFalse(boolean2);
      
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      assertNotNull(serializedClassifier0);
      assertEquals("If set to true, classifier may output additional info to the console.", serializedClassifier0.debugTipText());
      assertFalse(serializedClassifier0.getDebug());
      assertEquals("A wrapper around a serialized classifier model. This classifier loads a serialized models and uses it to make predictions.\n\nWarning: since the serialized model doesn't get changed, cross-validation cannot bet used with this classifier.", serializedClassifier0.globalInfo());
      assertEquals("The serialized classifier model to use for predictions.", serializedClassifier0.modelFileTipText());
      
      Classifier classifier0 = serializedClassifier0.getCurrentModel();
      assertNull(classifier0);
      assertEquals("If set to true, classifier may output additional info to the console.", serializedClassifier0.debugTipText());
      assertFalse(serializedClassifier0.getDebug());
      assertEquals("A wrapper around a serialized classifier model. This classifier loads a serialized models and uses it to make predictions.\n\nWarning: since the serialized model doesn't get changed, cross-validation cannot bet used with this classifier.", serializedClassifier0.globalInfo());
      assertEquals("The serialized classifier model to use for predictions.", serializedClassifier0.modelFileTipText());
      
      Classifier classifier1 = AbstractClassifier.makeCopy((Classifier) null);
      assertNull(classifier1);
      
      try { 
        evaluation0.evaluationForSingleInstance((Classifier) null, (Instance) binarySparseInstance1, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 31
  /*Coverage entropy=2.219177595605963
  */
  @Test(timeout = 4000)
  public void test031()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      boolean boolean0 = FileSystemHandling.createFolder(evoSuiteFile0);
      assertTrue(boolean0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      evaluation0.setPriors(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      
      Evaluation evaluation2 = new Evaluation(instances0);
      assertNotNull(evaluation2);
      assertTrue(evaluation2.equals((Object)evaluation1));
      assertTrue(evaluation2.equals((Object)evaluation0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation2.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation2.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation2.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation2.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.errorRate(), 0.01);
      assertEquals(0.0, evaluation2.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation2.rootRelativeSquaredError(), 0.01);
      assertEquals(1.0, evaluation2.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation2.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation2.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation2.numInstances(), 0.01);
      assertEquals(0.0, evaluation2.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation2.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation2.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation2.correct(), 0.01);
      assertEquals(Double.NaN, evaluation2.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation2.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation2.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation2.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation2.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation2.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation2.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation2.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedRecall(), 0.01);
      
      double double0 = evaluation1.SFEntropyGain();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertTrue(evaluation1.equals((Object)evaluation2));
      assertNotSame(evaluation1, evaluation2);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      PipedReader pipedReader0 = new PipedReader();
      assertNotNull(pipedReader0);
      
      Double double1 = new Double(0.0);
      assertNotNull(double1);
      assertEquals((double)double1, (double)double0, 0.01);
      assertEquals(0.0, (double)double1, 0.01);
      
      NaiveBayesUpdateable naiveBayesUpdateable0 = new NaiveBayesUpdateable();
      assertNotNull(naiveBayesUpdateable0);
      assertEquals("Use old format for model output. The old format is better when there are many class values. The new format is better when there are fewer classes and many attributes.", naiveBayesUpdateable0.displayModelInOldFormatTipText());
      assertEquals("Use supervised discretization to convert numeric attributes to nominal ones.", naiveBayesUpdateable0.useSupervisedDiscretizationTipText());
      assertEquals("Use a kernel estimator for numeric attributes rather than a normal distribution.", naiveBayesUpdateable0.useKernelEstimatorTipText());
      assertFalse(naiveBayesUpdateable0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", naiveBayesUpdateable0.debugTipText());
      assertFalse(naiveBayesUpdateable0.getUseSupervisedDiscretization());
      assertFalse(naiveBayesUpdateable0.getUseKernelEstimator());
      assertFalse(naiveBayesUpdateable0.getDisplayModelInOldFormat());
      
      String string0 = Evaluation.getGlobalInfo(naiveBayesUpdateable0);
      assertNotNull(string0);
      assertEquals("Use old format for model output. The old format is better when there are many class values. The new format is better when there are fewer classes and many attributes.", naiveBayesUpdateable0.displayModelInOldFormatTipText());
      assertEquals("Use supervised discretization to convert numeric attributes to nominal ones.", naiveBayesUpdateable0.useSupervisedDiscretizationTipText());
      assertEquals("Use a kernel estimator for numeric attributes rather than a normal distribution.", naiveBayesUpdateable0.useKernelEstimatorTipText());
      assertFalse(naiveBayesUpdateable0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", naiveBayesUpdateable0.debugTipText());
      assertFalse(naiveBayesUpdateable0.getUseSupervisedDiscretization());
      assertFalse(naiveBayesUpdateable0.getUseKernelEstimator());
      assertFalse(naiveBayesUpdateable0.getDisplayModelInOldFormat());
      assertEquals("\nSynopsis for weka.classifiers.bayes.NaiveBayesUpdateable:\n\nClass for a Naive Bayes classifier using estimator classes. This is the updateable version of NaiveBayes.\nThis classifier will use a default precision of 0.1 for numeric attributes when buildClassifier is called with zero training instances.\n\nFor more information on Naive Bayes classifiers, see\n\nGeorge H. John, Pat Langley: Estimating Continuous Distributions in Bayesian Classifiers. In: Eleventh Conference on Uncertainty in Artificial Intelligence, San Mateo, 338-345, 1995.", string0);
      
      double double2 = evaluation1.trueNegativeRate((-2));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertTrue(evaluation1.equals((Object)evaluation2));
      assertEquals(double2, double0, 0.01);
      assertNotSame(evaluation1, evaluation2);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      DatabaseLoader databaseLoader0 = new DatabaseLoader();
      assertNotNull(databaseLoader0);
      assertEquals("The user name for the database", databaseLoader0.userTipText());
      assertEquals("Encode data as sparse instances.", databaseLoader0.sparseDataTipText());
      assertEquals("", databaseLoader0.getUser());
      assertEquals("The query that should load the instances.\n The query has to be of the form SELECT <column-list>|* FROM <table> [WHERE <conditions>]", databaseLoader0.queryTipText());
      assertEquals("For incremental loading a unique identiefer has to be specified.\nIf the query includes all columns of a table (SELECT *...) a primary key\ncan be detected automatically depending on the JDBC driver. If that is not possible\nspecify the key columns here in a comma separated list.", databaseLoader0.keysTipText());
      assertFalse(databaseLoader0.getSparseData());
      assertEquals("Select * from Results0", databaseLoader0.getQuery());
      assertEquals("The custom properties that the user can use to override the default ones.", databaseLoader0.customPropsFileTipText());
      assertEquals("The URL of the database", databaseLoader0.urlTipText());
      assertEquals("jdbc:idb=experiments.prp", databaseLoader0.getUrl());
      assertEquals("The database password", databaseLoader0.passwordTipText());
      assertEquals("", databaseLoader0.getPassword());
      
      Instance instance0 = databaseLoader0.getNextInstance(instances0);
      assertNull(instance0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("The user name for the database", databaseLoader0.userTipText());
      assertEquals("Encode data as sparse instances.", databaseLoader0.sparseDataTipText());
      assertEquals("", databaseLoader0.getUser());
      assertEquals("The query that should load the instances.\n The query has to be of the form SELECT <column-list>|* FROM <table> [WHERE <conditions>]", databaseLoader0.queryTipText());
      assertEquals("For incremental loading a unique identiefer has to be specified.\nIf the query includes all columns of a table (SELECT *...) a primary key\ncan be detected automatically depending on the JDBC driver. If that is not possible\nspecify the key columns here in a comma separated list.", databaseLoader0.keysTipText());
      assertFalse(databaseLoader0.getSparseData());
      assertEquals("Select * from Results0", databaseLoader0.getQuery());
      assertEquals("The custom properties that the user can use to override the default ones.", databaseLoader0.customPropsFileTipText());
      assertEquals("The URL of the database", databaseLoader0.urlTipText());
      assertEquals("jdbc:idb=experiments.prp", databaseLoader0.getUrl());
      assertEquals("The database password", databaseLoader0.passwordTipText());
      assertEquals("", databaseLoader0.getPassword());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      
      try { 
        evaluation0.evaluationForSingleInstance((Classifier) multilayerPerceptron0, (Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 32
  /*Coverage entropy=2.463799917782297
  */
  @Test(timeout = 4000)
  public void test032()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      
      testInstances0.setNumNominal(111);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      
      boolean boolean0 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertTrue(boolean0);
      
      boolean boolean1 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertFalse(boolean1 == boolean0);
      assertFalse(boolean1);
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(112, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(112, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(112, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      Integer integer0 = new Integer(5);
      assertNotNull(integer0);
      assertEquals(5, (int)integer0);
      
      String string0 = evaluation0.toSummaryString(false);
      assertNotNull(string0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(112, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals("=== Summary ===\n\nTotal Number of Instances                0     \n", string0);
      
      double double1 = evaluation0.falseNegativeRate((-2));
      assertEquals(double1, double0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(112, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, double1, 0.01);
      
      String string1 = evaluation0.toSummaryString(false);
      assertNotNull(string1);
      assertTrue(string1.equals((Object)string0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(112, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals("=== Summary ===\n\nTotal Number of Instances                0     \n", string1);
      
      double[] doubleArray0 = new double[0];
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      boolean boolean2 = FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      assertTrue(boolean2 == boolean0);
      assertFalse(boolean2 == boolean1);
      assertTrue(boolean2);
      
      boolean boolean3 = FileSystemHandling.createFolder(evoSuiteFile0);
      assertFalse(boolean3 == boolean1);
      assertTrue(boolean3 == boolean2);
      assertTrue(boolean3 == boolean0);
      assertTrue(boolean3);
      
      boolean boolean4 = evaluation0.equals((Object) null);
      assertFalse(boolean4 == boolean0);
      assertTrue(boolean4 == boolean1);
      assertFalse(boolean4 == boolean3);
      assertFalse(boolean4 == boolean2);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(112, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(boolean4);
      
      double double2 = evaluation0.numTruePositives((-2));
      assertEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(112, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, double2, 0.01);
  }

  /**
  //Test case number: 33
  /*Coverage entropy=2.4707987632218065
  */
  @Test(timeout = 4000)
  public void test033()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      testInstances0.setNumRelationalNominalValues((-141));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      
      double double0 = evaluation0.m_ClassPriorsSum;
      assertEquals(22.0, double0, 0.01);
      
      double double1 = evaluation0.rootRelativeSquaredError();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.matthewsCorrelationCoefficient((-2));
      assertNotEquals(double2, double0, 0.01);
      assertNotEquals(double2, double1, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      evaluation0.addNumericTrainClass((-2), 5.0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      
      double double3 = evaluation0.m_Unclassified;
      assertNotEquals(double3, double1, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertEquals(double3, double2, 0.01);
      assertEquals(0.0, double3, 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(2, doubleArray0.length);
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      double double4 = evaluation0.SFMeanSchemeEntropy();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotEquals(double4, double2, 0.01);
      assertNotEquals(double4, double0, 0.01);
      assertEquals(double4, double1, 0.01);
      assertNotEquals(double4, double3, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double4, 0.01);
      
      double double5 = evaluation1.numInstances();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotEquals(double5, double4, 0.01);
      assertEquals(double5, double3, 0.01);
      assertNotEquals(double5, double0, 0.01);
      assertEquals(double5, double2, 0.01);
      assertNotEquals(double5, double1, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, double5, 0.01);
      
      String string0 = evaluation0.toClassDetailsString("S");
      assertNotNull(string0);
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals("S\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\n                 0        0        0          0       0          0     ?         ?         class1\n                 0        0        0          0       0          0     ?         ?         class2\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
      
      String string1 = evaluation1.toSummaryString();
      assertNotNull(string1);
      assertFalse(string1.equals((Object)string0));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals("\nTotal Number of Instances                0     \n", string1);
      
      double double6 = evaluation0.weightedFMeasure();
      assertEquals(double6, double4, 0.01);
      assertNotEquals(double6, double3, 0.01);
      assertEquals(double6, double1, 0.01);
      assertNotEquals(double6, double2, 0.01);
      assertNotEquals(double6, double5, 0.01);
      assertNotEquals(double6, double0, 0.01);
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, double6, 0.01);
      
      evaluation0.setNumericPriorsFromBuffer();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-141), testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=1.6999267696231979
  */
  @Test(timeout = 4000)
  public void test034()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      
      PoissonEstimator poissonEstimator0 = new PoissonEstimator();
      assertNotNull(poissonEstimator0);
      assertEquals("If set to true, estimator may output additional info to the console.", poissonEstimator0.debugTipText());
      assertFalse(poissonEstimator0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      
      String string0 = instances0.toSummaryString();
      assertNotNull(string0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("Relation Name:  _home_ubuntu_termite_projects_107_weka\nNum Instances:  0\nNum Attributes: 2\n\n     Name                      Type  Nom  Int Real     Missing      Unique  Dist\n   1 text                       Str   0%   0%   0%     0 /  0%     0 /  0%     0 \n   2 @@class@@                  Nom   0%   0%   0%     0 /  0%     0 /  0%     0 \n", string0);
      
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      char[] charArray0 = new char[5];
      charArray0[0] = 's';
      charArray0[1] = 'G';
      charArray0[2] = 'h';
      charArray0[3] = 'B';
      charArray0[4] = 'f';
      // Undeclared exception!
      try { 
        evaluation0.num2ShortID((-1), charArray0, (-2));
        fail("Expecting exception: NegativeArraySizeException");
      
      } catch(NegativeArraySizeException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 35
  /*Coverage entropy=0.47619047619047616
  */
  @Test(timeout = 4000)
  public void test035()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      TextDirectoryLoader textDirectoryLoader1 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader1);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader1.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      evaluation0.setPriors(instances0);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(0, doubleArray0.length);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      
      double[] doubleArray1 = new double[2];
      char[] charArray0 = new char[3];
      charArray0[0] = '_';
      charArray0[1] = '^';
      charArray0[2] = 'w';
      String string0 = evaluation1.num2ShortID(3620, charArray0, 3620);
      assertNotNull(string0);
      assertEquals(3, charArray0.length);
      assertFalse(textDirectoryLoader1.equals((Object)textDirectoryLoader0));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotSame(textDirectoryLoader1, textDirectoryLoader0);
      assertNotSame(evaluation1, evaluation0);
      assertArrayEquals(new char[] {'_', '^', 'w'}, charArray0);
      assertEquals("", textDirectoryLoader1.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader1.debugTipText());
      assertEquals("Directories", textDirectoryLoader1.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader1.charSetTipText());
      assertFalse(textDirectoryLoader1.getDebug());
      assertFalse(textDirectoryLoader1.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader1.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader1.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      
      doubleArray1[0] = (double) (-1101);
      doubleArray1[1] = (-1109.97811);
      // Undeclared exception!
      try { 
        evaluation1.updateMargins(doubleArray1, 108, 145.7393817474616);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 108
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=1.163735415854063
  */
  @Test(timeout = 4000)
  public void test036()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      
      double double0 = evaluation0.m_SumKBInfo;
      assertEquals(0.0, double0, 0.01);
      
      RandomForest randomForest0 = new RandomForest();
      assertNotNull(randomForest0);
      assertEquals("If set to true, classifier may output additional info to the console.", randomForest0.debugTipText());
      assertEquals(10, randomForest0.getNumTrees());
      assertEquals("Print the individual trees in the output", randomForest0.printTreesTipText());
      assertEquals("The maximum depth of the trees, 0 for unlimited.", randomForest0.maxDepthTipText());
      assertEquals(1, randomForest0.getSeed());
      assertEquals(0, randomForest0.getNumFeatures());
      assertEquals("The number of trees to be generated.", randomForest0.numTreesTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", randomForest0.numExecutionSlotsTipText());
      assertFalse(randomForest0.getDebug());
      assertEquals("The random number seed to be used.", randomForest0.seedTipText());
      assertEquals("The number of attributes to be used in random selection (see RandomTree).", randomForest0.numFeaturesTipText());
      assertFalse(randomForest0.getPrintTrees());
      assertEquals(1, randomForest0.getNumExecutionSlots());
      assertEquals(0, randomForest0.getMaxDepth());
      assertEquals(Double.NaN, randomForest0.measureOutOfBagError(), 0.01);
      
      evaluation0.updateNumericScores((double[]) null, (double[]) null, 0.0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      
      double double1 = evaluation0.meanPriorAbsoluteError();
      assertNotEquals(double1, double0, 0.01);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      String string0 = evaluation0.getRevision();
      assertNotNull(string0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals("9101", string0);
      
      char[] charArray0 = new char[5];
      charArray0[0] = 'f';
      charArray0[1] = 'u';
      charArray0[2] = 'o';
      charArray0[3] = 'j';
      charArray0[4] = 'S';
      String string1 = evaluation0.num2ShortID(20, charArray0, 20);
      assertNotNull(string1);
      assertEquals(5, charArray0.length);
      assertFalse(string1.equals((Object)string0));
      assertArrayEquals(new char[] {'f', 'u', 'o', 'j', 'S'}, charArray0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals("                  jf", string1);
      
      double double2 = evaluation0.SFEntropyGain();
      assertNotEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, double2, 0.01);
  }

  /**
  //Test case number: 37
  /*Coverage entropy=1.3368883075390159
  */
  @Test(timeout = 4000)
  public void test037()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      
      testInstances0.setNumNominal(111);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      
      boolean boolean0 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertTrue(boolean0);
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = (double) (-2);
      doubleArray0[1] = (double) 111;
      doubleArray0[2] = (-2240.1924999);
      doubleArray0[3] = (-1418.7422);
      doubleArray0[4] = 251.0;
      doubleArray0[5] = (double) (-1);
      doubleArray0[6] = 251.0;
      doubleArray0[7] = (double) (-1);
      DenseInstance denseInstance0 = new DenseInstance(251.0, doubleArray0);
      assertNotNull(denseInstance0);
      assertEquals(8, doubleArray0.length);
      assertArrayEquals(new double[] {(-2.0), 111.0, (-2240.1924999), (-1418.7422), 251.0, (-1.0), 251.0, (-1.0)}, doubleArray0, 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(8, denseInstance0.numAttributes());
      assertEquals(251.0, denseInstance0.weight(), 0.01);
      assertEquals(8, denseInstance0.numValues());
      
      boolean boolean1 = instances0.add((Instance) denseInstance0);
      assertEquals(8, doubleArray0.length);
      assertTrue(boolean1 == boolean0);
      assertArrayEquals(new double[] {(-2.0), 111.0, (-2240.1924999), (-1418.7422), 251.0, (-1.0), 251.0, (-1.0)}, doubleArray0, 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(8, denseInstance0.numAttributes());
      assertEquals(251.0, denseInstance0.weight(), 0.01);
      assertEquals(8, denseInstance0.numValues());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(1, instances0.numInstances());
      assertEquals(251.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertTrue(boolean1);
      
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation(instances0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 38
  /*Coverage entropy=3.576617555974212
  */
  @Test(timeout = 4000)
  public void test038()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      
      testInstances0.setNumNominal(111);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.weightedMatthewsCorrelation();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(2, doubleArray0.length);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      String[] stringArray0 = new String[0];
      testInstances0.setOptions(stringArray0);
      assertEquals(0, stringArray0.length);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      
      double double2 = evaluation0.SFMeanSchemeEntropy();
      assertEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation0.numFalsePositives(111);
      assertNotEquals(double3, double2, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertEquals(double3, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, double3, 0.01);
      
      String string0 = evaluation0.toClassDetailsString(".bsi");
      assertNotNull(string0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(".bsi\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\n                 0        0        0          0       0          0     ?         ?         class1\n                 0        0        0          0       0          0     ?         ?         class2\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
  }

  /**
  //Test case number: 39
  /*Coverage entropy=2.1049561813316413
  */
  @Test(timeout = 4000)
  public void test039()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      double double0 = evaluation0.m_SumKBInfo;
      assertEquals(0.0, double0, 0.01);
      
      evaluation0.updateNumericScores((double[]) null, (double[]) null, 0.0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertNotNull(costSensitiveClassifier0);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals(0, costSensitiveClassifier0.graphType());
      
      double double1 = evaluation0.SFSchemeEntropy();
      assertEquals(double1, double0, 0.01);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, double1, 0.01);
      
      double double2 = evaluation0.numFalsePositives(2);
      assertEquals(double2, double0, 0.01);
      assertEquals(double2, double1, 0.01);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, double2, 0.01);
  }

  /**
  //Test case number: 40
  /*Coverage entropy=1.1714080501251627
  */
  @Test(timeout = 4000)
  public void test040()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      
      Instances instances0 = testInstances0.generate("ov\"qW{8?q%gG&6iI,$-");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      testInstances0.setNumRelationalNominal((-786));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-786), testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      
      NaiveBayesUpdateable naiveBayesUpdateable0 = new NaiveBayesUpdateable();
      assertNotNull(naiveBayesUpdateable0);
      assertFalse(naiveBayesUpdateable0.getUseKernelEstimator());
      assertEquals("Use old format for model output. The old format is better when there are many class values. The new format is better when there are fewer classes and many attributes.", naiveBayesUpdateable0.displayModelInOldFormatTipText());
      assertFalse(naiveBayesUpdateable0.getDisplayModelInOldFormat());
      assertEquals("Use supervised discretization to convert numeric attributes to nominal ones.", naiveBayesUpdateable0.useSupervisedDiscretizationTipText());
      assertFalse(naiveBayesUpdateable0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", naiveBayesUpdateable0.debugTipText());
      assertEquals("Use a kernel estimator for numeric attributes rather than a normal distribution.", naiveBayesUpdateable0.useKernelEstimatorTipText());
      assertFalse(naiveBayesUpdateable0.getUseSupervisedDiscretization());
      
      double double0 = evaluation0.falsePositiveRate(100000);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-786), testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.unweightedMacroFmeasure();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-786), testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.totalCost();
      assertNotEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-786), testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      double double3 = evaluation0.numTrueNegatives(652);
      assertEquals(double3, double0, 0.01);
      assertEquals(double3, double2, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-786), testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, double3, 0.01);
  }

  /**
  //Test case number: 41
  /*Coverage entropy=3.0864377866667283
  */
  @Test(timeout = 4000)
  public void test041()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      
      testInstances0.setNumNominal(111);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      
      boolean boolean0 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertTrue(boolean0);
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.m_SumPriorAbsErr;
      assertEquals(double1, double0, 0.01);
      assertEquals(0.0, double1, 0.01);
      
      double double2 = evaluation0.numFalseNegatives((-1));
      assertEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(2, doubleArray0.length);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      double[] doubleArray1 = evaluation0.getClassPriors();
      assertNotNull(doubleArray1);
      assertEquals(2, doubleArray1.length);
      assertArrayEquals(new double[] {12.0, 10.0}, doubleArray1, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      double double3 = evaluation0.SFMeanSchemeEntropy();
      assertNotEquals(double3, double2, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
      
      double double4 = evaluation0.matthewsCorrelationCoefficient(5);
      assertEquals(double4, double0, 0.01);
      assertNotEquals(double4, double3, 0.01);
      assertEquals(double4, double2, 0.01);
      assertEquals(double4, double1, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, double4, 0.01);
      
      double double5 = evaluation0.areaUnderPRC((-2));
      assertEquals(double5, double3, 0.01);
      assertNotEquals(double5, double2, 0.01);
      assertNotEquals(double5, double1, 0.01);
      assertNotEquals(double5, double4, 0.01);
      assertNotEquals(double5, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, double5, 0.01);
      
      double double6 = evaluation0.sizeOfPredictedRegions();
      assertNotEquals(double6, double4, 0.01);
      assertNotEquals(double6, double2, 0.01);
      assertNotEquals(double6, double1, 0.01);
      assertEquals(double6, double5, 0.01);
      assertNotEquals(double6, double0, 0.01);
      assertEquals(double6, double3, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, double6, 0.01);
      
      double double7 = evaluation0.areaUnderROC(5);
      assertNotEquals(double7, double1, 0.01);
      assertEquals(double7, double6, 0.01);
      assertNotEquals(double7, double4, 0.01);
      assertEquals(double7, double3, 0.01);
      assertNotEquals(double7, double0, 0.01);
      assertEquals(double7, double5, 0.01);
      assertNotEquals(double7, double2, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, double7, 0.01);
      
      double double8 = evaluation0.SFPriorEntropy();
      assertNotEquals(double8, double3, 0.01);
      assertNotEquals(double8, double6, 0.01);
      assertEquals(double8, double2, 0.01);
      assertEquals(double8, double1, 0.01);
      assertNotEquals(double8, double5, 0.01);
      assertNotEquals(double8, double7, 0.01);
      assertEquals(double8, double4, 0.01);
      assertEquals(double8, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, double8, 0.01);
      
      DenseInstance denseInstance0 = new DenseInstance((-1000.0822412732), doubleArray1);
      assertNotNull(denseInstance0);
      assertEquals(2, doubleArray1.length);
      assertArrayEquals(new double[] {12.0, 10.0}, doubleArray1, 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, denseInstance0.numValues());
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals((-1000.0822412732), denseInstance0.weight(), 0.01);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      try { 
        evaluation0.updateStatsForClassifier(doubleArray1, denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 42
  /*Coverage entropy=2.272539375087381
  */
  @Test(timeout = 4000)
  public void test042()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      
      multilayerPerceptron0.setTrainingTime(371);
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(371, multilayerPerceptron0.getTrainingTime());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(371, multilayerPerceptron0.getTrainingTime());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      
      String string0 = testInstances0.getWords();
      assertNotNull(string0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("The,quick,brown,fox,jumps,over,the,lazy,dog", string0);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      double double0 = evaluation0.meanPriorAbsoluteError();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.areaUnderROC(371);
      assertEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      String string1 = evaluation0.getRevision();
      assertNotNull(string1);
      assertFalse(string1.equals((Object)string0));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals("9101", string1);
      
      double double2 = evaluation0.m_SumErr;
      assertNotEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      assertEquals(0.0, double2, 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.fMeasure((-2));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -2
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 43
  /*Coverage entropy=1.1270802060306617
  */
  @Test(timeout = 4000)
  public void test043()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      
      CostMatrix costMatrix0 = Evaluation.handleCostOption("", 3026);
      assertNull(costMatrix0);
      
      AdditiveRegression additiveRegression0 = new AdditiveRegression();
      assertNotNull(additiveRegression0);
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertFalse(additiveRegression0.getDebug());
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      
      Capabilities capabilities0 = additiveRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertFalse(additiveRegression0.getDebug());
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertFalse(additiveRegression0.getDebug());
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      
      testInstances0.setNumNominal(3026);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertFalse(additiveRegression0.getDebug());
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3029, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(3026, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      
      boolean boolean0 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertTrue(boolean0);
      
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances1);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertFalse(additiveRegression0.getDebug());
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(20, testInstances1.getNumInstances());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumString());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, testInstances1.getNumAttributes());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertFalse(testInstances1.getMultiInstance());
      
      Instances instances0 = testInstances1.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertFalse(additiveRegression0.getDebug());
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(20, testInstances1.getNumInstances());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumString());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, testInstances1.getNumAttributes());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertFalse(additiveRegression0.getDebug());
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(20, testInstances1.getNumInstances());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumString());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, testInstances1.getNumAttributes());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertFalse(additiveRegression0.getDebug());
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(20, testInstances1.getNumInstances());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumString());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, testInstances1.getNumAttributes());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.weightedMatthewsCorrelation();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 44
  /*Coverage entropy=0.4897959183673469
  */
  @Test(timeout = 4000)
  public void test044()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      CostMatrix costMatrix0 = Evaluation.handleCostOption("", 3026);
      assertNull(costMatrix0);
      
      AdditiveRegression additiveRegression0 = new AdditiveRegression();
      assertNotNull(additiveRegression0);
      assertFalse(additiveRegression0.getDebug());
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      
      Capabilities capabilities0 = additiveRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(additiveRegression0.getDebug());
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertFalse(additiveRegression0.getDebug());
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      boolean boolean0 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertTrue(boolean0);
      
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances1);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(additiveRegression0.getDebug());
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(20, testInstances1.getNumInstances());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(4, testInstances1.getNumAttributes());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumString());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      
      Instances instances0 = testInstances1.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(additiveRegression0.getDebug());
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(20, testInstances1.getNumInstances());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(4, testInstances1.getNumAttributes());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumString());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertNotNull(evaluation0);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(additiveRegression0.getDebug());
      assertEquals(10, additiveRegression0.getNumIterations());
      assertEquals("The number of iterations to be performed.", additiveRegression0.numIterationsTipText());
      assertEquals("The base classifier to be used.", additiveRegression0.classifierTipText());
      assertEquals(0.0, additiveRegression0.measureNumIterations(), 0.01);
      assertEquals(1.0, additiveRegression0.getShrinkage(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", additiveRegression0.debugTipText());
      assertEquals("Shrinkage rate. Smaller values help prevent overfitting and have a smoothing effect (but increase learning time). Default = 1.0, ie. no shrinkage.", additiveRegression0.shrinkageTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(20, testInstances1.getNumInstances());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(0, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(4, testInstances1.getNumAttributes());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumString());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      try { 
        evaluation0.toClassDetailsString("@relation");
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Evaluation: No per class statistics possible!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 45
  /*Coverage entropy=1.4169372058999015
  */
  @Test(timeout = 4000)
  public void test045()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      String string0 = evaluation0.toSummaryString(".bsi", true);
      assertNotNull(string0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(".bsi\nTotal Number of Instances                0     \n", string0);
      
      evaluation0.setNumericPriorsFromBuffer();
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      Stacking stacking0 = new Stacking();
      assertNotNull(stacking0);
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertFalse(stacking0.getDebug());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      
      double double0 = evaluation0.weightedFalseNegativeRate();
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, double0, 0.01);
  }

  /**
  //Test case number: 46
  /*Coverage entropy=2.5875048411843102
  */
  @Test(timeout = 4000)
  public void test046()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      
      testInstances0.setNumNominal(117);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(118, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(118, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(118, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(117, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(118, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(118, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(117, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      
      MockRandom mockRandom0 = new MockRandom((-1));
      assertNotNull(mockRandom0);
      
      double double0 = evaluation0.weightedAreaUnderPRC();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(118, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(118, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(117, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.totalCost();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(118, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(118, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(117, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, double1, 0.01);
      
      double double2 = evaluation0.weightedFalseNegativeRate();
      assertNotEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(118, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(118, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(117, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation0.weightedPrecision();
      assertEquals(double3, double0, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertEquals(double3, double2, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(118, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(118, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(117, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
  }

  /**
  //Test case number: 47
  /*Coverage entropy=1.4486869174985209
  */
  @Test(timeout = 4000)
  public void test047()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      Instances instances1 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances1);
      assertSame(instances1, instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances1.relationName());
      assertEquals(1, instances1.classIndex());
      assertEquals(0, instances1.numClasses());
      assertEquals(0, instances1.numInstances());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals(2, instances1.numAttributes());
      assertTrue(instances1.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      PlainText plainText0 = new PlainText();
      assertNotNull(plainText0);
      assertEquals("Whether to suppress the regular output when storing the output in a file.", plainText0.suppressOutputTipText());
      assertEquals(3, plainText0.getDefaultNumDecimals());
      assertFalse(plainText0.getOutputDistribution());
      assertEquals("Whether to ouput the class distribution as well (only nominal class attributes).", plainText0.outputDistributionTipText());
      assertEquals("The indices of the attributes to print in addition.", plainText0.attributesTipText());
      assertEquals("The number of digits to output after the decimal point.", plainText0.numDecimalsTipText());
      assertEquals("The file to write the generated output to (disabled if path is a directory).", plainText0.outputFileTipText());
      assertEquals(3, plainText0.getNumDecimals());
      assertEquals("Plain text", plainText0.getDisplay());
      assertTrue(plainText0.generatesOutput());
      assertFalse(plainText0.getSuppressOutput());
      assertEquals("Outputs the predictions in plain text.", plainText0.globalInfo());
      
      Instances instances2 = plainText0.getHeader();
      assertNull(instances2);
      assertEquals("Whether to suppress the regular output when storing the output in a file.", plainText0.suppressOutputTipText());
      assertEquals(3, plainText0.getDefaultNumDecimals());
      assertFalse(plainText0.getOutputDistribution());
      assertEquals("Whether to ouput the class distribution as well (only nominal class attributes).", plainText0.outputDistributionTipText());
      assertEquals("The indices of the attributes to print in addition.", plainText0.attributesTipText());
      assertEquals("The number of digits to output after the decimal point.", plainText0.numDecimalsTipText());
      assertEquals("The file to write the generated output to (disabled if path is a directory).", plainText0.outputFileTipText());
      assertEquals(3, plainText0.getNumDecimals());
      assertEquals("Plain text", plainText0.getDisplay());
      assertTrue(plainText0.generatesOutput());
      assertFalse(plainText0.getSuppressOutput());
      assertEquals("Outputs the predictions in plain text.", plainText0.globalInfo());
      
      try { 
        evaluation0.setPriors((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 48
  /*Coverage entropy=2.7148603057626772
  */
  @Test(timeout = 4000)
  public void test048()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      String string0 = evaluation0.toMatrixString();
      assertNotNull(string0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals("=== Confusion Matrix ===\n\n   <-- classified as\n", string0);
      
      double[][] doubleArray0 = evaluation0.m_ConfusionMatrix;
      assertNotNull(doubleArray0);
      assertEquals(0, doubleArray0.length);
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertNotNull(regressionByDiscretization0);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      
      ArffLoader arffLoader0 = new ArffLoader();
      assertNotNull(arffLoader0);
      assertEquals("http://", arffLoader0.retrieveURL());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals(".arff", arffLoader0.getFileExtension());
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      
      double double0 = evaluation0.fMeasure((-1983214072));
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      
      double double1 = evaluation0.m_SumPriorAbsErr;
      assertEquals(double1, double0, 0.01);
      assertEquals(0.0, double1, 0.01);
      
      double double2 = evaluation0.weightedFalseNegativeRate();
      assertNotEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      try { 
        evaluation0.correlationCoefficient();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't compute correlation coefficient: class is nominal!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 49
  /*Coverage entropy=1.1546856420984069
  */
  @Test(timeout = 4000)
  public void test049()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      
      String string0 = evaluation0.getRevision();
      assertNotNull(string0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals("9101", string0);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.m_SumPriorAbsErr;
      assertEquals(double1, double0, 0.01);
      assertEquals(0.0, double1, 0.01);
      
      evaluation0.setNumericPriorsFromBuffer();
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
  }

  /**
  //Test case number: 50
  /*Coverage entropy=2.843827178250701
  */
  @Test(timeout = 4000)
  public void test050()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      SMOreg sMOreg0 = new SMOreg();
      assertNotNull(sMOreg0);
      assertEquals(0, SMOreg.FILTER_NORMALIZE);
      assertEquals(2, SMOreg.FILTER_NONE);
      assertEquals(1, SMOreg.FILTER_STANDARDIZE);
      assertEquals("Determines how/if the data will be transformed.", sMOreg0.filterTypeTipText());
      assertEquals("The learning algorithm.", sMOreg0.regOptimizerTipText());
      assertEquals(1.0, sMOreg0.getC(), 0.01);
      assertEquals("The kernel to use.", sMOreg0.kernelTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sMOreg0.debugTipText());
      assertEquals("The complexity parameter C.", sMOreg0.cTipText());
      assertFalse(sMOreg0.getDebug());
      
      PolyKernel polyKernel0 = (PolyKernel)sMOreg0.getKernel();
      assertNotNull(polyKernel0);
      assertEquals(0, SMOreg.FILTER_NORMALIZE);
      assertEquals(2, SMOreg.FILTER_NONE);
      assertEquals(1, SMOreg.FILTER_STANDARDIZE);
      assertEquals("Determines how/if the data will be transformed.", sMOreg0.filterTypeTipText());
      assertEquals("The learning algorithm.", sMOreg0.regOptimizerTipText());
      assertEquals(1.0, sMOreg0.getC(), 0.01);
      assertEquals("The kernel to use.", sMOreg0.kernelTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sMOreg0.debugTipText());
      assertEquals("The complexity parameter C.", sMOreg0.cTipText());
      assertFalse(sMOreg0.getDebug());
      assertEquals(250007, polyKernel0.getCacheSize());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", polyKernel0.cacheSizeTipText());
      assertFalse(polyKernel0.getDebug());
      assertEquals("Whether to use lower-order terms.", polyKernel0.useLowerOrderTipText());
      assertEquals(0, polyKernel0.numCacheHits());
      assertFalse(polyKernel0.getChecksTurnedOff());
      assertEquals("Turns time-consuming checks off - use with caution.", polyKernel0.checksTurnedOffTipText());
      assertFalse(polyKernel0.getUseLowerOrder());
      assertEquals("The polynomial kernel : K(x, y) = <x, y>^p or K(x, y) = (<x, y>+1)^p", polyKernel0.globalInfo());
      assertEquals(1.0, polyKernel0.getExponent(), 0.01);
      assertEquals(0, polyKernel0.numEvals());
      assertEquals("Turns on the output of debugging information.", polyKernel0.debugTipText());
      assertEquals("The exponent value.", polyKernel0.exponentTipText());
      
      Capabilities capabilities0 = new Capabilities(polyKernel0);
      assertNotNull(capabilities0);
      assertEquals(0, SMOreg.FILTER_NORMALIZE);
      assertEquals(2, SMOreg.FILTER_NONE);
      assertEquals(1, SMOreg.FILTER_STANDARDIZE);
      assertEquals("Determines how/if the data will be transformed.", sMOreg0.filterTypeTipText());
      assertEquals("The learning algorithm.", sMOreg0.regOptimizerTipText());
      assertEquals(1.0, sMOreg0.getC(), 0.01);
      assertEquals("The kernel to use.", sMOreg0.kernelTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sMOreg0.debugTipText());
      assertEquals("The complexity parameter C.", sMOreg0.cTipText());
      assertFalse(sMOreg0.getDebug());
      assertEquals(250007, polyKernel0.getCacheSize());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", polyKernel0.cacheSizeTipText());
      assertFalse(polyKernel0.getDebug());
      assertEquals("Whether to use lower-order terms.", polyKernel0.useLowerOrderTipText());
      assertEquals(0, polyKernel0.numCacheHits());
      assertFalse(polyKernel0.getChecksTurnedOff());
      assertEquals("Turns time-consuming checks off - use with caution.", polyKernel0.checksTurnedOffTipText());
      assertFalse(polyKernel0.getUseLowerOrder());
      assertEquals("The polynomial kernel : K(x, y) = <x, y>^p or K(x, y) = (<x, y>+1)^p", polyKernel0.globalInfo());
      assertEquals(1.0, polyKernel0.getExponent(), 0.01);
      assertEquals(0, polyKernel0.numEvals());
      assertEquals("Turns on the output of debugging information.", polyKernel0.debugTipText());
      assertEquals("The exponent value.", polyKernel0.exponentTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      evaluation0.setPriors(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(2, doubleArray0.length);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      
      double double0 = evaluation1.falsePositiveRate(0);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.unweightedMacroFmeasure();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation1.weightedAreaUnderPRC();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotEquals(double2, double0, 0.01);
      assertEquals(double2, double1, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation0.totalCost();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotEquals(double3, double1, 0.01);
      assertEquals(double3, double0, 0.01);
      assertNotEquals(double3, double2, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, double3, 0.01);
      
      Stacking stacking0 = new Stacking();
      assertNotNull(stacking0);
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      
      double double4 = evaluation1.weightedFalseNegativeRate();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals(double4, double1, 0.01);
      assertNotEquals(double4, double0, 0.01);
      assertEquals(double4, double2, 0.01);
      assertNotEquals(double4, double3, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double4, 0.01);
  }

  /**
  //Test case number: 51
  /*Coverage entropy=1.1546856420984069
  */
  @Test(timeout = 4000)
  public void test051()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      
      testInstances0.setNumNominal(111);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      
      String string0 = evaluation0.toSummaryString("@relation", false);
      assertNotNull(string0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(112, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals("@relation\nTotal Number of Instances                0     \n", string0);
      
      MockRandom mockRandom0 = new MockRandom((-1));
      assertNotNull(mockRandom0);
      
      try { 
        evaluation0.correlationCoefficient();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't compute correlation coefficient: class is nominal!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 52
  /*Coverage entropy=1.1693376567504215
  */
  @Test(timeout = 4000)
  public void test052()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      
      Instances instances1 = textDirectoryLoader0.getStructure();
      assertNotNull(instances1);
      assertSame(instances1, instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(1, instances1.classIndex());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(0, instances1.numClasses());
      assertEquals(0, instances1.numInstances());
      assertEquals(2, instances1.numAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances1.relationName());
      assertEquals(0, instances1.size());
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(0, doubleArray0.length);
      assertSame(instances0, instances1);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      
      double double0 = evaluation0.precision(109);
      assertSame(instances0, instances1);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.relativeAbsoluteError();
      assertNotEquals(double1, double0, 0.01);
      assertSame(instances0, instances1);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double[] doubleArray1 = evaluation0.evaluateModel((Classifier) null, instances0, (Object[]) doubleArray0);
      assertNotNull(doubleArray1);
      assertEquals(0, doubleArray0.length);
      assertEquals(0, doubleArray1.length);
      assertSame(instances0, instances1);
      assertArrayEquals(new double[] {}, doubleArray1, 0.01);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      
      MockRandom mockRandom0 = new MockRandom(109);
      assertNotNull(mockRandom0);
      
      try { 
        evaluation0.crossValidateModel((Classifier) null, instances0, 109, (Random) mockRandom0, (Object[]) doubleArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Can't have more folds than instances!
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 53
  /*Coverage entropy=2.8698898940205453
  */
  @Test(timeout = 4000)
  public void test053()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Stacking stacking0 = new Stacking();
      assertNotNull(stacking0);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      
      Capabilities capabilities0 = stacking0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(5, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(5, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(5, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.weightedMatthewsCorrelation();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(5, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.numFalseNegatives((-2));
      assertEquals(double2, double0, 0.01);
      assertNotEquals(double2, double1, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(5, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      Attribute attribute0 = new Attribute(" ", 1658);
      assertNotNull(attribute0);
      assertEquals(1, Attribute.NOMINAL);
      assertEquals(4, Attribute.RELATIONAL);
      assertEquals(0, Attribute.ORDERING_SYMBOLIC);
      assertEquals(0, Attribute.NUMERIC);
      assertEquals(3, Attribute.DATE);
      assertEquals(1, Attribute.ORDERING_ORDERED);
      assertEquals(2, Attribute.ORDERING_MODULO);
      assertEquals(2, Attribute.STRING);
      assertEquals(1658, attribute0.index());
      assertEquals(0, attribute0.numValues());
      assertTrue(attribute0.isRegular());
      assertFalse(attribute0.isNominal());
      assertEquals(0, attribute0.type());
      assertFalse(attribute0.isDate());
      assertFalse(attribute0.lowerNumericBoundIsOpen());
      assertEquals(Double.NEGATIVE_INFINITY, attribute0.getLowerNumericBound(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, attribute0.getUpperNumericBound(), 0.01);
      assertEquals(1, attribute0.ordering());
      assertFalse(attribute0.upperNumericBoundIsOpen());
      assertFalse(attribute0.isString());
      assertTrue(attribute0.isNumeric());
      assertEquals("", attribute0.getDateFormat());
      assertFalse(attribute0.isRelationValued());
      assertEquals(" ", attribute0.name());
      assertTrue(attribute0.isAveragable());
      assertEquals(1.0, attribute0.weight(), 0.01);
      assertTrue(attribute0.hasZeropoint());
      
      instances0.setClass(attribute0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, Attribute.NOMINAL);
      assertEquals(4, Attribute.RELATIONAL);
      assertEquals(0, Attribute.ORDERING_SYMBOLIC);
      assertEquals(0, Attribute.NUMERIC);
      assertEquals(3, Attribute.DATE);
      assertEquals(1, Attribute.ORDERING_ORDERED);
      assertEquals(2, Attribute.ORDERING_MODULO);
      assertEquals(2, Attribute.STRING);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(20, instances0.numInstances());
      assertEquals(6, instances0.numAttributes());
      assertEquals(1658, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1658, attribute0.index());
      assertEquals(0, attribute0.numValues());
      assertTrue(attribute0.isRegular());
      assertFalse(attribute0.isNominal());
      assertEquals(0, attribute0.type());
      assertFalse(attribute0.isDate());
      assertFalse(attribute0.lowerNumericBoundIsOpen());
      assertEquals(Double.NEGATIVE_INFINITY, attribute0.getLowerNumericBound(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, attribute0.getUpperNumericBound(), 0.01);
      assertEquals(1, attribute0.ordering());
      assertFalse(attribute0.upperNumericBoundIsOpen());
      assertFalse(attribute0.isString());
      assertTrue(attribute0.isNumeric());
      assertEquals("", attribute0.getDateFormat());
      assertFalse(attribute0.isRelationValued());
      assertEquals(" ", attribute0.name());
      assertTrue(attribute0.isAveragable());
      assertEquals(1.0, attribute0.weight(), 0.01);
      assertTrue(attribute0.hasZeropoint());
      
      double double3 = evaluation0.trueNegativeRate((-1995138716));
      assertEquals(double3, double0, 0.01);
      assertEquals(double3, double2, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(20, instances0.numInstances());
      assertEquals(6, instances0.numAttributes());
      assertEquals(1658, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, double3, 0.01);
      
      Enumeration enumeration0 = testInstances0.listOptions();
      assertNotNull(enumeration0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      
      int int0 = attribute0.addStringValue("WARNING: loading a newer version (");
      assertEquals(1, Attribute.NOMINAL);
      assertEquals(4, Attribute.RELATIONAL);
      assertEquals(0, Attribute.ORDERING_SYMBOLIC);
      assertEquals(0, Attribute.NUMERIC);
      assertEquals(3, Attribute.DATE);
      assertEquals(1, Attribute.ORDERING_ORDERED);
      assertEquals(2, Attribute.ORDERING_MODULO);
      assertEquals(2, Attribute.STRING);
      assertEquals(1658, attribute0.index());
      assertEquals(0, attribute0.numValues());
      assertTrue(attribute0.isRegular());
      assertFalse(attribute0.isNominal());
      assertEquals(0, attribute0.type());
      assertFalse(attribute0.isDate());
      assertFalse(attribute0.lowerNumericBoundIsOpen());
      assertEquals(Double.NEGATIVE_INFINITY, attribute0.getLowerNumericBound(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, attribute0.getUpperNumericBound(), 0.01);
      assertEquals(1, attribute0.ordering());
      assertFalse(attribute0.upperNumericBoundIsOpen());
      assertFalse(attribute0.isString());
      assertTrue(attribute0.isNumeric());
      assertEquals("", attribute0.getDateFormat());
      assertFalse(attribute0.isRelationValued());
      assertEquals(" ", attribute0.name());
      assertTrue(attribute0.isAveragable());
      assertEquals(1.0, attribute0.weight(), 0.01);
      assertTrue(attribute0.hasZeropoint());
      assertEquals((-1), int0);
      
      double double4 = evaluation0.truePositiveRate(0);
      assertEquals(double4, double2, 0.01);
      assertNotEquals(double4, double1, 0.01);
      assertEquals(double4, double0, 0.01);
      assertEquals(double4, double3, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals(1, stacking0.getSeed());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(20, instances0.numInstances());
      assertEquals(6, instances0.numAttributes());
      assertEquals(1658, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, double4, 0.01);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      // Undeclared exception!
      try { 
        evaluation0.updateMargins((double[]) null, (-1898), 0.0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 54
  /*Coverage entropy=0.4915254237288135
  */
  @Test(timeout = 4000)
  public void test054()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Stacking stacking0 = new Stacking();
      assertNotNull(stacking0);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      
      Capabilities capabilities0 = stacking0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.classIndex());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.classIndex());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.classIndex());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.weightedMatthewsCorrelation();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.classIndex());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.numFalseNegatives((-2));
      assertNotEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.classIndex());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      Attribute attribute0 = new Attribute(" ", 1658);
      assertNotNull(attribute0);
      assertEquals(2, Attribute.STRING);
      assertEquals(3, Attribute.DATE);
      assertEquals(2, Attribute.ORDERING_MODULO);
      assertEquals(4, Attribute.RELATIONAL);
      assertEquals(0, Attribute.ORDERING_SYMBOLIC);
      assertEquals(0, Attribute.NUMERIC);
      assertEquals(1, Attribute.NOMINAL);
      assertEquals(1, Attribute.ORDERING_ORDERED);
      assertEquals("", attribute0.getDateFormat());
      assertEquals(" ", attribute0.name());
      assertTrue(attribute0.isRegular());
      assertFalse(attribute0.isNominal());
      assertEquals(0, attribute0.numValues());
      assertFalse(attribute0.upperNumericBoundIsOpen());
      assertTrue(attribute0.isNumeric());
      assertEquals(Double.NEGATIVE_INFINITY, attribute0.getLowerNumericBound(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, attribute0.getUpperNumericBound(), 0.01);
      assertEquals(0, attribute0.type());
      assertFalse(attribute0.lowerNumericBoundIsOpen());
      assertFalse(attribute0.isDate());
      assertFalse(attribute0.isRelationValued());
      assertFalse(attribute0.isString());
      assertEquals(1658, attribute0.index());
      assertEquals(1.0, attribute0.weight(), 0.01);
      assertTrue(attribute0.hasZeropoint());
      assertEquals(1, attribute0.ordering());
      assertTrue(attribute0.isAveragable());
      
      instances0.setClass(attribute0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, Attribute.STRING);
      assertEquals(3, Attribute.DATE);
      assertEquals(2, Attribute.ORDERING_MODULO);
      assertEquals(4, Attribute.RELATIONAL);
      assertEquals(0, Attribute.ORDERING_SYMBOLIC);
      assertEquals(0, Attribute.NUMERIC);
      assertEquals(1, Attribute.NOMINAL);
      assertEquals(1, Attribute.ORDERING_ORDERED);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1658, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals("", attribute0.getDateFormat());
      assertEquals(" ", attribute0.name());
      assertTrue(attribute0.isRegular());
      assertFalse(attribute0.isNominal());
      assertEquals(0, attribute0.numValues());
      assertFalse(attribute0.upperNumericBoundIsOpen());
      assertTrue(attribute0.isNumeric());
      assertEquals(Double.NEGATIVE_INFINITY, attribute0.getLowerNumericBound(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, attribute0.getUpperNumericBound(), 0.01);
      assertEquals(0, attribute0.type());
      assertFalse(attribute0.lowerNumericBoundIsOpen());
      assertFalse(attribute0.isDate());
      assertFalse(attribute0.isRelationValued());
      assertFalse(attribute0.isString());
      assertEquals(1658, attribute0.index());
      assertEquals(1.0, attribute0.weight(), 0.01);
      assertTrue(attribute0.hasZeropoint());
      assertEquals(1, attribute0.ordering());
      assertTrue(attribute0.isAveragable());
      
      double double3 = evaluation0.trueNegativeRate((-1995138716));
      assertNotEquals(double3, double1, 0.01);
      assertEquals(double3, double0, 0.01);
      assertEquals(double3, double2, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1658, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, double3, 0.01);
      
      Enumeration enumeration0 = testInstances0.listOptions();
      assertNotNull(enumeration0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      
      int int0 = attribute0.addStringValue("WARNING: loading a newer version (");
      assertEquals(2, Attribute.STRING);
      assertEquals(3, Attribute.DATE);
      assertEquals(2, Attribute.ORDERING_MODULO);
      assertEquals(4, Attribute.RELATIONAL);
      assertEquals(0, Attribute.ORDERING_SYMBOLIC);
      assertEquals(0, Attribute.NUMERIC);
      assertEquals(1, Attribute.NOMINAL);
      assertEquals(1, Attribute.ORDERING_ORDERED);
      assertEquals("", attribute0.getDateFormat());
      assertEquals(" ", attribute0.name());
      assertTrue(attribute0.isRegular());
      assertFalse(attribute0.isNominal());
      assertEquals(0, attribute0.numValues());
      assertFalse(attribute0.upperNumericBoundIsOpen());
      assertTrue(attribute0.isNumeric());
      assertEquals(Double.NEGATIVE_INFINITY, attribute0.getLowerNumericBound(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, attribute0.getUpperNumericBound(), 0.01);
      assertEquals(0, attribute0.type());
      assertFalse(attribute0.lowerNumericBoundIsOpen());
      assertFalse(attribute0.isDate());
      assertFalse(attribute0.isRelationValued());
      assertFalse(attribute0.isString());
      assertEquals(1658, attribute0.index());
      assertEquals(1.0, attribute0.weight(), 0.01);
      assertTrue(attribute0.hasZeropoint());
      assertEquals(1, attribute0.ordering());
      assertTrue(attribute0.isAveragable());
      assertEquals((-1), int0);
      
      double double4 = evaluation0.truePositiveRate(0);
      assertEquals(double4, double3, 0.01);
      assertEquals(double4, double0, 0.01);
      assertNotEquals(double4, double1, 0.01);
      assertEquals(double4, double2, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(10, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(6, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1658, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(6, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, double4, 0.01);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (double) 2;
      // Undeclared exception!
      try { 
        evaluation0.updateMargins(doubleArray0, 0, (-2));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 1
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 55
  /*Coverage entropy=0.4736842105263158
  */
  @Test(timeout = 4000)
  public void test055()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      
      double double0 = evaluation0.KBMeanInformation();
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      
      CostMatrix costMatrix0 = Evaluation.handleCostOption((String) null, (-1461032992));
      assertNull(costMatrix0);
      
      double double1 = evaluation1.KBInformation();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, double1, 0.01);
  }

  /**
  //Test case number: 56
  /*Coverage entropy=2.448442309591302
  */
  @Test(timeout = 4000)
  public void test056()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(0, doubleArray0.length);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.SFMeanPriorEntropy();
      assertNotEquals(double1, double0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2);
      assertNotNull(binarySparseInstance0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(2, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.numValues());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      
      Instances instances1 = binarySparseInstance0.dataset();
      assertNull(instances1);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(2, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.numValues());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      
      textDirectoryLoader0.setCharSet(" is not supported!");
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(" is not supported!", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      double double2 = evaluation0.numTrueNegatives(111);
      assertNotEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(" is not supported!", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(" is not supported!", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      
      double double3 = evaluation0.rootMeanSquaredError();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotEquals(double3, double2, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertEquals(double3, double1, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(" is not supported!", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
  }

  /**
  //Test case number: 57
  /*Coverage entropy=1.9589472787966302
  */
  @Test(timeout = 4000)
  public void test057()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      
      testInstances0.setNumNominal(111);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(112, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(112, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(112, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      Instances instances1 = testInstances0.generate();
      assertNotNull(instances1);
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(112, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances1.numInstances());
      assertEquals(111, instances1.classIndex());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(2, instances1.numClasses());
      assertEquals(112, instances1.numAttributes());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.size());
      
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (double) (-2);
      doubleArray0[1] = (double) 111;
      doubleArray0[2] = (double) 111;
      evaluation0.updateNumericScores(doubleArray0, doubleArray0, 2104.0);
      assertEquals(3, doubleArray0.length);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      assertArrayEquals(new double[] {(-2.0), 111.0, 111.0}, doubleArray0, 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(112, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      String string0 = evaluation0.toSummaryString();
      assertNotNull(string0);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(112, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals("\nTotal Number of Instances                0     \n", string0);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertFalse(instances0.equals((Object)instances1));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(112, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertNotNull(costSensitiveClassifier0);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      
      CostSensitiveClassifier costSensitiveClassifier1 = new CostSensitiveClassifier();
      assertNotNull(costSensitiveClassifier1);
      assertFalse(costSensitiveClassifier1.equals((Object)costSensitiveClassifier0));
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertFalse(costSensitiveClassifier1.getDebug());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier1.globalInfo());
      assertEquals("The random number seed to be used.", costSensitiveClassifier1.seedTipText());
      assertEquals(0, costSensitiveClassifier1.graphType());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier1.debugTipText());
      assertFalse(costSensitiveClassifier1.getMinimizeExpectedCost());
      assertEquals(1, costSensitiveClassifier1.getSeed());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier1.costMatrixTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier1.classifierTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier1.onDemandDirectoryTipText());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier1.minimizeExpectedCostTipText());
      
      CostMatrix costMatrix0 = costSensitiveClassifier1.getCostMatrix();
      assertNotNull(costMatrix0);
      assertFalse(costSensitiveClassifier1.equals((Object)costSensitiveClassifier0));
      assertNotSame(costSensitiveClassifier1, costSensitiveClassifier0);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertFalse(costSensitiveClassifier1.getDebug());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier1.globalInfo());
      assertEquals("The random number seed to be used.", costSensitiveClassifier1.seedTipText());
      assertEquals(0, costSensitiveClassifier1.graphType());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier1.debugTipText());
      assertFalse(costSensitiveClassifier1.getMinimizeExpectedCost());
      assertEquals(1, costSensitiveClassifier1.getSeed());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier1.costMatrixTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier1.classifierTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier1.onDemandDirectoryTipText());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier1.minimizeExpectedCostTipText());
      assertEquals(1, costMatrix0.size());
      assertEquals(1, costMatrix0.numRows());
      assertEquals(1, costMatrix0.numColumns());
      
      evaluation0.setDiscardPredictions(false);
      assertFalse(instances0.equals((Object)instances1));
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotSame(instances0, instances1);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(112, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      double double0 = evaluation0.weightedRecall();
      assertFalse(instances0.equals((Object)instances1));
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotSame(instances0, instances1);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(112, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(112, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
  }

  /**
  //Test case number: 58
  /*Coverage entropy=0.4444444444444445
  */
  @Test(timeout = 4000)
  public void test058()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      
      RandomForest randomForest0 = new RandomForest();
      assertNotNull(randomForest0);
      assertFalse(randomForest0.getDebug());
      assertEquals(1, randomForest0.getSeed());
      assertEquals("The maximum depth of the trees, 0 for unlimited.", randomForest0.maxDepthTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", randomForest0.numExecutionSlotsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", randomForest0.debugTipText());
      assertEquals(0, randomForest0.getNumFeatures());
      assertEquals("The number of trees to be generated.", randomForest0.numTreesTipText());
      assertEquals("Print the individual trees in the output", randomForest0.printTreesTipText());
      assertEquals("The number of attributes to be used in random selection (see RandomTree).", randomForest0.numFeaturesTipText());
      assertEquals("The random number seed to be used.", randomForest0.seedTipText());
      assertEquals(10, randomForest0.getNumTrees());
      assertEquals(1, randomForest0.getNumExecutionSlots());
      assertEquals(0, randomForest0.getMaxDepth());
      assertEquals(Double.NaN, randomForest0.measureOutOfBagError(), 0.01);
      assertFalse(randomForest0.getPrintTrees());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.updateNumericScores((double[]) null, (double[]) null, (-2));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 59
  /*Coverage entropy=1.864555230685108
  */
  @Test(timeout = 4000)
  public void test059()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      
      String string0 = evaluation0.toMatrixString();
      assertNotNull(string0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals("=== Confusion Matrix ===\n\n   <-- classified as\n", string0);
      
      boolean boolean0 = FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "-o\n");
      assertFalse(boolean0);
      
      double[][] doubleArray0 = evaluation0.m_ConfusionMatrix;
      assertNotNull(doubleArray0);
      assertEquals(0, doubleArray0.length);
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertNotNull(regressionByDiscretization0);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      
      ArffLoader arffLoader0 = new ArffLoader();
      assertNotNull(arffLoader0);
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertEquals(".arff", arffLoader0.getFileExtension());
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals("http://", arffLoader0.retrieveURL());
      
      double double0 = evaluation0.fMeasure((-1983214072));
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      
      multilayerPerceptron0.setTrainingTime(1);
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals(1, multilayerPerceptron0.getTrainingTime());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertTrue(multilayerPerceptron0.getReset());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      
      RegressionByDiscretization regressionByDiscretization1 = (RegressionByDiscretization)AbstractClassifier.makeCopy(regressionByDiscretization0);
      assertNotNull(regressionByDiscretization1);
      assertFalse(regressionByDiscretization1.equals((Object)regressionByDiscretization0));
      assertNotSame(regressionByDiscretization0, regressionByDiscretization1);
      assertNotSame(regressionByDiscretization1, regressionByDiscretization0);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization1.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization1.getMinimizeAbsoluteError());
      assertFalse(regressionByDiscretization1.getDeleteEmptyBins());
      assertFalse(regressionByDiscretization1.getUseEqualFrequency());
      assertFalse(regressionByDiscretization1.getDebug());
      assertEquals("Number of bins for discretization.", regressionByDiscretization1.numBinsTipText());
      assertEquals("The base classifier to be used.", regressionByDiscretization1.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization1.debugTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization1.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization1.getNumBins());
      assertEquals("The density estimator to use.", regressionByDiscretization1.estimatorTypeTipText());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization1.minimizeAbsoluteErrorTipText());
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(134);
      assertNotNull(binarySparseInstance0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(134, binarySparseInstance0.numAttributes());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(134, binarySparseInstance0.numValues());
      
      try { 
        evaluation0.evaluateModelOnce((Classifier) regressionByDiscretization1, (Instance) binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 60
  /*Coverage entropy=2.888638239098775
  */
  @Test(timeout = 4000)
  public void test060()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.m_ClassPriorsSum;
      assertNotEquals(double1, double0, 0.01);
      assertEquals(22.0, double1, 0.01);
      
      double double2 = evaluation0.rootRelativeSquaredError();
      assertNotEquals(double2, double0, 0.01);
      assertNotEquals(double2, double1, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation0.matthewsCorrelationCoefficient((-2));
      assertEquals(double3, double0, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertNotEquals(double3, double2, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, double3, 0.01);
      
      evaluation0.addNumericTrainClass(0.0, 0.0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      double double4 = evaluation0.m_SumSqrPredicted;
      assertEquals(double4, double3, 0.01);
      assertEquals(double4, double0, 0.01);
      assertNotEquals(double4, double2, 0.01);
      assertNotEquals(double4, double1, 0.01);
      assertEquals(0.0, double4, 0.01);
      
      double double5 = evaluation0.meanAbsoluteError();
      assertNotEquals(double5, double4, 0.01);
      assertNotEquals(double5, double1, 0.01);
      assertNotEquals(double5, double3, 0.01);
      assertNotEquals(double5, double0, 0.01);
      assertEquals(double5, double2, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, double5, 0.01);
  }

  /**
  //Test case number: 61
  /*Coverage entropy=0.47058823529411764
  */
  @Test(timeout = 4000)
  public void test061()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      
      int int0 = 1;
      double double0 = evaluation0.SFMeanPriorEntropy();
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.weightedMatthewsCorrelation();
      assertEquals(double1, double0, 0.01);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.numFalseNegatives(455);
      assertNotEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      double[][] doubleArray0 = evaluation0.m_ConfusionMatrix;
      assertNotNull(doubleArray0);
      assertEquals(0, doubleArray0.length);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      double double3 = evaluation0.SFMeanSchemeEntropy();
      assertNotEquals(double3, double2, 0.01);
      assertEquals(double3, double0, 0.01);
      assertEquals(double3, double1, 0.01);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.makeDistribution(1);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 1
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 62
  /*Coverage entropy=0.4444444444444445
  */
  @Test(timeout = 4000)
  public void test062()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      
      Stacking stacking0 = new Stacking();
      assertNotNull(stacking0);
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      
      J48 j48_0 = new J48();
      assertNotNull(j48_0);
      assertFalse(j48_0.getUnpruned());
      assertEquals(1, j48_0.getSeed());
      assertTrue(j48_0.getUseMDLcorrection());
      assertEquals("The seed used for randomizing the data when reduced-error pruning is used.", j48_0.seedTipText());
      assertEquals(2, j48_0.getMinNumObj());
      assertTrue(j48_0.getCollapseTree());
      assertEquals(1, j48_0.graphType());
      assertTrue(j48_0.getSubtreeRaising());
      assertFalse(j48_0.getBinarySplits());
      assertEquals("The minimum number of instances per leaf.", j48_0.minNumObjTipText());
      assertEquals("Whether reduced-error pruning is used instead of C.4.5 pruning.", j48_0.reducedErrorPruningTipText());
      assertEquals(3, j48_0.getNumFolds());
      assertEquals("Whether parts are removed that do not reduce training error.", j48_0.collapseTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", j48_0.debugTipText());
      assertEquals(0.25F, j48_0.getConfidenceFactor(), 0.01F);
      assertFalse(j48_0.getDebug());
      assertEquals("Whether MDL correction is used when finding splits on numeric attributes.", j48_0.useMDLcorrectionTipText());
      assertFalse(j48_0.getUseLaplace());
      assertEquals("Whether counts at leaves are smoothed based on Laplace.", j48_0.useLaplaceTipText());
      assertEquals("Whether to consider the subtree raising operation when pruning.", j48_0.subtreeRaisingTipText());
      assertEquals("Whether to use binary splits on nominal attributes when building the trees.", j48_0.binarySplitsTipText());
      assertEquals("The confidence factor used for pruning (smaller values incur more pruning).", j48_0.confidenceFactorTipText());
      assertEquals("Determines the amount of data used for reduced-error pruning.  One fold is used for pruning, the rest for growing the tree.", j48_0.numFoldsTipText());
      assertEquals("Whether to save the training data for visualization.", j48_0.saveInstanceDataTipText());
      assertFalse(j48_0.getSaveInstanceData());
      assertEquals("Whether pruning is performed.", j48_0.unprunedTipText());
      assertFalse(j48_0.getReducedErrorPruning());
      
      stacking0.setMetaClassifier(j48_0);
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertFalse(j48_0.getUnpruned());
      assertEquals(1, j48_0.getSeed());
      assertTrue(j48_0.getUseMDLcorrection());
      assertEquals("The seed used for randomizing the data when reduced-error pruning is used.", j48_0.seedTipText());
      assertEquals(2, j48_0.getMinNumObj());
      assertTrue(j48_0.getCollapseTree());
      assertEquals(1, j48_0.graphType());
      assertTrue(j48_0.getSubtreeRaising());
      assertFalse(j48_0.getBinarySplits());
      assertEquals("The minimum number of instances per leaf.", j48_0.minNumObjTipText());
      assertEquals("Whether reduced-error pruning is used instead of C.4.5 pruning.", j48_0.reducedErrorPruningTipText());
      assertEquals(3, j48_0.getNumFolds());
      assertEquals("Whether parts are removed that do not reduce training error.", j48_0.collapseTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", j48_0.debugTipText());
      assertEquals(0.25F, j48_0.getConfidenceFactor(), 0.01F);
      assertFalse(j48_0.getDebug());
      assertEquals("Whether MDL correction is used when finding splits on numeric attributes.", j48_0.useMDLcorrectionTipText());
      assertFalse(j48_0.getUseLaplace());
      assertEquals("Whether counts at leaves are smoothed based on Laplace.", j48_0.useLaplaceTipText());
      assertEquals("Whether to consider the subtree raising operation when pruning.", j48_0.subtreeRaisingTipText());
      assertEquals("Whether to use binary splits on nominal attributes when building the trees.", j48_0.binarySplitsTipText());
      assertEquals("The confidence factor used for pruning (smaller values incur more pruning).", j48_0.confidenceFactorTipText());
      assertEquals("Determines the amount of data used for reduced-error pruning.  One fold is used for pruning, the rest for growing the tree.", j48_0.numFoldsTipText());
      assertEquals("Whether to save the training data for visualization.", j48_0.saveInstanceDataTipText());
      assertFalse(j48_0.getSaveInstanceData());
      assertEquals("Whether pruning is performed.", j48_0.unprunedTipText());
      assertFalse(j48_0.getReducedErrorPruning());
      
      J48 j48_1 = (J48)stacking0.getMetaClassifier();
      assertNotNull(j48_1);
      assertSame(j48_1, j48_0);
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertFalse(stacking0.getDebug());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertFalse(j48_1.getReducedErrorPruning());
      assertEquals(1, j48_1.getSeed());
      assertEquals("Whether to use binary splits on nominal attributes when building the trees.", j48_1.binarySplitsTipText());
      assertEquals("Whether to consider the subtree raising operation when pruning.", j48_1.subtreeRaisingTipText());
      assertEquals("The seed used for randomizing the data when reduced-error pruning is used.", j48_1.seedTipText());
      assertEquals("Whether reduced-error pruning is used instead of C.4.5 pruning.", j48_1.reducedErrorPruningTipText());
      assertFalse(j48_1.getUseLaplace());
      assertFalse(j48_1.getUnpruned());
      assertEquals("Whether MDL correction is used when finding splits on numeric attributes.", j48_1.useMDLcorrectionTipText());
      assertEquals("Whether counts at leaves are smoothed based on Laplace.", j48_1.useLaplaceTipText());
      assertEquals("Whether pruning is performed.", j48_1.unprunedTipText());
      assertTrue(j48_1.getUseMDLcorrection());
      assertEquals("Whether to save the training data for visualization.", j48_1.saveInstanceDataTipText());
      assertEquals(2, j48_1.getMinNumObj());
      assertTrue(j48_1.getCollapseTree());
      assertEquals(0.25F, j48_1.getConfidenceFactor(), 0.01F);
      assertEquals(3, j48_1.getNumFolds());
      assertEquals("If set to true, classifier may output additional info to the console.", j48_1.debugTipText());
      assertFalse(j48_1.getSaveInstanceData());
      assertEquals("Determines the amount of data used for reduced-error pruning.  One fold is used for pruning, the rest for growing the tree.", j48_1.numFoldsTipText());
      assertEquals("Whether parts are removed that do not reduce training error.", j48_1.collapseTreeTipText());
      assertFalse(j48_1.getBinarySplits());
      assertEquals("The confidence factor used for pruning (smaller values incur more pruning).", j48_1.confidenceFactorTipText());
      assertEquals(1, j48_1.graphType());
      assertFalse(j48_1.getDebug());
      assertEquals("The minimum number of instances per leaf.", j48_1.minNumObjTipText());
      assertTrue(j48_1.getSubtreeRaising());
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertNotNull(regressionByDiscretization0);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0);
      assertNotNull(sparseInstance0);
      assertEquals(0, doubleArray0.length);
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(0, sparseInstance0.numAttributes());
      assertEquals(0.0, sparseInstance0.weight(), 0.01);
      assertEquals(0, sparseInstance0.numValues());
      
      try { 
        evaluation0.updateStatsForIntervalEstimator(regressionByDiscretization0, sparseInstance0, 4.9E-324);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.meta.RegressionByDiscretization", e);
      }
  }

  /**
  //Test case number: 63
  /*Coverage entropy=0.4666666666666667
  */
  @Test(timeout = 4000)
  public void test063()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      
      testInstances0.setNumNominal(117);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(118, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(118, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(118, instances0.numAttributes());
      assertEquals(117, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(118, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(118, instances0.numAttributes());
      assertEquals(117, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      MockRandom mockRandom0 = new MockRandom((-1));
      assertNotNull(mockRandom0);
      
      evaluation0.addNumericTrainClass((-2724.45730929), (-3074.381764487506));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(118, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(118, instances0.numAttributes());
      assertEquals(117, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      double double0 = evaluation0.weightedFalsePositiveRate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(117, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(118, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(118, instances0.numAttributes());
      assertEquals(117, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.m_SumClassPredicted;
      assertNotEquals(double1, double0, 0.01);
      assertEquals(0.0, double1, 0.01);
  }

  /**
  //Test case number: 64
  /*Coverage entropy=0.4444444444444445
  */
  @Test(timeout = 4000)
  public void test064()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      
      Stacking stacking0 = new Stacking();
      assertNotNull(stacking0);
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, stacking0.getNumFolds());
      
      J48 j48_0 = new J48();
      assertNotNull(j48_0);
      assertFalse(j48_0.getDebug());
      assertEquals("Determines the amount of data used for reduced-error pruning.  One fold is used for pruning, the rest for growing the tree.", j48_0.numFoldsTipText());
      assertFalse(j48_0.getSaveInstanceData());
      assertEquals("Whether MDL correction is used when finding splits on numeric attributes.", j48_0.useMDLcorrectionTipText());
      assertEquals("Whether reduced-error pruning is used instead of C.4.5 pruning.", j48_0.reducedErrorPruningTipText());
      assertEquals("The confidence factor used for pruning (smaller values incur more pruning).", j48_0.confidenceFactorTipText());
      assertEquals(0.25F, j48_0.getConfidenceFactor(), 0.01F);
      assertEquals("Whether parts are removed that do not reduce training error.", j48_0.collapseTreeTipText());
      assertEquals("Whether counts at leaves are smoothed based on Laplace.", j48_0.useLaplaceTipText());
      assertTrue(j48_0.getUseMDLcorrection());
      assertEquals(3, j48_0.getNumFolds());
      assertTrue(j48_0.getCollapseTree());
      assertEquals(2, j48_0.getMinNumObj());
      assertEquals("Whether to consider the subtree raising operation when pruning.", j48_0.subtreeRaisingTipText());
      assertEquals("Whether to use binary splits on nominal attributes when building the trees.", j48_0.binarySplitsTipText());
      assertEquals("Whether to save the training data for visualization.", j48_0.saveInstanceDataTipText());
      assertEquals("The seed used for randomizing the data when reduced-error pruning is used.", j48_0.seedTipText());
      assertEquals("Whether pruning is performed.", j48_0.unprunedTipText());
      assertFalse(j48_0.getBinarySplits());
      assertFalse(j48_0.getReducedErrorPruning());
      assertFalse(j48_0.getUseLaplace());
      assertFalse(j48_0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", j48_0.debugTipText());
      assertEquals("The minimum number of instances per leaf.", j48_0.minNumObjTipText());
      assertEquals(1, j48_0.graphType());
      assertEquals(1, j48_0.getSeed());
      assertTrue(j48_0.getSubtreeRaising());
      
      Classifier[] classifierArray0 = new Classifier[0];
      stacking0.setClassifiers(classifierArray0);
      assertEquals(0, classifierArray0.length);
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, stacking0.getNumFolds());
      
      stacking0.setMetaClassifier(j48_0);
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertFalse(j48_0.getDebug());
      assertEquals("Determines the amount of data used for reduced-error pruning.  One fold is used for pruning, the rest for growing the tree.", j48_0.numFoldsTipText());
      assertFalse(j48_0.getSaveInstanceData());
      assertEquals("Whether MDL correction is used when finding splits on numeric attributes.", j48_0.useMDLcorrectionTipText());
      assertEquals("Whether reduced-error pruning is used instead of C.4.5 pruning.", j48_0.reducedErrorPruningTipText());
      assertEquals("The confidence factor used for pruning (smaller values incur more pruning).", j48_0.confidenceFactorTipText());
      assertEquals(0.25F, j48_0.getConfidenceFactor(), 0.01F);
      assertEquals("Whether parts are removed that do not reduce training error.", j48_0.collapseTreeTipText());
      assertEquals("Whether counts at leaves are smoothed based on Laplace.", j48_0.useLaplaceTipText());
      assertTrue(j48_0.getUseMDLcorrection());
      assertEquals(3, j48_0.getNumFolds());
      assertTrue(j48_0.getCollapseTree());
      assertEquals(2, j48_0.getMinNumObj());
      assertEquals("Whether to consider the subtree raising operation when pruning.", j48_0.subtreeRaisingTipText());
      assertEquals("Whether to use binary splits on nominal attributes when building the trees.", j48_0.binarySplitsTipText());
      assertEquals("Whether to save the training data for visualization.", j48_0.saveInstanceDataTipText());
      assertEquals("The seed used for randomizing the data when reduced-error pruning is used.", j48_0.seedTipText());
      assertEquals("Whether pruning is performed.", j48_0.unprunedTipText());
      assertFalse(j48_0.getBinarySplits());
      assertFalse(j48_0.getReducedErrorPruning());
      assertFalse(j48_0.getUseLaplace());
      assertFalse(j48_0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", j48_0.debugTipText());
      assertEquals("The minimum number of instances per leaf.", j48_0.minNumObjTipText());
      assertEquals(1, j48_0.graphType());
      assertEquals(1, j48_0.getSeed());
      assertTrue(j48_0.getSubtreeRaising());
      
      J48 j48_1 = (J48)stacking0.getMetaClassifier();
      assertNotNull(j48_1);
      assertSame(j48_1, j48_0);
      assertEquals(1, stacking0.getNumExecutionSlots());
      assertFalse(stacking0.getDebug());
      assertEquals("The base classifiers to be used.", stacking0.classifiersTipText());
      assertEquals("The number of execution slots (threads) to use for constructing the ensemble.", stacking0.numExecutionSlotsTipText());
      assertEquals("The number of folds used for cross-validation.", stacking0.numFoldsTipText());
      assertEquals(1, stacking0.getSeed());
      assertEquals("The random number seed to be used.", stacking0.seedTipText());
      assertEquals("The meta classifiers to be used.", stacking0.metaClassifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", stacking0.debugTipText());
      assertEquals(10, stacking0.getNumFolds());
      assertEquals(3, j48_1.getNumFolds());
      assertEquals(0.25F, j48_1.getConfidenceFactor(), 0.01F);
      assertEquals("Whether parts are removed that do not reduce training error.", j48_1.collapseTreeTipText());
      assertFalse(j48_1.getSaveInstanceData());
      assertEquals("Whether counts at leaves are smoothed based on Laplace.", j48_1.useLaplaceTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", j48_1.debugTipText());
      assertFalse(j48_1.getBinarySplits());
      assertTrue(j48_1.getCollapseTree());
      assertEquals(2, j48_1.getMinNumObj());
      assertEquals("Whether reduced-error pruning is used instead of C.4.5 pruning.", j48_1.reducedErrorPruningTipText());
      assertFalse(j48_1.getUnpruned());
      assertEquals(1, j48_1.getSeed());
      assertFalse(j48_1.getReducedErrorPruning());
      assertTrue(j48_1.getUseMDLcorrection());
      assertEquals("Whether pruning is performed.", j48_1.unprunedTipText());
      assertEquals("Whether to save the training data for visualization.", j48_1.saveInstanceDataTipText());
      assertFalse(j48_1.getUseLaplace());
      assertEquals("The confidence factor used for pruning (smaller values incur more pruning).", j48_1.confidenceFactorTipText());
      assertEquals("The minimum number of instances per leaf.", j48_1.minNumObjTipText());
      assertEquals("Whether MDL correction is used when finding splits on numeric attributes.", j48_1.useMDLcorrectionTipText());
      assertTrue(j48_1.getSubtreeRaising());
      assertEquals(1, j48_1.graphType());
      assertFalse(j48_1.getDebug());
      assertEquals("The seed used for randomizing the data when reduced-error pruning is used.", j48_1.seedTipText());
      assertEquals("Determines the amount of data used for reduced-error pruning.  One fold is used for pruning, the rest for growing the tree.", j48_1.numFoldsTipText());
      assertEquals("Whether to use binary splits on nominal attributes when building the trees.", j48_1.binarySplitsTipText());
      assertEquals("Whether to consider the subtree raising operation when pruning.", j48_1.subtreeRaisingTipText());
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertNotNull(regressionByDiscretization0);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertFalse(regressionByDiscretization0.getDebug());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      
      evaluation0.addNumericTrainClass(1000.0, (-4202.11));
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
  }

  /**
  //Test case number: 65
  /*Coverage entropy=1.87565606324755
  */
  @Test(timeout = 4000)
  public void test065()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      evaluation0.setPriors(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals(2, doubleArray0.length);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertNotNull(evaluation1);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      
      double double0 = evaluation1.falsePositiveRate((-2));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.unweightedMacroFmeasure();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.weightedAreaUnderPRC();
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      assertNotSame(evaluation0, evaluation1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation1.totalCost();
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotEquals(double3, double1, 0.01);
      assertEquals(double3, double0, 0.01);
      assertNotEquals(double3, double2, 0.01);
      assertNotSame(evaluation1, evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(0.0, double3, 0.01);
      
      String string0 = instances0.toSummaryString();
      assertNotNull(string0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Relation Name:  Testdata\nNum Instances:  20\nNum Attributes: 2\n\n     Name                      Type  Nom  Int Real     Missing      Unique  Dist\n   1 Nominal1                   Nom 100%   0%   0%     0 /  0%     0 /  0%     2 \n   2 Class                      Nom 100%   0%   0%     0 /  0%     0 /  0%     2 \n", string0);
      
      try { 
        evaluation1.evaluateModelOnce(0.0, (Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 66
  /*Coverage entropy=0.42857142857142855
  */
  @Test(timeout = 4000)
  public void test066()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      
      BayesNet bayesNet0 = new BayesNet();
      assertNotNull(bayesNet0);
      assertEquals("Set the name of a file in BIF XML format. A Bayes network learned from data can be compared with the Bayes network represented by the BIF file. Statistics calculated are o.a. the number of missing and extra arcs.", bayesNet0.BIFFileTipText());
      assertEquals("Select Estimator algorithm for finding the conditional probability tables of the Bayes Network.", bayesNet0.estimatorTipText());
      assertEquals("Select method used for searching network structures.", bayesNet0.searchAlgorithmTipText());
      assertFalse(bayesNet0.getDebug());
      assertEquals(2, bayesNet0.graphType());
      assertEquals("Bayes Network learning using various search algorithms and quality measures.\nBase class for a Bayes Network classifier. Provides datastructures (network structure, conditional probability distributions, etc.) and facilities common to Bayes Network learning algorithms like K2 and B.\n\nFor more information see:\n\nhttp://www.cs.waikato.ac.nz/~remco/weka.pdf", bayesNet0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", bayesNet0.debugTipText());
      assertFalse(bayesNet0.getUseADTree());
      assertEquals("When ADTree (the data structure for increasing speed on counts, not to be confused with the classifier under the same name) is used learning time goes down typically. However, because ADTrees are memory intensive, memory problems may occur. Switching this option off makes the structure learning algorithms slower, and run with less memory. By default, ADTrees are used.", bayesNet0.useADTreeTipText());
      
      TestInstances testInstances1 = new TestInstances();
      assertNotNull(testInstances1);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances1.getNumDate());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertFalse(testInstances1.getMultiInstance());
      assertFalse(testInstances1.getNoClass());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(0, testInstances1.getNumRelationalDate());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumAttributes());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(0, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(0, testInstances1.getNumString());
      
      Instances instances0 = testInstances1.generate();
      assertNotNull(instances0);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances1.getNumDate());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertFalse(testInstances1.getMultiInstance());
      assertFalse(testInstances1.getNoClass());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(0, testInstances1.getNumRelationalDate());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumAttributes());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(0, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(0, testInstances1.getNumString());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      CostMatrix costMatrix0 = null;
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertNotNull(evaluation0);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances1.getNumDate());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertFalse(testInstances1.getMultiInstance());
      assertFalse(testInstances1.getNoClass());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(0, testInstances1.getNumRelationalDate());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumAttributes());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(0, testInstances1.getNumRelationalNumeric());
      assertEquals(0, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(0, testInstances1.getNumString());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = 10.0;
      doubleArray0[2] = (double) (-2);
      try { 
        evaluation0.updateStatsForClassifier(doubleArray0, (Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 67
  /*Coverage entropy=0.4615384615384615
  */
  @Test(timeout = 4000)
  public void test067()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      
      testInstances0.setNumNominal(111);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      Instances instances1 = new Instances(instances0);
      assertNotNull(instances1);
      assertFalse(instances1.equals((Object)instances0));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(112, instances1.numAttributes());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(111, instances1.classIndex());
      assertEquals(2, instances1.numClasses());
      assertEquals(20, instances1.size());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.numInstances());
      
      String string0 = instances0.toSummaryString();
      assertNotNull(string0);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(111, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(112, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertFalse(multilayerPerceptron0.getGUI());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      
      double[] doubleArray0 = evaluation0.m_MarginCounts;
      assertNotNull(doubleArray0);
      assertEquals(501, doubleArray0.length);
      
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray0, (Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 68
  /*Coverage entropy=1.8564909139241832
  */
  @Test(timeout = 4000)
  public void test068()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      assertNotNull(multilayerPerceptron0);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      assertNotNull(capabilities0);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      
      Instances instances0 = testInstances0.generate("ov\"sW{?q%gG&ViI,$-");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      
      NaiveBayes naiveBayes0 = new NaiveBayes();
      assertNotNull(naiveBayes0);
      assertFalse(naiveBayes0.getDebug());
      assertFalse(naiveBayes0.getUseSupervisedDiscretization());
      assertEquals("Use a kernel estimator for numeric attributes rather than a normal distribution.", naiveBayes0.useKernelEstimatorTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", naiveBayes0.debugTipText());
      assertEquals("Use old format for model output. The old format is better when there are many class values. The new format is better when there are fewer classes and many attributes.", naiveBayes0.displayModelInOldFormatTipText());
      assertFalse(naiveBayes0.getDisplayModelInOldFormat());
      assertFalse(naiveBayes0.getUseKernelEstimator());
      assertEquals("Use supervised discretization to convert numeric attributes to nominal ones.", naiveBayes0.useSupervisedDiscretizationTipText());
      
      String string0 = Evaluation.getGlobalInfo(multilayerPerceptron0);
      assertNotNull(string0);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("\nSynopsis for weka.classifiers.functions.MultilayerPerceptron:\n\nA Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", string0);
      
      ZeroR zeroR0 = new ZeroR();
      assertNotNull(zeroR0);
      assertFalse(zeroR0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", zeroR0.debugTipText());
      assertEquals("Class for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).", zeroR0.globalInfo());
      
      MultilayerPerceptron multilayerPerceptron1 = (MultilayerPerceptron)AbstractClassifier.makeCopy(multilayerPerceptron0);
      assertNotNull(multilayerPerceptron1);
      assertFalse(multilayerPerceptron1.equals((Object)multilayerPerceptron0));
      assertNotSame(multilayerPerceptron0, multilayerPerceptron1);
      assertNotSame(multilayerPerceptron1, multilayerPerceptron0);
      assertEquals(0.2, multilayerPerceptron0.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron0.getSeed());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron0.hiddenLayersTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron0.decayTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron0.learningRateTipText());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron0.globalInfo());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron0.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron0.debugTipText());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron0.normalizeNumericClassTipText());
      assertTrue(multilayerPerceptron0.getAutoBuild());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron0.seedTipText());
      assertEquals(0, multilayerPerceptron0.getValidationSetSize());
      assertEquals(500, multilayerPerceptron0.getTrainingTime());
      assertEquals(0.3, multilayerPerceptron0.getLearningRate(), 0.01);
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron0.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron0.normalizeAttributesTipText());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron0.validationSetSizeTipText());
      assertEquals(20, multilayerPerceptron0.getValidationThreshold());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron0.nominalToBinaryFilterTipText());
      assertTrue(multilayerPerceptron0.getNormalizeNumericClass());
      assertEquals("a", multilayerPerceptron0.getHiddenLayers());
      assertFalse(multilayerPerceptron0.getDecay());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron0.resetTipText());
      assertFalse(multilayerPerceptron0.getDebug());
      assertFalse(multilayerPerceptron0.getGUI());
      assertTrue(multilayerPerceptron0.getReset());
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron0.trainingTimeTipText());
      assertTrue(multilayerPerceptron0.getNormalizeAttributes());
      assertTrue(multilayerPerceptron0.getNominalToBinaryFilter());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron0.momentumTipText());
      assertEquals("This will preprocess the instances with the filter. This could help improve performance if there are nominal attributes in the data.", multilayerPerceptron1.nominalToBinaryFilterTipText());
      assertEquals("Adds and connects up hidden layers in the network.", multilayerPerceptron1.autoBuildTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multilayerPerceptron1.debugTipText());
      assertEquals("Momentum applied to the weights during updating.", multilayerPerceptron1.momentumTipText());
      assertEquals("Seed used to initialise the random number generator.Random numbers are used for setting the initial weights of the connections betweem nodes, and also for shuffling the training data.", multilayerPerceptron1.seedTipText());
      assertTrue(multilayerPerceptron1.getAutoBuild());
      assertEquals("This will normalize the class if it's numeric. This could help improve performance of the network, It normalizes the class to be between -1 and 1. Note that this is only internally, the output will be scaled back to the original range.", multilayerPerceptron1.normalizeNumericClassTipText());
      assertEquals("Used to terminate validation testing.The value here dictates how many times in a row the validation set error can get worse before training is terminated.", multilayerPerceptron1.validationThresholdTipText());
      assertEquals("This will normalize the attributes. This could help improve performance of the network. This is not reliant on the class being numeric. This will also normalize nominal attributes as well (after they have been run through the nominal to binary filter if that is in use) so that the nominal values are between -1 and 1", multilayerPerceptron1.normalizeAttributesTipText());
      assertEquals("The amount the weights are updated.", multilayerPerceptron1.learningRateTipText());
      assertEquals("This will cause the learning rate to decrease. This will divide the starting learning rate by the epoch number, to determine what the current learning rate should be. This may help to stop the network from diverging from the target output, as well as improve general performance. Note that the decaying learning rate will not be shown in the gui, only the original learning rate. If the learning rate is changed in the gui, this is treated as the starting learning rate.", multilayerPerceptron1.decayTipText());
      assertTrue(multilayerPerceptron1.getReset());
      assertTrue(multilayerPerceptron1.getNominalToBinaryFilter());
      assertFalse(multilayerPerceptron1.getGUI());
      assertEquals("The percentage size of the validation set.(The training will continue until it is observed that the error on the validation set has been consistently getting worse, or if the training time is reached).\nIf This is set to zero no validation set will be used and instead the network will train for the specified number of epochs.", multilayerPerceptron1.validationSetSizeTipText());
      assertFalse(multilayerPerceptron1.getDecay());
      assertEquals("This defines the hidden layers of the neural network. This is a list of positive whole numbers. 1 for each hidden layer. Comma seperated. To have no hidden layers put a single 0 here. This will only be used if autobuild is set. There are also wildcard values 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.", multilayerPerceptron1.hiddenLayersTipText());
      assertEquals("a", multilayerPerceptron1.getHiddenLayers());
      assertEquals(0.2, multilayerPerceptron1.getMomentum(), 0.01);
      assertEquals(0, multilayerPerceptron1.getSeed());
      assertEquals("A Classifier that uses backpropagation to classify instances.\nThis network can be built by hand, created by an algorithm or both. The network can also be monitored and modified during training time. The nodes in this network are all sigmoid (except for when the class is numeric in which case the the output nodes become unthresholded linear units).", multilayerPerceptron1.globalInfo());
      assertTrue(multilayerPerceptron1.getNormalizeAttributes());
      assertFalse(multilayerPerceptron1.getDebug());
      assertEquals(0, multilayerPerceptron1.getValidationSetSize());
      assertEquals("This will allow the network to reset with a lower learning rate. If the network diverges from the answer this will automatically reset the network with a lower learning rate and begin training again. This option is only available if the gui is not set. Note that if the network diverges but isn't allowed to reset it will fail the training process and return an error message.", multilayerPerceptron1.resetTipText());
      assertEquals(0.3, multilayerPerceptron1.getLearningRate(), 0.01);
      assertEquals("The number of epochs to train through. If the validation set is non-zero then it can terminate the network early", multilayerPerceptron1.trainingTimeTipText());
      assertEquals(500, multilayerPerceptron1.getTrainingTime());
      assertEquals(20, multilayerPerceptron1.getValidationThreshold());
      assertTrue(multilayerPerceptron1.getNormalizeNumericClass());
      
      try { 
        evaluation0.crossValidateModel((Classifier) multilayerPerceptron1, instances0, (-1), (Random) null, (Object[]) testInstances0.DEFAULT_WORDS);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 69
  /*Coverage entropy=0.48717948717948717
  */
  @Test(timeout = 4000)
  public void test069()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      
      testInstances0.setNumNominal(111);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      
      Instances instances0 = testInstances0.generate(" ");
      assertNotNull(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.weightedMatthewsCorrelation();
      assertNotEquals(double1, double0, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.falseNegativeRate((-1));
      assertEquals(double2, double0, 0.01);
      assertNotEquals(double2, double1, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, double2, 0.01);
      
      double double3 = evaluation0.m_SumPriorAbsErr;
      assertEquals(double3, double0, 0.01);
      assertEquals(double3, double2, 0.01);
      assertNotEquals(double3, double1, 0.01);
      assertEquals(0.0, double3, 0.01);
      
      double double4 = evaluation0.weightedFalseNegativeRate();
      assertNotEquals(double4, double0, 0.01);
      assertNotEquals(double4, double2, 0.01);
      assertEquals(double4, double1, 0.01);
      assertNotEquals(double4, double3, 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(112, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(111, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(111, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(112, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, double4, 0.01);
  }

  /**
  //Test case number: 70
  /*Coverage entropy=1.5748027648585858
  */
  @Test(timeout = 4000)
  public void test070()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      String string0 = evaluation0.toMatrixString();
      assertNotNull(string0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals("=== Confusion Matrix ===\n\n   <-- classified as\n", string0);
      
      double[][] doubleArray0 = evaluation0.m_ConfusionMatrix;
      assertNotNull(doubleArray0);
      assertEquals(0, doubleArray0.length);
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertNotNull(regressionByDiscretization0);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      
      ArffLoader arffLoader0 = new ArffLoader();
      assertNotNull(arffLoader0);
      assertEquals("http://", arffLoader0.retrieveURL());
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals(".arff", arffLoader0.getFileExtension());
      
      double double0 = evaluation0.falseNegativeRate(1406);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, double0, 0.01);
      
      String string1 = evaluation0.toMatrixString("@relation");
      assertNotNull(string1);
      assertFalse(string1.equals((Object)string0));
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals("@relation\n   <-- classified as\n", string1);
      
      double double1 = evaluation0.relativeAbsoluteError();
      assertNotEquals(double1, double0, 0.01);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_termite_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
  }

  /**
  //Test case number: 71
  /*Coverage entropy=1.8764904395512632
  */
  @Test(timeout = 4000)
  public void test071()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("ov\"sW{?q%gG&ViI,$-");
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.SFEntropyGain();
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.weightedMatthewsCorrelation();
      assertEquals(Double.NaN, double1, 0.01);
      
      evaluation0.confusionMatrix();
      evaluation0.rootRelativeSquaredError();
      Integer integer0 = new Integer((-1));
      evaluation0.toSummaryString(true);
      evaluation0.toSummaryString(true);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
  }

  /**
  //Test case number: 72
  /*Coverage entropy=2.5781292057218304
  */
  @Test(timeout = 4000)
  public void test072()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      Capabilities capabilities0 = multilayerPerceptron0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.setNumNominal(111);
      FileSystemHandling.shouldAllThrowIOExceptions();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.SFEntropyGain();
      evaluation0.weightedMatthewsCorrelation();
      evaluation0.numFalseNegatives((-1));
      double[][] doubleArray0 = evaluation0.m_ConfusionMatrix;
      MockRandom mockRandom0 = new MockRandom();
      evaluation0.SFMeanSchemeEntropy();
      double[] doubleArray1 = evaluation0.makeDistribution(Double.NaN);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0}, doubleArray1, 0.01);
      
      evaluation0.SFMeanSchemeEntropy();
      evaluation0.toSummaryString();
      evaluation0.getDiscardPredictions();
      String string0 = evaluation0.toCumulativeMarginDistributionString();
      assertEquals(" -1       0    \n", string0);
      
      evaluation0.useNoPriors();
      String string1 = evaluation0.toClassDetailsString();
      assertEquals("=== Detailed Accuracy By Class ===\n\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\n                 0        0        0          0       0          0     ?         ?         class1\n                 0        0        0          0       0          0     ?         ?         class2\n                 0        0        0          0       0          0     ?         ?         class3\n                 0        0        0          0       0          0     ?         ?         class4\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string1);
  }

  /**
  //Test case number: 73
  /*Coverage entropy=2.6670329067710106
  */
  @Test(timeout = 4000)
  public void test073()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertEquals(0, doubleArray0.length);
      
      double[] doubleArray1 = evaluation0.getClassPriors();
      assertNotNull(doubleArray1);
      
      evaluation0.SFMeanSchemeEntropy();
      evaluation0.m_MissingClass = 0.0;
      evaluation0.unweightedMacroFmeasure();
      double double0 = evaluation0.KBRelativeInformation();
      double double1 = evaluation0.SFMeanSchemeEntropy();
      assertEquals(double1, double0, 0.01);
      
      double[] doubleArray2 = evaluation0.makeDistribution(Double.NaN);
      assertEquals(0, doubleArray2.length);
  }

  /**
  //Test case number: 74
  /*Coverage entropy=1.560150750206571
  */
  @Test(timeout = 4000)
  public void test074()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.avgCost();
      int int0 = 0;
      try { 
        evaluation0.evaluateModelOnce((double) 0, (Instance) null);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 75
  /*Coverage entropy=1.5888083670994821
  */
  @Test(timeout = 4000)
  public void test075()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.SFEntropyGain();
      evaluation0.weightedMatthewsCorrelation();
      evaluation0.rootRelativeSquaredError();
      Integer integer0 = new Integer((-1));
      evaluation0.matthewsCorrelationCoefficient((-1));
      evaluation0.addNumericTrainClass(Double.NaN, 0.0);
      // Undeclared exception!
      try { 
        evaluation0.precision((-2035344874));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -2035344874
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 76
  /*Coverage entropy=1.5888083670994821
  */
  @Test(timeout = 4000)
  public void test076()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.SFEntropyGain();
      evaluation0.weightedMatthewsCorrelation();
      evaluation0.rootRelativeSquaredError();
      evaluation0.matthewsCorrelationCoefficient((-2));
      evaluation0.addNumericTrainClass(0.0, 0.0);
      // Undeclared exception!
      try { 
        evaluation0.precision((-2));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -2
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 77
  /*Coverage entropy=2.832016211752416
  */
  @Test(timeout = 4000)
  public void test077()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.setNumNominal(111);
      FileSystemHandling.shouldAllThrowIOExceptions();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.SFEntropyGain();
      evaluation0.weightedMatthewsCorrelation();
      evaluation0.numFalseNegatives((-1));
      evaluation0.confusionMatrix();
      MockRandom mockRandom0 = new MockRandom();
      // Undeclared exception!
      try { 
        evaluation0.recall((-1));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -1
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 78
  /*Coverage entropy=1.8624848373103666
  */
  @Test(timeout = 4000)
  public void test078()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.KBMeanInformation();
      evaluation0.avgCost();
      RandomForest randomForest0 = new RandomForest();
      evaluation0.toSummaryString();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      evaluation0.SFSchemeEntropy();
      MockRandom mockRandom0 = new MockRandom(1499L);
      try { 
        evaluation0.crossValidateModel((Classifier) randomForest0, instances0, 2, (Random) mockRandom0, (Object[]) costSensitiveClassifier0.TAGS_MATRIX_SOURCE);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // weka.core.Tag cannot be cast to weka.classifiers.evaluation.output.prediction.AbstractOutput
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 79
  /*Coverage entropy=2.0205510251350907
  */
  @Test(timeout = 4000)
  public void test079()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.weightedAreaUnderROC();
      double double0 = evaluation0.m_Unclassified;
      Double double1 = new Double(Double.NaN);
      try { 
        Evaluation.handleCostOption(" ", 926);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't open file null.
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 80
  /*Coverage entropy=1.163735415854063
  */
  @Test(timeout = 4000)
  public void test080()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.SFEntropyGain();
      double double1 = evaluation0.meanPriorAbsoluteError();
      double double2 = evaluation0.priorEntropy();
      assertEquals(double2, double0, 0.01);
      
      double double3 = evaluation0.weightedPrecision();
      assertEquals(double3, double1, 0.01);
      
      evaluation0.getHeader();
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
  }

  /**
  //Test case number: 81
  /*Coverage entropy=1.1840562714690361
  */
  @Test(timeout = 4000)
  public void test081()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumNominal(111);
      Instances instances0 = testInstances0.generate(" ");
      Comparator<Object> comparator0 = (Comparator<Object>) mock(Comparator.class, new ViolatedAssumptionAnswer());
      doReturn(0, 0, 0, 0, 0).when(comparator0).compare(any() , any());
      instances0.sort(comparator0);
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.SFEntropyGain();
      double double0 = evaluation0.weightedMatthewsCorrelation();
      assertEquals(Double.NaN, double0, 0.01);
      
      double double1 = evaluation0.falseNegativeRate((-1));
      assertEquals(0.0, double1, 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0, (CostMatrix) null);
      evaluation1.SFMeanSchemeEntropy();
      evaluation1.useNoPriors();
      evaluation1.SFMeanEntropyGain();
      evaluation1.errorRate();
      String string0 = evaluation1.toMatrixString("mbc");
      assertEquals("mbc\n a b   <-- classified as\n 0 0 | a = class1\n 0 0 | b = class2\n", string0);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
  }

  /**
  //Test case number: 82
  /*Coverage entropy=1.1476926351053998
  */
  @Test(timeout = 4000)
  public void test082()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      SimpleLogistic simpleLogistic0 = new SimpleLogistic();
      String string0 = Evaluation.getGlobalInfo(simpleLogistic0);
      assertEquals("\nSynopsis for weka.classifiers.functions.SimpleLogistic:\n\nClassifier for building linear logistic regression models. LogitBoost with simple regression functions as base learners is used for fitting the logistic models. The optimal number of LogitBoost iterations to perform is cross-validated, which leads to automatic attribute selection. For more information see:\nNiels Landwehr, Mark Hall, Eibe Frank (2005). Logistic Model Trees.\n\nMarc Sumner, Eibe Frank, Mark Hall: Speeding up Logistic Model Tree Induction. In: 9th European Conference on Principles and Practice of Knowledge Discovery in Databases, 675-683, 2005.", string0);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.correct();
      assertEquals(0.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  /**
  //Test case number: 83
  /*Coverage entropy=1.582483256410045
  */
  @Test(timeout = 4000)
  public void test083()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      Stacking stacking0 = new Stacking();
      stacking0.getMetaClassifier();
      evaluation0.setDiscardPredictions(false);
      String string0 = evaluation0.toClassDetailsString();
      assertEquals("=== Detailed Accuracy By Class ===\n\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
  }

  /**
  //Test case number: 84
  /*Coverage entropy=1.1779956654084303
  */
  @Test(timeout = 4000)
  public void test084()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.SFEntropyGain();
      evaluation0.rootRelativeSquaredError();
      evaluation0.toMatrixString(" ");
      Evaluation evaluation1 = new Evaluation(instances0);
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      Evaluation evaluation2 = null;
      try {
        evaluation2 = new Evaluation(instances0, costMatrix0);
        fail("Expecting exception: Exception");
      
      } catch(Throwable e) {
         //
         // Cost matrix not compatible with data!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 85
  /*Coverage entropy=1.5813709093577648
  */
  @Test(timeout = 4000)
  public void test085()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      TextDirectoryLoader textDirectoryLoader1 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader1.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.setPriors(instances0);
      evaluation0.confusionMatrix();
      evaluation0.SFEntropyGain();
      evaluation0.weightedMatthewsCorrelation();
      evaluation0.numFalseNegatives(89);
      MockRandom mockRandom0 = new MockRandom();
      evaluation0.SFMeanSchemeEntropy();
      evaluation0.getClassPriors();
      evaluation0.SFMeanSchemeEntropy();
      evaluation0.numTruePositives(10);
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(10);
      try { 
        evaluation0.evaluateModelOnce((Classifier) inputMappedClassifier0, (Instance) binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.misc.InputMappedClassifier", e);
      }
  }

  /**
  //Test case number: 86
  /*Coverage entropy=1.1546856420984069
  */
  @Test(timeout = 4000)
  public void test086()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumRelationalNominal(105);
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      Instances instances1 = new Instances(instances0);
      instances0.toSummaryString();
      double[] doubleArray0 = evaluation0.m_MarginCounts;
      evaluation0.kappa();
      TestInstances testInstances1 = new TestInstances();
      testInstances1.setNumInstancesRelational(9);
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction((Classifier) costSensitiveClassifier0, (Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 87
  /*Coverage entropy=1.8677758426013722
  */
  @Test(timeout = 4000)
  public void test087()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.confusionMatrix();
      Version.VERSION = "x";
      evaluation0.precision(1);
      evaluation0.relativeAbsoluteError();
      evaluation0.numFalseNegatives(1);
      evaluation0.recall(1);
      evaluation0.SFMeanSchemeEntropy();
      LogitBoost logitBoost0 = new LogitBoost();
      try { 
        Evaluation.wekaStaticWrapper(logitBoost0, "x");
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No model built yet
         //
         verifyException("weka.classifiers.meta.LogitBoost", e);
      }
  }

  /**
  //Test case number: 88
  /*Coverage entropy=1.864555230685108
  */
  @Test(timeout = 4000)
  public void test088()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      Version.VERSION = "@relation";
      double double0 = evaluation0.precision(3);
      evaluation0.relativeAbsoluteError();
      double double1 = evaluation0.m_ClassPriorsSum;
      double double2 = evaluation0.recall(3);
      assertEquals(0.0, double2, 0.01);
      
      double double3 = evaluation0.m_SumPriorSqrErr;
      LogitBoost logitBoost0 = new LogitBoost();
      evaluation0.getHeader();
      double double4 = evaluation0.weightedAreaUnderROC();
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertNotEquals(double4, double0, 0.01);
      assertEquals(Double.NaN, double4, 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
  }

  /**
  //Test case number: 89
  /*Coverage entropy=1.9593337382266454
  */
  @Test(timeout = 4000)
  public void test089()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.weightedAreaUnderPRC();
      assertEquals(Double.NaN, double0, 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertEquals(0, doubleArray0.length);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  /**
  //Test case number: 90
  /*Coverage entropy=0.4736842105263158
  */
  @Test(timeout = 4000)
  public void test090()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      TextDirectoryLoader textDirectoryLoader1 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader1.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.setPriors(instances0);
      evaluation0.confusionMatrix();
      Evaluation evaluation1 = new Evaluation(instances0);
      double[] doubleArray0 = new double[5];
      doubleArray0[3] = (double) 1;
      doubleArray0[4] = (double) (-1101);
      evaluation1.updateMargins(doubleArray0, 1, (-1109.97811));
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
  }

  /**
  //Test case number: 91
  /*Coverage entropy=2.397980361433392
  */
  @Test(timeout = 4000)
  public void test091()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getStructure();
      Evaluation evaluation0 = new Evaluation(instances0);
      Enumeration enumeration0 = new NGramTokenizer();
      evaluation0.toSummaryString(".bsi", false);
      evaluation0.setNumericPriorsFromBuffer();
      double double0 = evaluation0.SFMeanEntropyGain();
      double double1 = evaluation0.pctIncorrect();
      assertEquals(double1, double0, 0.01);
      assertEquals(Double.NaN, double1, 0.01);
  }

  /**
  //Test case number: 92
  /*Coverage entropy=2.8856067532168717
  */
  @Test(timeout = 4000)
  public void test092()  throws Throwable  {
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      Capabilities capabilities0 = filteredClassifier0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.setNumNominal(111);
      FileSystemHandling.shouldAllThrowIOExceptions();
      Instances instances0 = testInstances0.generate((String) null);
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.SFEntropyGain();
      evaluation0.weightedMatthewsCorrelation();
      evaluation0.numFalseNegatives(0);
      Attribute attribute0 = new Attribute("  public String toString() {\n", (-439));
      String[] stringArray0 = new String[7];
      stringArray0[0] = "@attribute";
      stringArray0[1] = "-s <class na?e>\n";
      stringArray0[2] = "integer";
      stringArray0[3] = "integer";
      stringArray0[4] = "No assignments made.";
      stringArray0[5] = "integer";
      stringArray0[6] = null;
      Attribute.main(stringArray0);
      instances0.setClass(attribute0);
      evaluation0.trueNegativeRate(1);
      evaluation0.SFEntropyGain();
      evaluation0.unweightedMacroFmeasure();
      evaluation0.matthewsCorrelationCoefficient(1568);
      // Undeclared exception!
      try { 
        evaluation0.precision(111);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 111
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 93
  /*Coverage entropy=1.166831391086261
  */
  @Test(timeout = 4000)
  public void test093()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getStructure();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.confusionMatrix();
      MockRandom mockRandom0 = new MockRandom();
      evaluation0.rootRelativeSquaredError();
      double double0 = evaluation0.SFMeanSchemeEntropy();
      double double1 = evaluation0.weightedFMeasure();
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(double1, double0, 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
  }

  /**
  //Test case number: 94
  /*Coverage entropy=0.3333333333333333
  */
  @Test(timeout = 4000)
  public void test094()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      testInstances0.generate();
      ZeroR zeroR0 = new ZeroR();
      try { 
        Evaluation.getGlobalInfo((Classifier) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 95
  /*Coverage entropy=0.4444444444444445
  */
  @Test(timeout = 4000)
  public void test095()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      // Undeclared exception!
      try { 
        evaluation0.precision((-1));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -1
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 96
  /*Coverage entropy=0.4666666666666667
  */
  @Test(timeout = 4000)
  public void test096()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumNominal(117);
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      MockRandom mockRandom0 = new MockRandom((-1));
      evaluation0.weightedAreaUnderPRC();
      OneR oneR0 = new OneR();
      try { 
        evaluation0.crossValidateModel((Classifier) oneR0, instances0, (-1), (Random) mockRandom0, (Object[]) testInstances0.DEFAULT_WORDS);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Number of folds must be greater than 1
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 97
  /*Coverage entropy=1.5813709093577648
  */
  @Test(timeout = 4000)
  public void test097()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      Instances instances1 = new Instances(instances0);
      String string0 = evaluation0.toCumulativeMarginDistributionString();
      assertEquals(" -1       0    \n", string0);
      
      double double0 = evaluation0.m_Unclassified;
      Double double1 = new Double((-2));
      evaluation0.totalCost();
      BayesNet bayesNet0 = new BayesNet();
      double double2 = evaluation0.unweightedMicroFmeasure();
      assertEquals(Double.NaN, double2, 0.01);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      evaluation0.SFSchemeEntropy();
      double double3 = evaluation0.incorrect();
      assertEquals(0.0, double3, 0.01);
  }

  /**
  //Test case number: 98
  /*Coverage entropy=1.1476926351053998
  */
  @Test(timeout = 4000)
  public void test098()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumNominal(117);
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      MockRandom mockRandom0 = new MockRandom((-1));
      double double0 = evaluation0.totalCost();
      assertEquals(0.0, double0, 0.01);
      
      LogitBoost logitBoost0 = new LogitBoost();
      double double1 = evaluation0.SFPriorEntropy();
      assertEquals(0.0, double1, 0.01);
  }

  /**
  //Test case number: 99
  /*Coverage entropy=2.4613286382413784
  */
  @Test(timeout = 4000)
  public void test099()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.setPriors(instances0);
      evaluation0.confusionMatrix();
      Evaluation evaluation1 = new Evaluation(instances0);
      evaluation0.totalCost();
      BayesNet bayesNet0 = new BayesNet();
      double double0 = evaluation1.unweightedMicroFmeasure();
      assertEquals(Double.NaN, double0, 0.01);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      double double1 = evaluation1.numTruePositives(26);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, double1, 0.01);
  }

  /**
  //Test case number: 100
  /*Coverage entropy=2.1864137057509496
  */
  @Test(timeout = 4000)
  public void test100()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      costSensitiveClassifier0.getCostMatrix();
      double double0 = evaluation0.rootMeanPriorSquaredError();
      double double1 = evaluation0.weightedRecall();
      assertEquals(double1, double0, 0.01);
      assertEquals(Double.NaN, double1, 0.01);
  }

  /**
  //Test case number: 101
  /*Coverage entropy=0.4918032786885246
  */
  @Test(timeout = 4000)
  public void test101()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      GainRatioAttributeEval gainRatioAttributeEval0 = new GainRatioAttributeEval();
      Capabilities capabilities0 = gainRatioAttributeEval0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.setNumNominal(111);
      FileSystemHandling.shouldAllThrowIOExceptions();
      Instances instances0 = testInstances0.generate("globalInfo");
      Evaluation evaluation0 = new Evaluation(instances0);
      Evaluation evaluation1 = new Evaluation(instances0);
      evaluation1.SFEntropyGain();
      double double0 = evaluation1.weightedMatthewsCorrelation();
      assertEquals(Double.NaN, double0, 0.01);
      
      evaluation0.meanPriorAbsoluteError();
      double double1 = evaluation0.priorEntropy();
      assertEquals(1.9899343783255765, double1, 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
  }

  /**
  //Test case number: 102
  /*Coverage entropy=1.9907867545761528
  */
  @Test(timeout = 4000)
  public void test102()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.meanPriorAbsoluteError();
      evaluation0.areaUnderROC(1594);
      try { 
        Evaluation.handleCostOption(" ", (-2));
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't open file null.
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 103
  /*Coverage entropy=0.45454545454545453
  */
  @Test(timeout = 4000)
  public void test103()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.SFMeanPriorEntropy();
      double[] doubleArray0 = new double[0];
      // Undeclared exception!
      try { 
        evaluation0.updateMargins(doubleArray0, 1, Double.NaN);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 1
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 104
  /*Coverage entropy=1.580093770149591
  */
  @Test(timeout = 4000)
  public void test104()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      Stacking stacking0 = new Stacking();
      Evaluation evaluation1 = new Evaluation(instances0);
      Evaluation evaluation2 = new Evaluation(instances0);
      double double0 = evaluation1.SFMeanSchemeEntropy();
      double double1 = evaluation2.totalCost();
      assertEquals(0.0, double1, 0.01);
      
      double double2 = evaluation0.weightedFalseNegativeRate();
      assertEquals(Double.NaN, double2, 0.01);
      
      double double3 = evaluation2.pctCorrect();
      assertEquals(double3, double0, 0.01);
      assertEquals(0.0, evaluation2.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, double3, 0.01);
  }

  /**
  //Test case number: 105
  /*Coverage entropy=2.7468865530774305
  */
  @Test(timeout = 4000)
  public void test105()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toCumulativeMarginDistributionString();
      assertEquals(" -1       0    \n", string0);
      
      double double0 = evaluation0.weightedMatthewsCorrelation();
      assertEquals(Double.NaN, double0, 0.01);
      
      evaluation0.numFalseNegatives(2382);
      MockRandom mockRandom0 = new MockRandom();
      evaluation0.SFMeanSchemeEntropy();
      evaluation0.getClassPriors();
      evaluation0.numTruePositives(16);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  /**
  //Test case number: 106
  /*Coverage entropy=1.5692005239622273
  */
  @Test(timeout = 4000)
  public void test106()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getStructure();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toSummaryString(".bsi", true);
      assertEquals(".bsi\nTotal Number of Instances                0     \n", string0);
      
      evaluation0.setNumericPriorsFromBuffer();
      double double0 = evaluation0.SFMeanEntropyGain();
      double double1 = evaluation0.pctIncorrect();
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(double1, double0, 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
  }

  /**
  //Test case number: 107
  /*Coverage entropy=0.45454545454545453
  */
  @Test(timeout = 4000)
  public void test107()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      Evaluation.handleCostOption("", (-2));
      double double0 = evaluation0.KBInformation();
      assertEquals(0.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  /**
  //Test case number: 108
  /*Coverage entropy=1.1840562714690361
  */
  @Test(timeout = 4000)
  public void test108()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("globalInfo");
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.SFEntropyGain();
      double double0 = evaluation0.unweightedMacroFmeasure();
      double double1 = evaluation0.weightedMatthewsCorrelation();
      assertEquals(Double.NaN, double1, 0.01);
      
      double double2 = evaluation0.KBRelativeInformation();
      assertEquals(0.0, double2, 0.01);
      
      double double3 = evaluation0.SFMeanSchemeEntropy();
      assertEquals(double3, double0, 0.01);
      
      double double4 = evaluation0.rootRelativeSquaredError();
      assertEquals(double4, double1, 0.01);
  }

  /**
  //Test case number: 109
  /*Coverage entropy=1.036019355145124
  */
  @Test(timeout = 4000)
  public void test109()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances1 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances1);
      evaluation0.setPriors(instances0);
      Evaluation evaluation1 = new Evaluation(instances1);
      double double0 = evaluation1.SFEntropyGain();
      assertEquals(0.0, double0, 0.01);
      
      PipedReader pipedReader0 = new PipedReader();
      Double double1 = new Double((-1));
      double double2 = evaluation1.trueNegativeRate(2);
      assertEquals(0.0, double2, 0.01);
      assertEquals(double2, double0, 0.01);
  }

  /**
  //Test case number: 110
  /*Coverage entropy=0.3333333333333333
  */
  @Test(timeout = 4000)
  public void test110()  throws Throwable  {
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      J48 j48_0 = new J48();
      try { 
        Evaluation.wekaStaticWrapper(j48_0, "*'YpB_");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.trees.J48", e);
      }
  }

  /**
  //Test case number: 111
  /*Coverage entropy=0.4
  */
  @Test(timeout = 4000)
  public void test111()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      TextDirectoryLoader textDirectoryLoader1 = new TextDirectoryLoader();
      double[] doubleArray0 = new double[5];
      NaiveBayes naiveBayes0 = new NaiveBayes();
      String string0 = Evaluation.getGlobalInfo(naiveBayes0);
      ZeroR zeroR0 = new ZeroR();
      String string1 = Evaluation.wekaStaticWrapper(zeroR0, "\nSynopsis for weka.classifiers.bayes.NaiveBayes:\n\nClass for a Naive Bayes classifier using estimator classes. Numeric estimator precision values are chosen based on analysis of the  training data. For this reason, the classifier is not an UpdateableClassifier (which in typical usage are initialized with zero training instances) -- if you need the UpdateableClassifier functionality, use the NaiveBayesUpdateable classifier. The NaiveBayesUpdateable classifier will  use a default precision of 0.1 for numeric attributes when buildClassifier is called with zero training instances.\n\nFor more information on Naive Bayes classifiers, see\n\nGeorge H. John, Pat Langley: Estimating Continuous Distributions in Bayesian Classifiers. In: Eleventh Conference on Uncertainty in Artificial Intelligence, San Mateo, 338-345, 1995.");
      assertFalse(string1.equals((Object)string0));
  }

  /**
  //Test case number: 112
  /*Coverage entropy=2.0894379124341005
  */
  @Test(timeout = 4000)
  public void test112()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.getRevision();
      assertEquals("9101", string0);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      double double0 = evaluation1.SFEntropyGain();
      assertEquals(0.0, double0, 0.01);
      
      String string1 = evaluation0.toSummaryString();
      assertEquals("\nTotal Number of Instances                0     \n", string1);
      
      boolean boolean0 = evaluation1.getDiscardPredictions();
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertFalse(boolean0);
  }

  /**
  //Test case number: 113
  /*Coverage entropy=2.8097401287699535
  */
  @Test(timeout = 4000)
  public void test113()  throws Throwable  {
      InfoGainAttributeEval infoGainAttributeEval0 = new InfoGainAttributeEval();
      Capabilities capabilities0 = new Capabilities(infoGainAttributeEval0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.setNumNominal(17);
      FileSystemHandling.shouldAllThrowIOExceptions();
      Instances instances0 = testInstances0.generate("getClass");
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.m_SumPriorAbsErr;
      evaluation0.weightedMatthewsCorrelation();
      evaluation0.numFalseNegatives(688);
      Attribute attribute0 = new Attribute("jpGay`!ofg", (-1));
      instances0.setClass(attribute0);
      evaluation0.trueNegativeRate((-3619));
      evaluation0.SFEntropyGain();
      evaluation0.unweightedMacroFmeasure();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      Evaluation evaluation1 = null;
      try {
        evaluation1 = new Evaluation(instances0, costMatrix0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Class index is negative (not set)!
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 114
  /*Coverage entropy=0.4615384615384615
  */
  @Test(timeout = 4000)
  public void test114()  throws Throwable  {
      String[] stringArray0 = new String[1];
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertEquals(0, doubleArray0.length);
      
      MockRandom mockRandom0 = new MockRandom();
      MockRandom mockRandom1 = new MockRandom(19);
      double double0 = evaluation0.SFMeanSchemeEntropy();
      double double1 = evaluation0.sizeOfPredictedRegions();
      assertEquals(double1, double0, 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
  }

  /**
  //Test case number: 115
  /*Coverage entropy=0.48000000000000004
  */
  @Test(timeout = 4000)
  public void test115()  throws Throwable  {
      String[] stringArray0 = new String[4];
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.weightedMatthewsCorrelation();
      Evaluation evaluation1 = new Evaluation(instances0);
      evaluation1.numFalseNegatives((-1189));
      Attribute attribute0 = new Attribute("-r\n", 1420);
      Attribute.main(stringArray0);
      instances0.setClass(attribute0);
      evaluation0.trueNegativeRate(83);
      evaluation1.SFEntropyGain();
      evaluation0.unweightedMacroFmeasure();
      Evaluation evaluation2 = null;
      try {
        evaluation2 = new Evaluation(instances0);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 1420, Size: 2
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  /**
  //Test case number: 116
  /*Coverage entropy=1.1546856420984069
  */
  @Test(timeout = 4000)
  public void test116()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertEquals(0, doubleArray0.length);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.pctUnclassified();
      assertEquals(Double.NaN, double1, 0.01);
  }

  /**
  //Test case number: 117
  /*Coverage entropy=0.4615384615384615
  */
  @Test(timeout = 4000)
  public void test117()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Evaluation.makeOptionString(naiveBayesMultinomialText0, true);
      LibSVMLoader libSVMLoader0 = new LibSVMLoader();
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      Stacking stacking0 = new Stacking();
      try { 
        evaluation0.evaluateModel((Classifier) stacking0, instances0, (Object[]) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 118
  /*Coverage entropy=2.537947798990979
  */
  @Test(timeout = 4000)
  public void test118()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      Stacking stacking0 = new Stacking();
      Classifier classifier0 = stacking0.getMetaClassifier();
      Evaluation.makeOptionString(classifier0, true);
      double double0 = evaluation0.matthewsCorrelationCoefficient((-950));
      assertEquals(0.0, double0, 0.01);
  }

  /**
  //Test case number: 119
  /*Coverage entropy=2.6753569677801448
  */
  @Test(timeout = 4000)
  public void test119()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.setPriors(instances0);
      evaluation0.confusionMatrix();
      Evaluation evaluation1 = new Evaluation(instances0);
      evaluation0.unweightedMacroFmeasure();
      evaluation0.weightedAreaUnderPRC();
      evaluation1.totalCost();
      Evaluation evaluation2 = new Evaluation(instances0);
      // Undeclared exception!
      try { 
        evaluation0.truePositiveRate((-2));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -2
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 120
  /*Coverage entropy=0.4827586206896552
  */
  @Test(timeout = 4000)
  public void test120()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.confusionMatrix();
      Evaluation evaluation1 = new Evaluation(instances0);
      double double0 = evaluation1.falsePositiveRate((-2));
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.unweightedMacroFmeasure();
      assertNotEquals(double1, double0, 0.01);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      double double2 = evaluation1.areaUnderPRC((-1));
      assertEquals(double2, double1, 0.01);
  }

  /**
  //Test case number: 121
  /*Coverage entropy=2.1474346503786346
  */
  @Test(timeout = 4000)
  public void test121()  throws Throwable  {
      MultilayerPerceptron multilayerPerceptron0 = new MultilayerPerceptron();
      multilayerPerceptron0.setTrainingTime(18);
      Capabilities capabilities0 = new Capabilities(multilayerPerceptron0);
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.meanPriorAbsoluteError();
      assertEquals(Double.NaN, double0, 0.01);
      
      evaluation0.areaUnderROC((-1));
      String string0 = evaluation0.getRevision();
      assertEquals("9101", string0);
      
      double double1 = evaluation0.m_SumErr;
      double double2 = evaluation0.numFalseNegatives(656);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, double2, 0.01);
  }

  /**
  //Test case number: 122
  /*Coverage entropy=1.1693376567504215
  */
  @Test(timeout = 4000)
  public void test122()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toCumulativeMarginDistributionString();
      assertEquals(" -1       0    \n", string0);
      
      double double0 = evaluation0.kappa();
      assertEquals(1.0, double0, 0.01);
      
      double double1 = evaluation0.weightedTrueNegativeRate();
      assertEquals(Double.NaN, double1, 0.01);
      
      evaluation0.trueNegativeRate((-2));
      evaluation0.pctIncorrect();
      double double2 = evaluation0.m_TotalCoverage;
      assertNotEquals(double2, double0, 0.01);
  }

  /**
  //Test case number: 123
  /*Coverage entropy=1.595849857728883
  */
  @Test(timeout = 4000)
  public void test123()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.rootMeanPriorSquaredError();
      String string0 = evaluation0.toClassDetailsString("@relation");
      assertEquals("@relation\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\n                 0        0        0          0       0          0     ?         ?         class1\n                 0        0        0          0       0          0     ?         ?         class2\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
      
      testInstances0.listOptions();
      evaluation0.SFMeanSchemeEntropy();
      evaluation0.weightedTrueNegativeRate();
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
  }

  /**
  //Test case number: 124
  /*Coverage entropy=1.1476926351053998
  */
  @Test(timeout = 4000)
  public void test124()  throws Throwable  {
      String[] stringArray0 = new String[4];
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.confusionMatrix();
      MockRandom mockRandom0 = new MockRandom();
      MockRandom mockRandom1 = new MockRandom(19);
      try { 
        evaluation0.crossValidateModel(".arff", instances0, 19, stringArray0, (Random) mockRandom1);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class called: .arff
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 125
  /*Coverage entropy=0.4444444444444445
  */
  @Test(timeout = 4000)
  public void test125()  throws Throwable  {
      DatabaseLoader databaseLoader0 = new DatabaseLoader();
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.setDiscardPredictions(true);
      assertTrue(evaluation0.getDiscardPredictions());
  }

  /**
  //Test case number: 126
  /*Coverage entropy=0.3333333333333333
  */
  @Test(timeout = 4000)
  public void test126()  throws Throwable  {
      Cobweb cobweb0 = new Cobweb();
      Capabilities capabilities0 = cobweb0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("#5t3j9h7Lp{9pW");
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation(instances0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Class index is negative (not set)!
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 127
  /*Coverage entropy=1.765976792018692
  */
  @Test(timeout = 4000)
  public void test127()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      Instances instances0 = testInstances1.generate((String) null);
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.rootMeanPriorSquaredError();
      try { 
        Evaluation.evaluateModel("@relation", testInstances0.DEFAULT_WORDS);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class with name @relation.
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 128
  /*Coverage entropy=0.4666666666666667
  */
  @Test(timeout = 4000)
  public void test128()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      Stacking stacking0 = new Stacking();
      J48 j48_0 = new J48();
      Evaluation evaluation1 = new Evaluation(instances0);
      Stacking stacking1 = new Stacking();
      Stacking stacking2 = new Stacking();
      stacking2.getMetaClassifier();
      String string0 = Evaluation.makeOptionString(j48_0, false);
      assertNotNull(string0);
  }

  /**
  //Test case number: 129
  /*Coverage entropy=0.4444444444444445
  */
  @Test(timeout = 4000)
  public void test129()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getStructure();
      Evaluation evaluation0 = new Evaluation(instances0);
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Object[] objectArray0 = new Object[2];
      objectArray0[0] = (Object) evaluation0;
      objectArray0[1] = (Object) simpleLinearRegression0;
      try { 
        evaluation0.evaluateModel((Classifier) simpleLinearRegression0, instances0, objectArray0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // weka.classifiers.Evaluation cannot be cast to weka.classifiers.evaluation.output.prediction.AbstractOutput
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 130
  /*Coverage entropy=0.3333333333333333
  */
  @Test(timeout = 4000)
  public void test130()  throws Throwable  {
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[4] = "v`~S{i>WP,vtn#";
      try { 
        Evaluation.evaluateModel((Classifier) serializedClassifier0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 131
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test131()  throws Throwable  {
      Evaluation.handleCostOption("", 3026);
      BayesNet bayesNet0 = new BayesNet();
      Instances instances0 = bayesNet0.m_Instances;
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 132
  /*Coverage entropy=0.3333333333333333
  */
  @Test(timeout = 4000)
  public void test132()  throws Throwable  {
      CostMatrix costMatrix0 = new CostMatrix(0);
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation((Instances) null, costMatrix0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 133
  /*Coverage entropy=0.4
  */
  @Test(timeout = 4000)
  public void test133()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "thence";
      stringArray0[1] = "\tThe directory to work on.\n\t(default: current directory)";
      stringArray0[2] = "=== Confusion Matrix ===\n";
      stringArray0[3] = "";
      try { 
        Evaluation.evaluateModel((Classifier) null, stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // 
         // Weka exception: No training file and no object input file given.
         // 
         // General options:
         // 
         // -h or -help
         // \tOutput help information.
         // -synopsis or -info
         // \tOutput synopsis for classifier (use in conjunction  with -h)
         // -t <name of training file>
         // \tSets training file.
         // -T <name of test file>
         // \tSets test file. If missing, a cross-validation will be performed
         // \ton the training data.
         // -c <class index>
         // \tSets index of class attribute (default: last).
         // -x <number of folds>
         // \tSets number of folds for cross-validation (default: 10).
         // -no-cv
         // \tDo not perform any cross validation.
         // -split-percentage <percentage>
         // \tSets the percentage for the train/test set split, e.g., 66.
         // -preserve-order
         // \tPreserves the order in the percentage split.
         // -s <random number seed>
         // \tSets random number seed for cross-validation or percentage split
         // \t(default: 1).
         // -m <name of file with cost matrix>
         // \tSets file with cost matrix.
         // -l <name of input file>
         // \tSets model input file. In case the filename ends with '.xml',
         // \ta PMML file is loaded or, if that fails, options are loaded
         // \tfrom the XML file.
         // -d <name of output file>
         // \tSets model output file. In case the filename ends with '.xml',
         // \tonly the options are saved to the XML file, not the model.
         // -v
         // \tOutputs no statistics for training data.
         // -o
         // \tOutputs statistics only, not the classifier.
         // -i
         // \tOutputs detailed information-retrieval statistics for each class.
         // -k
         // \tOutputs information-theoretic statistics.
         // -classifications \"weka.classifiers.evaluation.output.prediction.AbstractOutput + options\"
         // \tUses the specified class for generating the classification output.
         // \tE.g.: weka.classifiers.evaluation.output.prediction.PlainText
         // -p range
         // \tOutputs predictions for test instances (or the train instances if
         // \tno test instances provided and -no-cv is used), along with the 
         // \tattributes in the specified range (and nothing else). 
         // \tUse '-p 0' if no attributes are desired.
         // \tDeprecated: use \"-classifications ...\" instead.
         // -distribution
         // \tOutputs the distribution instead of only the prediction
         // \tin conjunction with the '-p' option (only nominal classes).
         // \tDeprecated: use \"-classifications ...\" instead.
         // -r
         // \tOnly outputs cumulative margin distribution.
         // -xml filename | xml-string
         // \tRetrieves the options from the XML-data instead of the command line.
         // -threshold-file <file>
         // \tThe file to save the threshold data to.
         // \tThe format is determined by the extensions, e.g., '.arff' for ARFF 
         // \tformat or '.csv' for CSV.
         // -threshold-label <label>
         // \tThe class label to determine the threshold data for
         // \t(default is the first label)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 134
  /*Coverage entropy=0.4615384615384615
  */
  @Test(timeout = 4000)
  public void test134()  throws Throwable  {
      String[] stringArray0 = new String[1];
      Evaluation.main(stringArray0);
      Bagging bagging0 = new Bagging();
      bagging0.setSeed(15);
      Evaluation.makeOptionString(bagging0, true);
      LibSVMLoader libSVMLoader0 = new LibSVMLoader();
      try { 
        Evaluation.evaluateModel((Classifier) bagging0, stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // 
         // Weka exception: No training file and no object input file given.
         // 
         // General options:
         // 
         // -h or -help
         // \tOutput help information.
         // -synopsis or -info
         // \tOutput synopsis for classifier (use in conjunction  with -h)
         // -t <name of training file>
         // \tSets training file.
         // -T <name of test file>
         // \tSets test file. If missing, a cross-validation will be performed
         // \ton the training data.
         // -c <class index>
         // \tSets index of class attribute (default: last).
         // -x <number of folds>
         // \tSets number of folds for cross-validation (default: 10).
         // -no-cv
         // \tDo not perform any cross validation.
         // -split-percentage <percentage>
         // \tSets the percentage for the train/test set split, e.g., 66.
         // -preserve-order
         // \tPreserves the order in the percentage split.
         // -s <random number seed>
         // \tSets random number seed for cross-validation or percentage split
         // \t(default: 1).
         // -m <name of file with cost matrix>
         // \tSets file with cost matrix.
         // -l <name of input file>
         // \tSets model input file. In case the filename ends with '.xml',
         // \ta PMML file is loaded or, if that fails, options are loaded
         // \tfrom the XML file.
         // -d <name of output file>
         // \tSets model output file. In case the filename ends with '.xml',
         // \tonly the options are saved to the XML file, not the model.
         // -v
         // \tOutputs no statistics for training data.
         // -o
         // \tOutputs statistics only, not the classifier.
         // -i
         // \tOutputs detailed information-retrieval statistics for each class.
         // -k
         // \tOutputs information-theoretic statistics.
         // -classifications \"weka.classifiers.evaluation.output.prediction.AbstractOutput + options\"
         // \tUses the specified class for generating the classification output.
         // \tE.g.: weka.classifiers.evaluation.output.prediction.PlainText
         // -p range
         // \tOutputs predictions for test instances (or the train instances if
         // \tno test instances provided and -no-cv is used), along with the 
         // \tattributes in the specified range (and nothing else). 
         // \tUse '-p 0' if no attributes are desired.
         // \tDeprecated: use \"-classifications ...\" instead.
         // -distribution
         // \tOutputs the distribution instead of only the prediction
         // \tin conjunction with the '-p' option (only nominal classes).
         // \tDeprecated: use \"-classifications ...\" instead.
         // -r
         // \tOnly outputs cumulative margin distribution.
         // -xml filename | xml-string
         // \tRetrieves the options from the XML-data instead of the command line.
         // -threshold-file <file>
         // \tThe file to save the threshold data to.
         // \tThe format is determined by the extensions, e.g., '.arff' for ARFF 
         // \tformat or '.csv' for CSV.
         // -threshold-label <label>
         // \tThe class label to determine the threshold data for
         // \t(default is the first label)
         // 
         // Options specific to weka.classifiers.meta.Bagging:
         // 
         // -P
         // \tSize of each bag, as a percentage of the
         // \ttraining set size. (default 100)
         // -O
         // \tCalculate the out of bag error.
         // -S <num>
         // \tRandom number seed.
         // \t(default 1)
         // -num-slots <num>
         // \tNumber of execution slots.
         // \t(default 1 - i.e. no parallelism)
         // -I <num>
         // \tNumber of iterations.
         // \t(default 10)
         // -D
         // \tIf set, classifier is run in debug mode and
         // \tmay output additional info to the console
         // -W
         // \tFull name of base classifier.
         // \t(default: weka.classifiers.trees.REPTree)
         // 
         // Options specific to classifier weka.classifiers.trees.REPTree:
         // 
         // -M <minimum number of instances>
         // \tSet minimum number of instances per leaf (default 2).
         // -V <minimum variance for split>
         // \tSet minimum numeric class variance proportion
         // \tof train variance for split (default 1e-3).
         // -N <number of folds>
         // \tNumber of folds for reduced error pruning (default 3).
         // -S <seed>
         // \tSeed for random data shuffling (default 1).
         // -P
         // \tNo pruning.
         // -L
         // \tMaximum tree depth (default -1, no maximum)
         // -I
         // \tInitial class value count (default 0)
         // -R
         // \tSpread initial count over all class values (i.e. don't use 1 per value)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 135
  /*Coverage entropy=0.42857142857142855
  */
  @Test(timeout = 4000)
  public void test135()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      DecisionStump decisionStump0 = new DecisionStump();
      String[] stringArray0 = new String[0];
      DecisionStump.main(stringArray0);
      try { 
        Evaluation.wekaStaticWrapper(decisionStump0, "setDecay");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.trees.DecisionStump", e);
      }
  }

  /**
  //Test case number: 136
  /*Coverage entropy=0.3333333333333333
  */
  @Test(timeout = 4000)
  public void test136()  throws Throwable  {
      String[] stringArray0 = new String[0];
      Evaluation.main(stringArray0);
      LibSVMLoader libSVMLoader0 = new LibSVMLoader();
      assertFalse(libSVMLoader0.getUseRelativePath());
  }
}
