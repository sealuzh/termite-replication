/*
 * This file was automatically generated by EvoSuite
 * Sat Nov 16 06:32:49 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.net.URI;
import java.util.AbstractMap;
import java.util.ArrayList;
import java.util.Comparator;
import java.util.Locale;
import java.util.Map;
import java.util.function.UnaryOperator;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.net.MockURI;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.rules.ZeroR;
import weka.core.AllJavadoc;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.ChebyshevDistance;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.OptionHandlerJavadoc;
import weka.core.SparseInstance;
import weka.core.TechnicalInformationHandlerJavadoc;
import weka.core.TestInstances;
import weka.core.stemmers.IteratedLovinsStemmer;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.AlphabeticTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.9129799669787033
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.debugTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("If set to true, classifier may output additional info to the console.");
      naiveBayesMultinomialText0.setPeriodicPruning(10000);
      NullStemmer nullStemmer0 = new NullStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) nullStemmer0;
      naiveBayesMultinomialText0.buildClassifier(instances0);
      Capabilities.forInstances(instances0, true);
      TestInstances.main(testInstances0.DEFAULT_WORDS);
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      testInstances0.setNumRelationalDate(10000);
      naiveBayesMultinomialText0.normTipText();
      TestInstances testInstances1 = new TestInstances();
      testInstances1.setRelationalClassFormat(instances0);
      testInstances1.setSeed(455);
      testInstances1.setNumNominalValues(968);
      testInstances0.setNumRelationalDate((-1));
      testInstances1.setNoClass(false);
      TestInstances testInstances2 = new TestInstances();
      testInstances1.setNumInstancesRelational(10000);
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      String string1 = naiveBayesMultinomialText0.toString();
      assertEquals("The independent probability of a class\n--------------------------------------\nclass1\t12.0\nclass2\t10.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\t\n", string1);
      
      String string2 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string2);
      
      String string3 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string3);
      
      naiveBayesMultinomialText0.LNormTipText();
      String string4 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string4);
      
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      String string5 = naiveBayesMultinomialText0.stemmerTipText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", string5);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 1
  /*Coverage entropy=3.303580233610724
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("If true then document length is normalized according to the settings for norm and lnorm");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      Capabilities.forInstances(instances0, true);
      testInstances0.setSeed(10000);
      naiveBayesMultinomialText0.setUseStopList(true);
      double double0 = naiveBayesMultinomialText0.m_t;
      naiveBayesMultinomialText0.getStemmer();
      NullStemmer.main(testInstances0.DEFAULT_WORDS);
      Capabilities.forInstances(instances0);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.toString();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (double) (-1);
      int[] intArray0 = new int[10];
      naiveBayesMultinomialText0.buildClassifier(instances0);
      intArray0[6] = (-2);
      intArray0[2] = (-2);
      intArray0[3] = (-2);
      intArray0[4] = (-1);
      naiveBayesMultinomialText0.getOptions();
      intArray0[5] = 10000;
      SparseInstance sparseInstance0 = new SparseInstance((-1.0), doubleArray0, intArray0, (-2));
      naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.6709087878625355
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, (String) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.getRevision();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.globalInfo();
      Random.setNextRandom(33);
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.listOptions();
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 3
  /*Coverage entropy=2.226865198671571
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("");
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (double) (-1);
      doubleArray0[2] = (-486.0);
      doubleArray0[3] = (double) (-2);
      DenseInstance denseInstance0 = new DenseInstance((-1), doubleArray0);
      instances0.add((Instance) denseInstance0);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=3.0436506099620244
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.m_periodicP = 7;
      naiveBayesMultinomialText0.getOptions();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      System.setCurrentTimeMillis(721L);
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.getPeriodicPruning();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      assertEquals("Transform through the PC space and back to the original space. If only the best n PCs are retained (by setting varianceCovered < 1) then this option will give a dataset in the original space but with less attribute noise.", principalComponents0.transformBackToOriginalTipText());
  }

  /**
  //Test case number: 5
  /*Coverage entropy=3.303235159138467
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("");
      UnaryOperator<Instance> unaryOperator0 = UnaryOperator.identity();
      instances0.replaceAll(unaryOperator0);
      TestInstances testInstances1 = new TestInstances();
      Instances instances1 = testInstances0.generate(".bsi");
      TestInstances testInstances2 = new TestInstances();
      naiveBayesMultinomialText0.m_leplace = (double) (-1);
      testInstances0.setNumNominalValues((-1));
      testInstances1.setNumNominal(11);
      testInstances1.getWords();
      testInstances1.setNumRelationalString((-1));
      testInstances2.setSeed(16);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.normTipText();
      testInstances2.setRelationalClassFormat(instances1);
      testInstances2.setNumNominalValues((-1));
      testInstances1.setNumRelationalDate((-1406));
      testInstances1.setNoClass(false);
      TestInstances testInstances3 = new TestInstances();
      testInstances1.setNumInstancesRelational((-2161));
      naiveBayesMultinomialText0.useStopListTipText();
      SystemInUtil.addInputLine("a.7t>U$gL4#206");
      String string1 = naiveBayesMultinomialText0.toString();
      assertEquals("The independent probability of a class\n--------------------------------------\nclass1\t12.0\nclass2\t10.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\t\n", string1);
      
      String string2 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string2);
      
      Random.setNextRandom((-1));
      String string3 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string3);
      
      naiveBayesMultinomialText0.LNormTipText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray0.length);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 6
  /*Coverage entropy=3.076787870678774
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("If true then document length is normalized according to the settings for norm and lnorm");
      UnaryOperator<Instance> unaryOperator0 = UnaryOperator.identity();
      instances0.replaceAll(unaryOperator0);
      TestInstances testInstances1 = new TestInstances();
      Instances instances1 = testInstances0.generate(".bsi");
      TestInstances testInstances2 = new TestInstances();
      testInstances0.setMultiInstance(false);
      testInstances1.setNumInstances((-2));
      testInstances1.setNumNominal(11);
      testInstances1.getWords();
      testInstances1.setNumRelationalString((-2));
      testInstances2.setSeed((-1));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      testInstances0.setNumRelationalDate((-1));
      naiveBayesMultinomialText0.normTipText();
      testInstances2.setRelationalClassFormat(instances1);
      testInstances2.setNumNominalValues((-1));
      testInstances2.setNumRelationalDate((-994));
      testInstances2.setNoClass(true);
      TestInstances testInstances3 = new TestInstances();
      testInstances0.setNumInstancesRelational((-1));
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.tokenizerTipText();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setOptions(testInstances1.DEFAULT_WORDS);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 7
  /*Coverage entropy=2.531883773730881
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      double double0 = naiveBayesMultinomialText0.m_t;
      NullStemmer.main(testInstances0.DEFAULT_WORDS);
      naiveBayesMultinomialText0.stemmerTipText();
      instances0.setClassIndex((-1));
      naiveBayesMultinomialText0.setLNorm((-1));
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      double[] doubleArray0 = new double[1];
      int[] intArray0 = new int[6];
      testInstances0.setNumRelational(4083);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Class attribute not set!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=3.2812767177431468
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      System.setCurrentTimeMillis(0L);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, (String) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.getTechnicalInformation();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      naiveBayesMultinomialText0.setLNorm(0L);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "");
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.getLNorm();
      SystemInUtil.addInputLine("9122");
      naiveBayesMultinomialText0.globalInfo();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "9122");
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.getStopwords();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "9122";
      stringArray0[1] = "9122";
      stringArray0[2] = "";
      stringArray0[3] = "9122";
      stringArray0[4] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[5] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setMinWordFrequency(605.0);
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      Random.setNextRandom(1517);
  }

  /**
  //Test case number: 9
  /*Coverage entropy=3.270421379850272
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("");
      instances0.deleteAttributeType((-2676));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      Capabilities.forInstances(instances0, false);
      naiveBayesMultinomialText0.setUseStopList(false);
      double double0 = naiveBayesMultinomialText0.m_t;
      naiveBayesMultinomialText0.getStemmer();
      double double1 = naiveBayesMultinomialText0.m_norm;
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.setLNorm((-1));
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      testInstances0.getRevision();
      naiveBayesMultinomialText0.stopwordsTipText();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = 1152.3623069784;
      int[] intArray0 = new int[6];
      intArray0[4] = (-2);
      intArray0[2] = (-2);
      intArray0[3] = 0;
      intArray0[4] = (-1);
      intArray0[5] = 68;
      SparseInstance sparseInstance0 = new SparseInstance(1152.3623069784, doubleArray0, intArray0, 0);
      SparseInstance sparseInstance1 = new SparseInstance(9.223372036854776E18, doubleArray0);
      naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
      naiveBayesMultinomialText0.setOptions(testInstances0.DEFAULT_WORDS);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      Random.setNextRandom((-2));
      System.setCurrentTimeMillis(0);
      double double2 = naiveBayesMultinomialText0.getLNorm();
      assertEquals((-1.0), double2, 0.01);
  }

  /**
  //Test case number: 10
  /*Coverage entropy=3.0449799552594654
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[12];
      doubleArray0[0] = 3578.7;
      naiveBayesMultinomialText0.getOptions();
      doubleArray0[1] = 2437.025024;
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.m_stemmer = null;
      naiveBayesMultinomialText0.m_leplace = 0.0;
      naiveBayesMultinomialText0.setNorm(0.0);
      naiveBayesMultinomialText0.m_lnorm = 0.0;
      naiveBayesMultinomialText0.setMinWordFrequency((-1564.2417548737));
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      boolean boolean0 = naiveBayesMultinomialText0.m_useStopList;
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.m_stemmer = null;
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      MockFile.createTempFile(" inst#     actual  predicted error prediction", " inst#     actual  predicted error prediction");
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.LNormTipText();
      assertEquals((-1564.2417548737), naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 11
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizerTipText();
      TestInstances testInstances0 = new TestInstances();
      naiveBayesMultinomialText0.setUseStopList(true);
      TestInstances testInstances1 = new TestInstances();
      TestInstances testInstances2 = new TestInstances();
      testInstances2.setSeed(16);
      testInstances2.generate("&ivn.##Us;\"#xZ1");
      naiveBayesMultinomialText0.normTipText();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) (-2);
      testInstances2.setNumNominalValues((-1));
      doubleArray0[1] = (double) (-2);
      doubleArray0[2] = 4.0;
      doubleArray0[3] = (double) (-1);
      testInstances2.setNumInstancesRelational((-1));
      testInstances0.setWordSeparators("-M <double>");
      doubleArray0[4] = (double) (-2);
      doubleArray0[5] = (double) (-1);
      doubleArray0[6] = (double) (-2);
      doubleArray0[7] = (double) (-1);
      testInstances1.setNumInstancesRelational((-1));
      doubleArray0[8] = (double) (-2);
      SparseInstance sparseInstance0 = new SparseInstance((-1), doubleArray0);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      boolean boolean0 = naiveBayesMultinomialText0.getUseStopList();
      assertTrue(boolean0);
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances((String) null, arrayList0, 0);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: No attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=2.9803943038548706
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      String[] stringArray0 = new String[7];
      File file0 = MockFile.createTempFile("-norm <num>", "-norm <num>");
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getOptions();
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=2.2268974827716517
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("");
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (double) (-1);
      doubleArray0[2] = (double) (-1);
      doubleArray0[3] = (double) (-1);
      doubleArray0[4] = 0.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-2), doubleArray0);
      instances0.add((Instance) binarySparseInstance0);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 2, Size: 2
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  /**
  //Test case number: 15
  /*Coverage entropy=2.84723313421923
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      UnaryOperator<Instance> unaryOperator0 = UnaryOperator.identity();
      instances0.replaceAll(unaryOperator0);
      TestInstances testInstances1 = new TestInstances();
      testInstances0.generate(".bsi");
      TestInstances testInstances2 = new TestInstances();
      testInstances0.setNumNominalValues((-1));
      TestInstances testInstances3 = new TestInstances();
      testInstances2.setNumNominalValues((-3025));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      testInstances0.setNumNominal((-1));
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      
      naiveBayesMultinomialText0.m_data = instances0;
      testInstances2.setRelationalClassFormat(instances0);
      testInstances0.getWords();
      testInstances1.setNumNominalValues((-2));
      testInstances1.setNoClass(false);
      TestInstances testInstances4 = new TestInstances();
      testInstances4.setNumInstances((-2));
      testInstances4.setNumInstancesRelational((-1));
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      Random.setNextRandom((-2));
      Random.setNextRandom((-2161));
      naiveBayesMultinomialText0.useStopListTipText();
      String string1 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string1);
      
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      double[] doubleArray0 = new double[0];
      testInstances0.getWords();
      DenseInstance denseInstance0 = new DenseInstance(2779.5922724, doubleArray0);
      double[] doubleArray1 = naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
      assertArrayEquals(new double[] {0.5454545454545454, 0.4545454545454546}, doubleArray1, 0.01);
      
      naiveBayesMultinomialText0.stemmerTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 16
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      ZeroR zeroR0 = new ZeroR();
      Capabilities capabilities0 = zeroR0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText1.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Cannot handle relational attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 17
  /*Coverage entropy=3.1842732800005193
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      double double0 = naiveBayesMultinomialText0.m_t;
      NullStemmer.main(testInstances0.DEFAULT_WORDS);
      naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      naiveBayesMultinomialText0.setLNorm((-1));
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      double[] doubleArray0 = new double[1];
      int[] intArray0 = new int[6];
      testInstances0.setNumRelational(4083);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      intArray0[4] = (-2);
      intArray0[2] = (-2);
      intArray0[3] = (-2);
      intArray0[4] = (-1);
      intArray0[5] = 68;
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0, intArray0, (-2));
      SparseInstance sparseInstance1 = new SparseInstance((-2), doubleArray0);
      naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
      naiveBayesMultinomialText0.setOptions(testInstances0.DEFAULT_WORDS);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.m_stemmer = null;
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      naiveBayesMultinomialText0.setOptions(testInstances0.DEFAULT_WORDS);
      naiveBayesMultinomialText0.setOptions(testInstances0.DEFAULT_WORDS);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.242212190971484
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "If true then document length is normalized according to the settings for norm and lnorm");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.createFolder(evoSuiteFile1);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "-tokenizer";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No value given for -tokenizer option.
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=2.3359085195270404
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("");
      UnaryOperator<Instance> unaryOperator0 = UnaryOperator.identity();
      instances0.replaceAll(unaryOperator0);
      naiveBayesMultinomialText0.setPeriodicPruning((-1));
      TestInstances testInstances1 = new TestInstances();
      testInstances1.setOptions(testInstances0.DEFAULT_WORDS);
      Instances instances1 = testInstances0.generate(".bsi");
      TestInstances testInstances2 = new TestInstances();
      testInstances0.setNumNominalValues((-1));
      TestInstances testInstances3 = new TestInstances();
      testInstances2.setNumNominalValues((-3025));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      ChebyshevDistance chebyshevDistance0 = new ChebyshevDistance();
      chebyshevDistance0.initializeRanges();
      OptionHandlerJavadoc optionHandlerJavadoc0 = new OptionHandlerJavadoc();
      ChebyshevDistance chebyshevDistance1 = new ChebyshevDistance();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      AbstractMap.SimpleEntry<ChebyshevDistance, Object> abstractMap_SimpleEntry0 = new AbstractMap.SimpleEntry<ChebyshevDistance, Object>(chebyshevDistance1, instances1);
      // Undeclared exception!
      try { 
        Map.Entry.comparingByKey((Comparator<? super TechnicalInformationHandlerJavadoc>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.Objects", e);
      }
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.84723313421923
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string0);
      
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      UnaryOperator<Instance> unaryOperator0 = UnaryOperator.identity();
      instances0.replaceAll(unaryOperator0);
      TestInstances testInstances1 = new TestInstances();
      testInstances0.generate(".bsi");
      TestInstances testInstances2 = new TestInstances();
      testInstances0.setNumNominalValues((-1));
      TestInstances testInstances3 = new TestInstances();
      testInstances2.generate(".bsi");
      testInstances2.setNumNominalValues((-3025));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      testInstances0.setNumNominal((-1));
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.m_data = instances0;
      testInstances2.setRelationalClassFormat(instances0);
      testInstances0.getWords();
      testInstances1.setNumNominalValues((-2));
      testInstances1.setNoClass(false);
      TestInstances testInstances4 = new TestInstances();
      testInstances4.setNumInstances((-2));
      testInstances4.setNumInstancesRelational((-1));
      String string1 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      
      Random.setNextRandom((-2));
      Random.setNextRandom((-2161));
      naiveBayesMultinomialText0.useStopListTipText();
      String string2 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string2);
      
      String string3 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string3);
      
      String string4 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string4);
      
      double[] doubleArray0 = new double[0];
      testInstances0.getWords();
      DenseInstance denseInstance0 = new DenseInstance((-1), doubleArray0);
      double[] doubleArray1 = naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
      assertArrayEquals(new double[] {0.5454545454545454, 0.4545454545454546}, doubleArray1, 0.01);
      
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, false);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.6868977693384444
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      byte[] byteArray0 = new byte[4];
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "If true then document length is normalized according to the settings for norm and lnorm");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      String[] stringArray0 = precomputedKernelMatrixKernel0.getOptions();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile1);
      FileSystemHandling.createFolder(evoSuiteFile0);
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      TestInstances testInstances0 = new TestInstances();
      int int0 = (-1);
      testInstances0.setNumNominalValues((-1));
      Instances instances0 = null;
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 23
  /*Coverage entropy=2.764295407969964
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.debugTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("If set to true, classifier may output additional info to the console.");
      UnaryOperator<Instance> unaryOperator0 = UnaryOperator.identity();
      instances0.replaceAll(unaryOperator0);
      TestInstances testInstances1 = new TestInstances();
      Instances instances1 = testInstances0.generate(".bsi");
      TestInstances testInstances2 = new TestInstances();
      testInstances0.setMultiInstance(false);
      testInstances1.setNumInstances((-2));
      testInstances1.setNumNominal((-1));
      testInstances1.getWords();
      testInstances1.setNumRelationalString((-2));
      testInstances2.setSeed((-1));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      testInstances0.setNumRelationalDate((-1));
      naiveBayesMultinomialText0.normTipText();
      testInstances2.setRelationalClassFormat(instances1);
      testInstances2.setNumNominalValues((-1));
      testInstances2.setNumRelationalDate((-994));
      testInstances2.setNoClass(true);
      TestInstances testInstances3 = new TestInstances();
      testInstances0.setNumInstancesRelational((-1));
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 24
  /*Coverage entropy=3.529790556794326
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      FileSystemHandling.shouldAllThrowIOExceptions();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(12, stringArray0.length);
      
      naiveBayesMultinomialText0.reset();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      
      String string1 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string1);
      
      URI uRI0 = MockURI.aFileURI;
      MockFile mockFile0 = new MockFile(uRI0);
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.reset();
      String[] stringArray1 = new String[1];
      stringArray1[0] = "The tokenizing algorithm to use on the strings.";
      naiveBayesMultinomialText2.setOptions(stringArray1);
      assertFalse(naiveBayesMultinomialText2.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText2.getUseStopList());
      assertFalse(naiveBayesMultinomialText2.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText2.getLowercaseTokens());
      
      double double0 = naiveBayesMultinomialText0.m_lnorm;
      naiveBayesMultinomialText1.getStemmer();
      Tokenizer tokenizer0 = naiveBayesMultinomialText1.getTokenizer();
      naiveBayesMultinomialText1.setTokenizer(tokenizer0);
      String string2 = naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string2);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertTrue(file0.isFile());
      
      NaiveBayesMultinomialText naiveBayesMultinomialText4 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText3.normTipText();
      String string3 = naiveBayesMultinomialText4.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string3);
      
      naiveBayesMultinomialText4.normalizeDocLengthTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText5 = new NaiveBayesMultinomialText();
      String string4 = naiveBayesMultinomialText5.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string4);
      
      String string5 = naiveBayesMultinomialText3.minWordFrequencyTipText();
      assertEquals(2.0, naiveBayesMultinomialText3.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText3.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText3.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText3.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string5);
  }

  /**
  //Test case number: 25
  /*Coverage entropy=2.649669942596342
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.createFolder(evoSuiteFile0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.getOptions();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "user.dir");
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      FileSystemHandling.createFolder(evoSuiteFile0);
      AllJavadoc allJavadoc0 = null;
      try {
        allJavadoc0 = new AllJavadoc();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=3.2698986887396755
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "If true then document length is normalized according to the settings for norm and lnorm");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      naiveBayesMultinomialText0.setNorm(0.0);
      assertEquals(0.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile1);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 27
  /*Coverage entropy=3.583207772928188
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_wordsPerClass = null;
      double[] doubleArray0 = new double[4];
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      doubleArray0[0] = 2470.19;
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.m_norm = (-1264.0);
      doubleArray0[1] = 1.0E10;
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("If true then document length is normalized according to the settings for norm and lnorm");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      doubleArray0[3] = (-347.85368339678695);
      int[] intArray0 = new int[8];
      intArray0[0] = (-1);
      intArray0[1] = (-1);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.setLNorm(1.0E10);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.toString();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 28
  /*Coverage entropy=3.108834409086613
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      naiveBayesMultinomialText0.getOptions();
      doubleArray0[0] = 2470.19;
      naiveBayesMultinomialText0.m_norm = (-1264.0);
      doubleArray0[1] = 1.0E10;
      doubleArray0[2] = (-861.0);
      doubleArray0[3] = (-347.85368339678695);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.getLNorm();
      Stemmer stemmer0 = naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.setStemmer(stemmer0);
      naiveBayesMultinomialText0.m_stemmer = stemmer0;
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.setLNorm(1.0E10);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.toString();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=2.188947438429127
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.m_minWordP = 586.400877568;
      String[] stringArray0 = new String[7];
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, false, true, false);
      stringArray0[0] = "eKhDKk{/NRQ~3|";
      stringArray0[1] = "";
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile1);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      String[] stringArray1 = new String[9];
      stringArray1[0] = "-tokenizer";
      stringArray1[1] = "-tokenizer";
      stringArray1[2] = "";
      stringArray1[3] = "eKhDKk{/NRQ~3|";
      stringArray1[4] = "";
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      stringArray1[5] = "eKhDKk{/NRQ~3|";
      stringArray1[6] = "-tokenizer";
      stringArray1[7] = "eKhDKk{/NRQ~3|";
      stringArray1[8] = "";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray1);
        fail("Expecting exception: ClassNotFoundException");
      
      } catch(ClassNotFoundException e) {
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=2.4287877436062972
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setStopwords((File) null);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.setDebug(false);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.getKernelMatrixFile();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-W";
      stringArray0[1] = "& _w3`_;Qhz";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 31
  /*Coverage entropy=3.2944630434120015
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.listOptions();
      doubleArray0[0] = 2470.19;
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.m_norm = 1.0E10;
      doubleArray0[1] = 1.0E10;
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, false);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-lowercase";
      stringArray0[1] = "";
      stringArray0[2] = "";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(1.0E10, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 32
  /*Coverage entropy=3.0432504498979998
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      naiveBayesMultinomialText0.getOptions();
      doubleArray0[0] = 2470.19;
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.m_norm = (-1264.0);
      doubleArray0[1] = 1.0E10;
      naiveBayesMultinomialText0.setUseStopList(true);
      doubleArray0[2] = (-861.0);
      doubleArray0[3] = (-347.85368339678695);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      naiveBayesMultinomialText0.pruneDictionary();
      double double0 = naiveBayesMultinomialText0.getMinWordFrequency();
      assertEquals((-1264.0), naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  /**
  //Test case number: 33
  /*Coverage entropy=0.9623351446188083
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldAllThrowIOExceptions();
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile1);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 34
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.m_minWordP = 586.400877568;
      String[] stringArray0 = new String[5];
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, false, true, false);
      stringArray0[0] = "eKhDKk{/NRQ~3|";
      stringArray0[1] = "";
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile1);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile2 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile0);
      FileSystemHandling.createFolder(evoSuiteFile2);
      naiveBayesMultinomialText1.setOptions(stringArray1);
      assertEquals(586.400877568, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 35
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.m_wordFrequencies = false;
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, double0, 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 36
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double double0 = (-839.112200183262);
      double[] doubleArray0 = new double[1];
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      doubleArray0[0] = (-839.112200183262);
      DenseInstance denseInstance0 = new DenseInstance((-839.112200183262), doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance(denseInstance0);
      SystemInUtil.addInputLine("A~~Yj<");
      naiveBayesMultinomialText0.getMinWordFrequency();
      SparseInstance sparseInstance1 = null;
      SparseInstance sparseInstance2 = new SparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance0 = null;
      try {
        binarySparseInstance0 = new BinarySparseInstance((SparseInstance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.BinarySparseInstance", e);
      }
  }

  /**
  //Test case number: 37
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      naiveBayesMultinomialText0.getLowercaseTokens();
      boolean boolean0 = naiveBayesMultinomialText0.m_useStopList;
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, (String) null);
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile0);
      FileSystemHandling.createFolder(evoSuiteFile1);
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-tokenizer";
      stringArray0[1] = "8lr~4";
      stringArray0[2] = "";
      stringArray0[3] = "-tokenizer";
      stringArray0[4] = "8lr~4";
      stringArray0[5] = "8lr~4";
      stringArray0[6] = "-tokenizer";
      String string0 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string0);
      
      String string1 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", string1);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 38
  /*Coverage entropy=2.9691101477068487
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("If true then document length is normalized according to the settings for norm and lnorm");
      UnaryOperator<Instance> unaryOperator0 = UnaryOperator.identity();
      instances0.replaceAll(unaryOperator0);
      TestInstances testInstances1 = new TestInstances();
      Instances instances1 = testInstances0.generate(".bsi");
      TestInstances testInstances2 = new TestInstances();
      testInstances0.setMultiInstance(false);
      testInstances1.setNumInstances((-2));
      testInstances1.setNumNominal((-1));
      testInstances1.getWords();
      testInstances1.setNumRelationalString((-2));
      testInstances2.setSeed((-1));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      testInstances0.setNumRelationalDate((-1));
      naiveBayesMultinomialText0.normTipText();
      testInstances2.setRelationalClassFormat(instances1);
      testInstances2.setNumNominalValues((-1));
      testInstances2.setNumRelationalDate((-994));
      testInstances2.setNoClass(true);
      TestInstances testInstances3 = new TestInstances();
      testInstances0.setNumInstancesRelational((-1));
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      String string1 = naiveBayesMultinomialText0.toString();
      assertEquals("The independent probability of a class\n--------------------------------------\nclass1\t12.0\nclass2\t10.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\t\n", string1);
      
      String string2 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string2);
      
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      MockFile mockFile0 = new MockFile("/=iq7dIc", "");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 39
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      naiveBayesMultinomialText0.getUseStopList();
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, (String) null);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "V#>wg");
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile1);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      boolean boolean0 = FileSystemHandling.createFolder(evoSuiteFile0);
      assertTrue(boolean0);
  }

  /**
  //Test case number: 40
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      Random.setNextRandom(4083);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "H\"B<_3wj.DPo6iO,7";
      stringArray0[1] = "";
      stringArray0[2] = "[+j[4F";
      stringArray0[3] = "weka.classifiers.bayes.NaiveBayesMultinomialText$Count";
      stringArray0[4] = "9]`dC#Ufh/f6}\"^";
      stringArray0[5] = "";
      stringArray0[6] = "QwAs$8m";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.getStemmer();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 41
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (-841.8367872572856);
      DenseInstance denseInstance0 = new DenseInstance((-841.8367872572856), doubleArray0);
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)18;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "lQg%XjnPc}%m]Ho8'A8");
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      
      naiveBayesMultinomialText1.m_norm = 0.0;
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      String[] stringArray0 = naiveBayesMultinomialText1.getOptions();
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText1.setOptions(stringArray0);
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
  }

  /**
  //Test case number: 42
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (-839.112200183262);
      DenseInstance denseInstance0 = new DenseInstance((-839.112200183262), doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance(denseInstance0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) sparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 43
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (-3155.6439453753);
      doubleArray0[1] = (-3155.6439453753);
      int[] intArray0 = new int[3];
      intArray0[0] = 843;
      intArray0[1] = 738;
      intArray0[2] = (-192);
      SparseInstance sparseInstance0 = new SparseInstance((-3155.6439453753), doubleArray0, intArray0, (-1));
      SparseInstance sparseInstance1 = new SparseInstance(sparseInstance0);
      try { 
        naiveBayesMultinomialText0.updateClassifier(sparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 44
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      Locale.getISOLanguages();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      String[] stringArray0 = new String[7];
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = (-2060.543214473);
      doubleArray0[1] = (-6.78214234);
      doubleArray0[2] = 2.0;
      doubleArray0[3] = (-1308.489840575);
      doubleArray0[4] = 2.0;
      doubleArray0[5] = 0.0;
      doubleArray0[6] = (-579.904615137);
      doubleArray0[7] = 0.0;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      stringArray0[3] = "eKhDKk{/NRQ~3|";
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      String[] stringArray1 = new String[10];
      stringArray1[0] = "-tokenizer";
      stringArray1[1] = "eKhDKk{/NRQ~3|";
      stringArray1[2] = "";
      stringArray1[3] = "eKhDKk{/NRQ~3|";
      stringArray0[4] = "";
      stringArray1[5] = stringArray0[0];
      stringArray1[6] = "-tokenizer";
      stringArray1[7] = "eKhDKk{/NRQ~3|";
      double[] doubleArray1 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray1);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 45
  /*Coverage entropy=2.9482791746635852
  */
  @Test(timeout = 4000)
  public void test45()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      
      TestInstances testInstances0 = new TestInstances();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Instances instances0 = testInstances0.generate("");
      UnaryOperator<Instance> unaryOperator0 = UnaryOperator.identity();
      instances0.replaceAll(unaryOperator0);
      TestInstances testInstances1 = new TestInstances();
      Instances instances1 = testInstances0.generate(".bsi");
      TestInstances testInstances2 = new TestInstances();
      testInstances1.setNumInstances((-2));
      testInstances1.setNumNominal(11);
      testInstances1.getWords();
      testInstances1.setNumRelationalString((-2));
      testInstances2.setSeed((-1));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      testInstances0.setNumRelationalDate((-1));
      naiveBayesMultinomialText0.normTipText();
      testInstances2.setRelationalClassFormat(instances1);
      testInstances2.setNumNominalValues((-1));
      testInstances1.setNumRelationalDate((-1406));
      testInstances1.setNoClass(false);
      TestInstances testInstances3 = new TestInstances();
      testInstances1.setNumInstancesRelational((-2161));
      String string1 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string1);
      
      SystemInUtil.addInputLine("a.7t>U$gL4#206");
      String string2 = naiveBayesMultinomialText0.toString();
      assertEquals("The independent probability of a class\n--------------------------------------\nclass1\t12.0\nclass2\t10.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\t\n", string2);
      
      String string3 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string3);
      
      String string4 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string4);
      
      String string5 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string5);
      
      String string6 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string6);
      
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 46
  /*Coverage entropy=2.3526910109712573
  */
  @Test(timeout = 4000)
  public void test46()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("");
      naiveBayesMultinomialText0.setUseStopList(true);
      UnaryOperator<Instance> unaryOperator0 = UnaryOperator.identity();
      instances0.replaceAll(unaryOperator0);
      TestInstances testInstances1 = new TestInstances();
      Instances instances1 = testInstances0.generate(".bsi");
      TestInstances testInstances2 = new TestInstances();
      testInstances0.setNumNominalValues((-1));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      testInstances2.setNumNominal((-2));
      naiveBayesMultinomialText0.normTipText();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) (-2);
      testInstances2.setRelationalClassFormat(instances1);
      testInstances2.getWords();
      testInstances2.setNumNominalValues((-1));
      doubleArray0[1] = (double) (-2);
      // Undeclared exception!
      try { 
        testInstances0.setWords("");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // At least 2 words must be provided!
         //
         verifyException("weka.core.TestInstances", e);
      }
  }

  /**
  //Test case number: 47
  /*Coverage entropy=2.185851463196929
  */
  @Test(timeout = 4000)
  public void test47()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, (String) null);
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile0);
      FileSystemHandling.createFolder(evoSuiteFile1);
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-tokenizer";
      stringArray0[1] = "8lr~4";
      stringArray0[2] = "";
      stringArray0[3] = "-tokenizer";
      stringArray0[4] = "8lr~4";
      stringArray0[5] = "8lr~4";
      stringArray0[6] = "-tokenizer";
      stringArray0[7] = "8lr~4";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: ClassNotFoundException");
      
      } catch(ClassNotFoundException e) {
      }
  }

  /**
  //Test case number: 48
  /*Coverage entropy=2.9603496546361194
  */
  @Test(timeout = 4000)
  public void test48()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      TestInstances testInstances0 = new TestInstances();
      naiveBayesMultinomialText0.setUseStopList(true);
      UnaryOperator.identity();
      TestInstances testInstances1 = new TestInstances();
      TestInstances testInstances2 = new TestInstances();
      testInstances0.setNumNominalValues((-1));
      testInstances2.setNumNominal((-2));
      naiveBayesMultinomialText0.normTipText();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) (-2);
      testInstances2.getWords();
      testInstances2.setNumNominalValues((-1));
      doubleArray0[1] = (double) (-2);
      doubleArray0[2] = (double) (-1);
      doubleArray0[3] = (double) (-1);
      testInstances1.setNoClass(false);
      TestInstances testInstances3 = new TestInstances();
      testInstances1.setNumInstancesRelational((-2161));
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      Random.setNextRandom((-1));
      Random.setNextRandom((-2));
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      
      naiveBayesMultinomialText0.setOptions(testInstances1.DEFAULT_WORDS);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", naiveBayesMultinomialText0.stopwordsTipText());
  }

  /**
  //Test case number: 49
  /*Coverage entropy=3.110621047329623
  */
  @Test(timeout = 4000)
  public void test49()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      boolean boolean0 = naiveBayesMultinomialText0.m_normalize;
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.createFolder(evoSuiteFile0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "user.dir");
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      FileSystemHandling.createFolder(evoSuiteFile0);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getOptions();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 50
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test50()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      byte[] byteArray0 = new byte[4];
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      byteArray0[0] = (byte) (-108);
      byteArray0[1] = (byte) (-1);
      byteArray0[2] = (byte) (-50);
      byteArray0[3] = (byte)18;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "If true then document length is normalized according to the settings for norm and lnorm");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.m_normalize = true;
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile1);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      Random.setNextRandom(362);
  }

  /**
  //Test case number: 51
  /*Coverage entropy=0.8505612088663046
  */
  @Test(timeout = 4000)
  public void test51()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (-839.112200183262);
      DenseInstance denseInstance0 = new DenseInstance((-839.112200183262), doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance(denseInstance0);
      int[] intArray0 = new int[8];
      intArray0[0] = 68;
      SystemInUtil.addInputLine((String) null);
      naiveBayesMultinomialText0.m_periodicP = (-1288);
      intArray0[1] = (-1);
      intArray0[2] = 68;
      intArray0[3] = 68;
      intArray0[4] = 68;
      SparseInstance sparseInstance1 = new SparseInstance(68, doubleArray0, intArray0, (-1));
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(sparseInstance1, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 52
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test52()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, double0, 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 53
  /*Coverage entropy=2.9482520471915943
  */
  @Test(timeout = 4000)
  public void test53()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("");
      UnaryOperator<Instance> unaryOperator0 = UnaryOperator.identity();
      instances0.replaceAll(unaryOperator0);
      TestInstances testInstances1 = new TestInstances();
      Instances instances1 = testInstances0.generate(".bsi");
      TestInstances testInstances2 = new TestInstances();
      testInstances1.setNumInstances((-2));
      testInstances1.setNumNominal(11);
      testInstances1.getWords();
      testInstances1.setNumRelationalString((-2));
      testInstances2.setSeed((-1));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      testInstances0.setNumRelationalDate((-1));
      naiveBayesMultinomialText0.normTipText();
      testInstances2.setRelationalClassFormat(instances1);
      testInstances2.setNumNominalValues((-1));
      testInstances1.setNumRelationalDate((-1406));
      testInstances1.setNoClass(false);
      TestInstances testInstances3 = new TestInstances();
      testInstances1.setNumInstancesRelational((-2161));
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      SystemInUtil.addInputLine("a.7t>U$gL4#206");
      String string1 = naiveBayesMultinomialText0.toString();
      assertEquals("The independent probability of a class\n--------------------------------------\nclass1\t12.0\nclass2\t10.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\t\n", string1);
      
      naiveBayesMultinomialText0.tokenizerTipText();
      String string2 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string2);
      
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      int int0 = naiveBayesMultinomialText0.getPeriodicPruning();
      assertEquals(0, int0);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 54
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test54()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "T-Vv4BhR|sXFIj4L";
      stringArray0[2] = "_+wBK0K[1";
      NaiveBayesMultinomialText.main(stringArray0);
      assertEquals(4, stringArray0.length);
  }

  /**
  //Test case number: 55
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test55()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      SystemInUtil.addInputLine(".m5]&!mJv4mxuqe");
      String string1 = naiveBayesMultinomialText0.getRevision();
      assertEquals("9122", string1);
      
      String string2 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string2);
      
      Random.setNextRandom(3512);
      String string3 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", string3);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 56
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test56()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, (String) null);
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile0);
      FileSystemHandling.createFolder(evoSuiteFile1);
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-tokenizer";
      stringArray0[1] = "8lr~4";
      stringArray0[2] = "";
      stringArray0[3] = "8lr~4";
      stringArray0[4] = "8lr~4";
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      String string1 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string1);
      
      String string2 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string2);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 57
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test57()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, (String) null);
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile0);
      FileSystemHandling.createFolder(evoSuiteFile1);
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.createFolder(evoSuiteFile0);
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (-99.0);
      DenseInstance denseInstance0 = new DenseInstance((-99.0), doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }
}
