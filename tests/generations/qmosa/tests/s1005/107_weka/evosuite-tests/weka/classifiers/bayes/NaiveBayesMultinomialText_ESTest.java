/*
 * This file was automatically generated by EvoSuite
 * Fri Nov 15 17:30:18 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.Locale;
import java.util.Properties;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.util.MockRandom;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.Classifier;
import weka.classifiers.bayes.NaiveBayes;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.LinearRegression;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.SMO;
import weka.classifiers.functions.SimpleLogistic;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.meta.ClassificationViaRegression;
import weka.classifiers.meta.FilteredClassifier;
import weka.classifiers.rules.JRip;
import weka.classifiers.trees.DecisionStump;
import weka.core.AbstractInstance;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.ProtectedProperties;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.neighboursearch.KDTree;
import weka.core.neighboursearch.LinearNNSearch;
import weka.core.stemmers.IteratedLovinsStemmer;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.AlphabeticTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.estimators.NormalEstimator;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_lnorm = 0.0;
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 2080.3864648546632;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 0.0;
      doubleArray0[4] = 0.0;
      doubleArray0[5] = 0.0;
      doubleArray0[6] = 0.0;
      doubleArray0[7] = 0.0;
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.toString();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=3.2843852887942293
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      double[] doubleArray0 = new double[14];
      SMO sMO0 = new SMO();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      binarySparseInstance0.deleteAttributeAt(2);
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      binarySparseInstance1.mergeInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance((SparseInstance) binarySparseInstance3);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      AbstractClassifier.runClassifier(sMO0, (String[]) null);
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      String[] stringArray1 = new String[3];
      stringArray1[0] = "the";
      stringArray1[1] = "-M";
      stringArray1[2] = "Set the name of a file in BIF XML format. A Bayes network learned from data can be compared with the Bayes network represented by the BIF file. Statistics calculated are o.a. the number of missing and extra arcs.";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray1);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.2302982632284003
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      double[] doubleArray0 = new double[14];
      SMO sMO0 = new SMO();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      double[] doubleArray1 = new double[1];
      doubleArray1[0] = (-2017.9077247704197);
      DenseInstance denseInstance0 = new DenseInstance(16.0, doubleArray1);
      DenseInstance denseInstance1 = new DenseInstance(denseInstance0);
      DenseInstance denseInstance2 = new DenseInstance(binarySparseInstance2);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((Instance) binarySparseInstance0);
      SparseInstance sparseInstance1 = new SparseInstance(1, doubleArray0);
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance((SparseInstance) binarySparseInstance2);
      binarySparseInstance1.setValue((-1), 1653.17189);
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("RZfv]j}@@<Bf");
      SparseInstance sparseInstance2 = new SparseInstance(1);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      BinarySparseInstance binarySparseInstance5 = new BinarySparseInstance(0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      double[] doubleArray2 = naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance5);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertArrayEquals(new double[] {0.5454545454545454, 0.4545454545454546}, doubleArray2, 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 3
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = (-904.10143487);
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      naiveBayesMultinomialText0.m_stopwordsFile = null;
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.pruneDictionary();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      TestInstances testInstances0 = new TestInstances();
      // Undeclared exception!
      try { 
        testInstances0.getRelationalFormat(33);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 33
         //
         verifyException("weka.core.TestInstances", e);
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.559241515868105
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning(3);
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.UNARY_CLASS;
      capabilities0.enable(capabilities_Capability0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      testInstances0.getWords();
      Instances instances1 = testInstances0.generate(".bsi");
      naiveBayesMultinomialText0.buildClassifier(instances1);
      naiveBayesMultinomialText0.toString();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch(instances0);
      instances0.containsAll(instances1);
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      Instances instances2 = testInstances1.generate("The,quick,brown,fox,jumps,over,the,lazy,dog");
      TestInstances testInstances2 = TestInstances.forCapabilities(capabilities0);
      testInstances2.getWords();
      capabilities0.toSource(".arff", (-2));
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.useStopListTipText();
      naiveBayesMultinomialText0.LNormTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.stemmerTipText();
      naiveBayesMultinomialText1.stopwordsTipText();
      naiveBayesMultinomialText2.periodicPruningTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText3.useWordFrequenciesTipText();
      Random.setNextRandom((-610));
      naiveBayesMultinomialText0.buildClassifier(instances2);
      assertEquals(3, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 5
  /*Coverage entropy=1.6262554809752925
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      naiveBayesMultinomialText0.m_useStopList = true;
      sMO0.turnChecksOff();
      DenseInstance denseInstance0 = new DenseInstance(0);
      SystemInUtil.addInputLine("OneRAttributeEval :\n\nEvaluates the worthof an attribute by using the OneR classifier.\n");
      DenseInstance denseInstance1 = new DenseInstance(0);
      denseInstance0.toStringNoWeight();
      denseInstance0.mergeInstance(denseInstance1);
      SparseInstance sparseInstance0 = new SparseInstance(denseInstance0);
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = 12.0;
      doubleArray0[1] = (double) 1;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2, doubleArray0);
      naiveBayesMultinomialText0.getUseStopList();
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=1.987991353377197
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      naiveBayesMultinomialText0.m_useStopList = true;
      sMO0.turnChecksOff();
      DenseInstance denseInstance0 = new DenseInstance(0);
      DenseInstance denseInstance1 = new DenseInstance(0);
      JRip jRip0 = new JRip();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      boolean boolean0 = naiveBayesMultinomialText0.m_normalize;
      assertFalse(boolean0);
      
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      testInstances0.getWords();
      testInstances0.generate("");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      MockFile mockFile0 = new MockFile("?'Q/Z6FdDR2pB", "D12cE7:l.`8bO");
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("");
      String string1 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string1);
      
      naiveBayesMultinomialText0.useStopListTipText();
      String string2 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", string2);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 7
  /*Coverage entropy=2.027377075708073
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      String[] stringArray0 = Locale.getISOCountries();
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
  }

  /**
  //Test case number: 8
  /*Coverage entropy=2.0610570536892165
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, true, true, true);
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.m_normalize = true;
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      String string1 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string1);
      
      naiveBayesMultinomialText0.stemmerTipText();
      String string2 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", string2);
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.5235456898431248
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      naiveBayesMultinomialText0.m_useStopList = true;
      sMO0.turnChecksOff();
      DenseInstance denseInstance0 = new DenseInstance(0);
      DenseInstance denseInstance1 = new DenseInstance(0);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumRelationalNumeric(2070);
      Instances instances0 = testInstances0.generate("-P");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      MockFile mockFile0 = new MockFile(")", "@relation");
      naiveBayesMultinomialText0.normTipText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("y-gs|");
      String string0 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string0);
      
      String string1 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string1);
      
      String string2 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string2);
      
      String string3 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string3);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 10
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      naiveBayesMultinomialText0.m_useStopList = true;
      TestInstances testInstances0 = new TestInstances();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      testInstances0.generate("");
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("~gc_|PCWB1KhIcgS|:0", arrayList0, 29);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: No attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=2.7350328288675785
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, true, true, true);
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      JRip jRip0 = new JRip();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.m_normalize = true;
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("}7p'v7>R8aA4'");
      testInstances0.getWords();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText1.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      
      String string1 = naiveBayesMultinomialText1.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string1);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      String string2 = naiveBayesMultinomialText3.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string2);
      
      String string3 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string3);
      
      String string4 = naiveBayesMultinomialText3.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string4);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText4 = new NaiveBayesMultinomialText();
      String string5 = naiveBayesMultinomialText3.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string5);
      
      Random.setNextRandom(1610612736);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = (double) 0;
      doubleArray0[1] = (double) 2;
      doubleArray0[2] = (double) 0;
      doubleArray0[3] = (double) 1;
      doubleArray0[4] = (double) 2;
      doubleArray0[5] = (double) 2;
      doubleArray0[6] = (double) 0;
      doubleArray0[7] = (double) 2;
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      DenseInstance denseInstance0 = new DenseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      DenseInstance denseInstance1 = new DenseInstance(denseInstance0);
      binarySparseInstance0.setValue(1, 2.0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[1] = "Invert: ";
      stringArray0[2] = "";
      stringArray0[3] = "-P <# instances>";
      stringArray0[4] = "-";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: StringIndexOutOfBoundsException");
      
      } catch(StringIndexOutOfBoundsException e) {
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=2.022248870579868
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      double[] doubleArray0 = new double[1];
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[7];
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "ReGdrim.U~]?]m-L0cT";
      stringArray0[1] = ".eEg4_M]t%F0U";
      stringArray0[2] = ")";
      stringArray0[3] = "";
      stringArray0[4] = "-stopwords <file>";
      stringArray0[5] = "e-W'9>Zo";
      naiveBayesMultinomialText1.setLowercaseTokens(false);
      stringArray0[6] = "?;^Y!sA#5<$?1C";
      stringArray0[7] = "";
      stringArray0[8] = "-M";
      try { 
        naiveBayesMultinomialText1.setOptions(stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No value given for -M option.
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=1.3120076729259056
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      double[] doubleArray0 = new double[14];
      SMO sMO0 = new SMO();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      binarySparseInstance0.deleteAttributeAt(2);
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance(1);
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance((SparseInstance) binarySparseInstance3);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray1 = new double[8];
      doubleArray1[0] = (double) 1;
      doubleArray1[1] = (double) 1;
      doubleArray1[2] = (double) 1;
      doubleArray1[3] = (double) 2;
      doubleArray1[4] = (double) 1;
      doubleArray1[5] = (double) 1;
      doubleArray1[6] = (double) 1;
      doubleArray1[7] = (double) 1;
      BinarySparseInstance binarySparseInstance5 = new BinarySparseInstance((-4393.231313), doubleArray1);
      binarySparseInstance4.isMissingSparse(0);
      BinarySparseInstance binarySparseInstance6 = new BinarySparseInstance((Instance) binarySparseInstance2);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText1.distributionForInstance(binarySparseInstance2);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 15
  /*Coverage entropy=3.4513675988096226
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setStemmer(iteratedLovinsStemmer0);
      naiveBayesMultinomialText0.setMinWordFrequency(3);
      naiveBayesMultinomialText1.setPeriodicPruning(3);
      FileSystemHandling.shouldAllThrowIOExceptions();
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText1.m_tokenizer;
      String[] stringArray0 = new String[1];
      Tokenizer.runTokenizer(wordTokenizer0, stringArray0);
      stringArray0[0] = "C[";
      wordTokenizer0.tokenize("C[");
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      Random.setNextRandom(3);
      NullStemmer nullStemmer0 = new NullStemmer();
      naiveBayesMultinomialText1.getRevision();
      naiveBayesMultinomialText1.stemmerTipText();
      naiveBayesMultinomialText1.getOptions();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText1.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 16
  /*Coverage entropy=2.3742860945273705
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Locale.getISOCountries();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("tu");
      SparseInstance sparseInstance0 = new SparseInstance(1882);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      instances0.add((Instance) sparseInstance0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      String string0 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string0);
      
      String string1 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string1);
  }

  /**
  //Test case number: 17
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      double[] doubleArray0 = new double[14];
      SMO sMO0 = new SMO();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      double[] doubleArray1 = new double[1];
      doubleArray1[0] = (-2017.9077247704197);
      DenseInstance denseInstance0 = new DenseInstance(16.0, doubleArray1);
      DenseInstance denseInstance1 = new DenseInstance(denseInstance0);
      DenseInstance denseInstance2 = new DenseInstance(binarySparseInstance2);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((Instance) binarySparseInstance0);
      SparseInstance sparseInstance1 = new SparseInstance(1, doubleArray0);
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("");
      SparseInstance sparseInstance2 = new SparseInstance(1);
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance(sparseInstance2);
      instances0.add((Instance) denseInstance2);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.8757273918971373
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning(2074);
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      testInstances1.setNumRelationalNumeric((-6160));
      Instances instances0 = testInstances0.generate("6OFzNeFK");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.normTipText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("f17YQ");
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.LNormTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      assertEquals(2074, naiveBayesMultinomialText0.getPeriodicPruning());
      
      naiveBayesMultinomialText1.stopwordsTipText();
      String string0 = naiveBayesMultinomialText1.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string0);
  }

  /**
  //Test case number: 19
  /*Coverage entropy=2.920359518820598
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      SMO sMO0 = new SMO();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning(1);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumRelationalNumeric(2);
      Instances instances0 = testInstances0.generate("6OFzNeFK");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.normTipText();
      String string0 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string0);
      
      String string1 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string1);
      
      String string2 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string2);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.stemmerTipText();
      String string3 = naiveBayesMultinomialText1.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string3);
      
      naiveBayesMultinomialText1.periodicPruningTipText();
      String string4 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", string4);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      SMO sMO0 = new SMO();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning(2);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumRelational(11);
      testInstances0.setNumRelationalNumeric((-1));
      Instances instances0 = testInstances0.generate("6OFzNeFK");
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Cannot handle relational attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "b8cbY|OkL");
      naiveBayesMultinomialText0.m_periodicP = 19;
      naiveBayesMultinomialText0.getPeriodicPruning();
      Random.setNextRandom(19);
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) 19;
      doubleArray0[1] = 299.87;
      doubleArray0[2] = 299.87;
      doubleArray0[3] = 299.87;
      doubleArray0[4] = 299.87;
      doubleArray0[5] = 299.87;
      doubleArray0[6] = (double) 19;
      doubleArray0[7] = (double) 19;
      doubleArray0[8] = 299.87;
      DenseInstance denseInstance0 = new DenseInstance(19);
      DenseInstance denseInstance1 = new DenseInstance(denseInstance0);
      // Undeclared exception!
      try { 
        denseInstance1.equalHeadersMsg(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=3.0215177853024624
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm(250.22606121);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.m_periodicP = 1245;
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "unsupervised):\n");
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.listOptions();
      MockFile mockFile0 = new MockFile("9122");
      MockFile mockFile1 = new MockFile(mockFile0, "k?ws%");
      mockFile1.delete();
      naiveBayesMultinomialText0.setStopwords(mockFile1);
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals(250.22606121, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 23
  /*Coverage entropy=3.2238144440718632
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      File file0 = MockFile.createTempFile("ju;*TrB=rH($wX", "ju;*TrB=rH($wX");
      MockFile.createTempFile("7w ~;X[X8B&pA", "7w ~;X[X8B&pA");
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.listOptions();
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = 5132.43;
      doubleArray0[1] = (double) 0L;
      SparseInstance sparseInstance0 = new SparseInstance(5132.43, doubleArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(1);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      AbstractClassifier.runClassifier(naiveBayesMultinomialText1, (String[]) null);
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, (String[]) null);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      
      naiveBayesMultinomialText1.setOptions((String[]) null);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 24
  /*Coverage entropy=3.1435618682187627
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      File file0 = MockFile.createTempFile("ju;*TrB=rH($wX", "ju;*TrB=rH($wX");
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.listOptions();
      System.setCurrentTimeMillis(0L);
      naiveBayesMultinomialText0.getStemmer();
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      naiveBayesMultinomialText0.globalInfo();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(11);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      naiveBayesMultinomialText0.getOptions();
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=1.9012735713814104
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      File file0 = MockFile.createTempFile("ju;*TrB=rH($wX", "ju;*TrB=rH($wX");
      file0.getCanonicalFile();
      MockFile.createTempFile("7w ~;X[X8B&pA", "7w ~;X[X8B&pA");
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.listOptions();
      DenseInstance denseInstance0 = new DenseInstance(63);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=1.9662848511774718
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      testInstances0.getWords();
      Instances instances1 = testInstances0.generate(".bsi");
      naiveBayesMultinomialText0.buildClassifier(instances1);
      naiveBayesMultinomialText0.toString();
      LinearNNSearch linearNNSearch0 = new LinearNNSearch(instances0);
      instances0.containsAll(instances1);
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      Instances instances2 = testInstances1.generate("The,quick,brown,fox,jumps,over,the,lazy,dog");
      TestInstances testInstances2 = TestInstances.forCapabilities(capabilities0);
      testInstances2.getWords();
      capabilities0.toSource(".arff", (-2));
      Capabilities.forInstances(instances2, false);
      SystemInUtil.addInputLine("XOM5d8");
      TestInstances testInstances3 = new TestInstances();
      MockRandom mockRandom0 = new MockRandom();
      TestInstances testInstances4 = new TestInstances();
      Instances instances3 = null;
      // Undeclared exception!
      try { 
        mockRandom0.doubles((double) (-1), (double) (-2));
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // bound must be greater than origin
         //
         verifyException("java.util.Random", e);
      }
  }

  /**
  //Test case number: 27
  /*Coverage entropy=0.9623351446188083
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte)28;
      byteArray0[1] = (byte) (-91);
      byteArray0[2] = (byte)117;
      byteArray0[3] = (byte) (-121);
      byteArray0[4] = (byte)12;
      byteArray0[5] = (byte)50;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      Random.setNextRandom(30);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setStopwords((File) null);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 28
  /*Coverage entropy=2.5500297769739535
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      boolean boolean0 = true;
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.m_lnorm = 0.0;
      naiveBayesMultinomialText0.setNorm(0.0);
      double[] doubleArray0 = new double[0];
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) iteratedLovinsStemmer0;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.setLNorm(0.0);
      iteratedLovinsStemmer0.getRevision();
      int int0 = (-2368);
      iteratedLovinsStemmer0.getRevision();
      naiveBayesMultinomialText0.setPeriodicPruning((-2368));
      naiveBayesMultinomialText0.getPeriodicPruning();
      iteratedLovinsStemmer0.stemString("KewZORwMMr(");
      SparseInstance sparseInstance0 = new SparseInstance(0.0, naiveBayesMultinomialText0.m_wordsPerClass);
      KDTree kDTree0 = new KDTree();
      try { 
        kDTree0.nearestNeighbour(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.KDTree", e);
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=2.5323204850794725
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      LinkedList<String> linkedList0 = new LinkedList<String>();
      linkedList0.poll();
      linkedList0.add("org.tartarus.snowball");
      ArrayList<String> arrayList0 = new ArrayList<String>();
      Attribute attribute0 = new Attribute("org.tartarus.snowball.ext", arrayList0);
      arrayList0.retainAll(linkedList0);
      linkedList0.offerLast("{tZ3RK4OMH/w");
      double[] doubleArray0 = new double[7];
      linkedList0.removeFirst();
      doubleArray0[0] = (double) 0;
      arrayList0.add("d(u'V/KDK7kQzk(X");
      LinearRegression linearRegression0 = new LinearRegression();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "integer";
      stringArray0[1] = null;
      stringArray0[2] = "@end";
      stringArray0[3] = "real";
      AbstractClassifier.runClassifier(linearRegression0, stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray1 = new String[2];
      stringArray1[0] = "org.tartarus.snowball";
      stringArray1[1] = "real";
      naiveBayesMultinomialText0.setOptions(stringArray1);
      Random.setNextRandom(2);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=2.372821413206516
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte)1;
      byteArray0[1] = (byte) (-54);
      byteArray0[2] = (byte)1;
      byteArray0[3] = (byte)0;
      byteArray0[4] = (byte)107;
      byteArray0[5] = (byte) (-29);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      precomputedKernelMatrixKernel0.setChecksTurnedOff(false);
      MockFile mockFile0 = new MockFile((String) null, "VemB;Z_W^B<>U:fU");
      naiveBayesMultinomialText0.setNorm(0.0);
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.getStopwords();
      assertEquals(0.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 31
  /*Coverage entropy=3.4011833280084667
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      snowballStemmer0.getStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      SnowballStemmer snowballStemmer1 = (SnowballStemmer)naiveBayesMultinomialText0.m_stemmer;
      naiveBayesMultinomialText0.setStemmer(snowballStemmer1);
      snowballStemmer0.getRevision();
      naiveBayesMultinomialText0.setMinWordFrequency(606.66613992);
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      String[] stringArray0 = new String[24];
      stringArray0[0] = "org.tartarus.snowball.ext";
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setUseStopList(false);
      naiveBayesMultinomialText1.setLowercaseTokens(false);
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText1.getStopwords();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.setPeriodicPruning((-564));
      AbstractClassifier.makeCopies(naiveBayesMultinomialText1, 3498);
      naiveBayesMultinomialText1.stemmerTipText();
      naiveBayesMultinomialText1.normTipText();
      naiveBayesMultinomialText1.getLNorm();
      naiveBayesMultinomialText0.getNorm();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.pruneDictionary();
      naiveBayesMultinomialText2.getStemmer();
      naiveBayesMultinomialText2.setOptions(stringArray1);
      assertEquals(606.66613992, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText2.getUseStopList());
  }

  /**
  //Test case number: 32
  /*Coverage entropy=1.0834763040946214
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      naiveBayesMultinomialText0.m_useStopList = true;
      sMO0.turnChecksOff();
      DenseInstance denseInstance0 = new DenseInstance(0);
      SystemInUtil.addInputLine("OneRAttributeEval :\n\nEvaluates the worthof an attribute by using the OneR classifier.\n");
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 33
  /*Coverage entropy=3.0310763973814288
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, false, false, false);
      naiveBayesMultinomialText0.m_minWordP = 0.0;
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "The norm of the instances after normalization.";
      stringArray0[1] = "The norm of the instances after normalization.";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("");
      snowballStemmer0.listOptions();
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.getCapabilities();
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText1.setNormalizeDocLength(true);
      assertTrue(naiveBayesMultinomialText1.getNormalizeDocLength());
      
      naiveBayesMultinomialText0.reset();
      assertEquals(0.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=2.8864499237464396
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, false, false, false);
      naiveBayesMultinomialText0.m_minWordP = 0.0;
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setNorm(0.0);
      SGDText sGDText0 = new SGDText();
      sGDText0.setStemmer((Stemmer) null);
      Tokenizer tokenizer0 = sGDText0.getTokenizer();
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.reset();
      MockFile mockFile0 = (MockFile)naiveBayesMultinomialText0.m_stopwordsFile;
      String[] stringArray0 = new String[9];
      stringArray0[0] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[1] = "The norm of the instances after normalization.";
      stringArray0[2] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[3] = "The norm of the instances after normalization.";
      stringArray0[4] = "The LNorm to use for document length normalization.";
      stringArray0[5] = "XQae,6,mcq8G12o0s";
      stringArray0[6] = "The norm of the instances after normalization.";
      stringArray0[7] = "-norm <num>";
      stringArray0[8] = "The norm of the instances after normalization.";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 35
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1245);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Capabilities.props");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "{3");
      SimpleLogistic simpleLogistic0 = new SimpleLogistic((-302), true, true);
      AbstractClassifier.makeCopy(simpleLogistic0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning((-937));
      DecisionStump decisionStump0 = new DecisionStump();
      naiveBayesMultinomialText0.pruneDictionary();
      assertEquals((-937), naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 36
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, false, false, false);
      naiveBayesMultinomialText0.globalInfo();
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte)40;
      byteArray0[1] = (byte)7;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.setNorm(0.0);
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.getNorm();
      Random.setNextRandom(5);
  }

  /**
  //Test case number: 37
  /*Coverage entropy=3.4011833280084667
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      snowballStemmer0.getStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      SnowballStemmer snowballStemmer1 = (SnowballStemmer)naiveBayesMultinomialText0.m_stemmer;
      naiveBayesMultinomialText0.setStemmer(snowballStemmer1);
      snowballStemmer0.getRevision();
      naiveBayesMultinomialText0.setMinWordFrequency(606.66613992);
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      String[] stringArray0 = new String[24];
      stringArray0[0] = "org.tartarus.snowball.ext";
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setUseStopList(false);
      naiveBayesMultinomialText1.setLowercaseTokens(false);
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText1.getStopwords();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.setPeriodicPruning((-564));
      AbstractClassifier.makeCopies(naiveBayesMultinomialText1, 3498);
      naiveBayesMultinomialText1.stemmerTipText();
      naiveBayesMultinomialText1.normTipText();
      naiveBayesMultinomialText1.getLNorm();
      naiveBayesMultinomialText0.getNorm();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.pruneDictionary();
      naiveBayesMultinomialText2.m_normalize = false;
      naiveBayesMultinomialText2.getStemmer();
      naiveBayesMultinomialText2.setOptions(stringArray1);
      System.setCurrentTimeMillis((-4012L));
  }

  /**
  //Test case number: 38
  /*Coverage entropy=0.9004024235381879
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      sMO0.turnChecksOff();
      DenseInstance denseInstance0 = new DenseInstance(0);
      sMO0.getFilterType();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, false);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 39
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      double[] doubleArray0 = new double[1];
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      DenseInstance denseInstance0 = new DenseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      DenseInstance denseInstance1 = new DenseInstance(denseInstance0);
      binarySparseInstance0.setValue(1, 926.0);
      SparseInstance sparseInstance1 = new SparseInstance(denseInstance0);
      AbstractInstance.s_numericAfterDecimalPoint = 1;
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance1);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.getData();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 40
  /*Coverage entropy=0.9623351446188083
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("!PUqk]J`EEn");
      LinkedList<String> linkedList0 = new LinkedList<String>();
      linkedList0.poll();
      ArrayList<String> arrayList0 = new ArrayList<String>();
      Attribute attribute0 = new Attribute("org.tartarus.snowball.ext", arrayList0);
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (double) 0;
      arrayList0.add("r$:IXsf.?61");
      doubleArray0[1] = (double) 3;
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 41
  /*Coverage entropy=3.3571740769916842
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      double[] doubleArray0 = new double[14];
      SMO sMO0 = new SMO();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      binarySparseInstance0.deleteAttributeAt(2);
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      binarySparseInstance3.setValue(6, (double) 1);
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance((SparseInstance) binarySparseInstance3);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      AbstractClassifier.runClassifier(sMO0, stringArray0);
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      AbstractClassifier.runClassifier(sMO0, stringArray0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 42
  /*Coverage entropy=0.8505612088663046
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      double[] doubleArray0 = new double[14];
      SMO sMO0 = new SMO();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      double[] doubleArray1 = new double[1];
      doubleArray0[3] = (-2021.470156811466);
      DenseInstance denseInstance0 = new DenseInstance(15.0, doubleArray1);
      DenseInstance denseInstance1 = new DenseInstance(denseInstance0);
      DenseInstance denseInstance2 = new DenseInstance(binarySparseInstance2);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((Instance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      DenseInstance denseInstance3 = new DenseInstance(binarySparseInstance1);
      binarySparseInstance4.setValue(0, 3.0);
      DenseInstance denseInstance4 = new DenseInstance(0);
      SparseInstance sparseInstance1 = new SparseInstance(denseInstance4);
      BinarySparseInstance binarySparseInstance5 = new BinarySparseInstance(3318.74, doubleArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 43
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      double[] doubleArray0 = new double[1];
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[5];
      TestInstances testInstances0 = new TestInstances();
      testInstances0.generate("RZfv]j}@@<Bf");
      SparseInstance sparseInstance0 = new SparseInstance(0);
      naiveBayesMultinomialText0.getUseStopList();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 44
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      int int0 = naiveBayesMultinomialText0.getPeriodicPruning();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, int0);
  }

  /**
  //Test case number: 45
  /*Coverage entropy=2.10893980259848
  */
  @Test(timeout = 4000)
  public void test45()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (double) 0;
      int[] intArray0 = new int[5];
      intArray0[0] = 0;
      intArray0[1] = 2;
      intArray0[2] = 1;
      intArray0[3] = 2;
      intArray0[4] = 2;
      SparseInstance sparseInstance0 = new SparseInstance(2, doubleArray0, intArray0, 617);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      DenseInstance denseInstance0 = new DenseInstance(binarySparseInstance1);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      DenseInstance denseInstance1 = new DenseInstance(sparseInstance0);
      binarySparseInstance1.setValue((-411), 0.0);
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("A journal name. Abbreviations are provided for many journals.");
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      instances0.add((Instance) denseInstance1);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 2, Size: 2
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  /**
  //Test case number: 46
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test46()  throws Throwable  {
      double[] doubleArray0 = new double[14];
      SMO sMO0 = new SMO();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      DenseInstance denseInstance0 = new DenseInstance(1, doubleArray0);
      DenseInstance denseInstance1 = new DenseInstance(denseInstance0);
      DenseInstance denseInstance2 = new DenseInstance(binarySparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((Instance) binarySparseInstance0);
      binarySparseInstance1.copy();
      binarySparseInstance2.setValue(0, (-612.7061032072958));
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      DenseInstance denseInstance3 = new DenseInstance(binarySparseInstance1);
      binarySparseInstance1.setValue(0, (double) 0);
      DenseInstance denseInstance4 = new DenseInstance(250);
      denseInstance3.toStringNoWeight();
      SparseInstance sparseInstance1 = new SparseInstance(denseInstance0);
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance((SparseInstance) binarySparseInstance2);
      BinarySparseInstance binarySparseInstance5 = new BinarySparseInstance((Instance) binarySparseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance2);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 47
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test47()  throws Throwable  {
      ArrayList<String> arrayList0 = new ArrayList<String>();
      Attribute attribute0 = new Attribute("!PUqk]J`EEn", arrayList0);
      LinkedList<String> linkedList0 = new LinkedList<String>();
      linkedList0.offerLast("E<ShSpZRQ\";a!");
      linkedList0.removeFirst();
      arrayList0.spliterator();
      arrayList0.add("date");
      LinearRegression linearRegression0 = new LinearRegression();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "@attribute";
      stringArray0[1] = "date";
      stringArray0[2] = "numeric";
      stringArray0[3] = "string";
      Properties properties0 = new Properties();
      ProtectedProperties protectedProperties0 = new ProtectedProperties(properties0);
      Attribute attribute1 = new Attribute("string", "0`{y", protectedProperties0);
      attribute0.addStringValue(attribute1, 0);
      stringArray0[4] = "E<ShSpZRQ\";a!";
      stringArray0[5] = "integer";
      arrayList0.removeAll(linkedList0);
      stringArray0[6] = "date";
      stringArray0[7] = "relational";
      stringArray0[8] = "4B:\"<.(2uQd";
      AbstractClassifier.runClassifier(linearRegression0, stringArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 48
  /*Coverage entropy=3.3589840317428155
  */
  @Test(timeout = 4000)
  public void test48()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      naiveBayesMultinomialText0.m_normalize = false;
      naiveBayesMultinomialText0.reset();
      doubleArray0[0] = 0.0;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.setLNorm((-1942.58));
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.m_useStopList = false;
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.setPeriodicPruning((-564));
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.m_periodicP = 0;
      AbstractClassifier.makeCopies(naiveBayesMultinomialText0, 3498);
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 49
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test49()  throws Throwable  {
      byte[] byteArray0 = new byte[7];
      byteArray0[0] = (byte) (-46);
      byteArray0[1] = (byte)23;
      byteArray0[2] = (byte)11;
      byteArray0[3] = (byte)0;
      byteArray0[4] = (byte)30;
      byteArray0[5] = (byte) (-106);
      byteArray0[6] = (byte)21;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      JRip jRip0 = new JRip();
      int[] intArray0 = new int[3];
      intArray0[0] = (int) (byte)21;
      intArray0[1] = (int) (byte)0;
      intArray0[2] = (int) (byte) (-46);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1286.51954536803), intArray0, (byte)0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 50
  /*Coverage entropy=2.900256387258455
  */
  @Test(timeout = 4000)
  public void test50()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.pruneDictionary();
      snowballStemmer0.getStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      SnowballStemmer snowballStemmer1 = (SnowballStemmer)naiveBayesMultinomialText0.m_stemmer;
      snowballStemmer0.listOptions();
      naiveBayesMultinomialText0.setStemmer(snowballStemmer1);
      String[] stringArray0 = new String[4];
      stringArray0[0] = "t|";
      stringArray0[1] = "org.tartarus.snowball.ext";
      stringArray0[2] = "org.tartarus.snowball";
      stringArray0[3] = "D- W";
      String string0 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string0);
      
      String string1 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string1);
      
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(2.0, double0, 0.01);
      
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 51
  /*Coverage entropy=2.739533718548687
  */
  @Test(timeout = 4000)
  public void test51()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      naiveBayesMultinomialText0.m_useStopList = true;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      String[] stringArray1 = new String[1];
      stringArray1[0] = "weka.classifiers.trees.REPTree";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray1);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 52
  /*Coverage entropy=3.3589840317428155
  */
  @Test(timeout = 4000)
  public void test52()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.reset();
      doubleArray0[0] = 0.0;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.m_normalize = false;
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.setPeriodicPruning((-564));
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.m_periodicP = 0;
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "\tMinimum word frequency. Words with less than this frequence are ignored.\n\tIf periodic pruning is turned on then this is also used to determine which\n\twords to remove from the dictionary (default = 3).");
      AbstractClassifier.makeCopies(naiveBayesMultinomialText0, 3498);
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      System.setCurrentTimeMillis(0);
  }

  /**
  //Test case number: 53
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test53()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 54
  /*Coverage entropy=2.82453825423366
  */
  @Test(timeout = 4000)
  public void test54()  throws Throwable  {
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("!PUqk]J`EEn");
      LinkedList<String> linkedList0 = new LinkedList<String>();
      linkedList0.poll();
      ArrayList<String> arrayList0 = new ArrayList<String>();
      Attribute attribute0 = new Attribute("org.tartarus.snowball.ext", arrayList0);
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (double) 0;
      arrayList0.add("r$:IXsf.?61");
      doubleArray0[1] = (double) 3;
      doubleArray0[2] = (double) 1;
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      
      SnowballStemmer snowballStemmer1 = new SnowballStemmer("W");
      naiveBayesMultinomialText0.setStemmer(snowballStemmer1);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "integer";
      naiveBayesMultinomialText1.setOptions(stringArray0);
      String string1 = naiveBayesMultinomialText1.minWordFrequencyTipText();
      assertFalse(naiveBayesMultinomialText1.getLowercaseTokens());
      assertFalse(naiveBayesMultinomialText1.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string1);
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      
      String string2 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string2);
      
      String string3 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", string3);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 55
  /*Coverage entropy=3.3142487148788504
  */
  @Test(timeout = 4000)
  public void test55()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.listOptions();
      DecisionStump decisionStump0 = new DecisionStump();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.m_minWordP = 1966.09807;
      naiveBayesMultinomialText1.setOptions(stringArray0);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 56
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test56()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = 608.4061009754;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 1235.7545956964443;
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      doubleArray0[3] = 1536.0;
      doubleArray0[4] = 4.0;
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      doubleArray0[5] = (-1.0);
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      System.setCurrentTimeMillis((-1127L));
      String[] stringArray0 = new String[5];
      stringArray0[0] = "Whether to convert all tokens to lowercase";
      stringArray0[1] = "Whether to convert all tokens to lowercase";
      stringArray0[2] = null;
      stringArray0[3] = "Whether to convert all tokens to lowercase";
      stringArray0[4] = null;
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 57
  /*Coverage entropy=2.6298718780844146
  */
  @Test(timeout = 4000)
  public void test57()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.listOptions();
      ClassificationViaRegression classificationViaRegression0 = new ClassificationViaRegression();
      AbstractClassifier.makeCopy(classificationViaRegression0);
      naiveBayesMultinomialText0.setPeriodicPruning((-564));
      DecisionStump decisionStump0 = new DecisionStump();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "nS?4ES)M#%eLhee";
      stringArray0[1] = "'LYSs$`'d^}?<2";
      stringArray0[2] = "z";
      stringArray0[3] = "'mS";
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      stringArray0[4] = "";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals((-564), naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 58
  /*Coverage entropy=2.4267173502315558
  */
  @Test(timeout = 4000)
  public void test58()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      naiveBayesMultinomialText0.m_useStopList = true;
      sMO0.turnChecksOff();
      DenseInstance denseInstance0 = new DenseInstance(1);
      SystemInUtil.addInputLine("OneRAttributeEval :\n\nEvaluates the worthof an attribute by using the OneR classifier.\n");
      String[] stringArray0 = new String[1];
      stringArray0[0] = "OneRAttributeEval :\n\nEvaluates the worthof an attribute by using the OneR classifier.\n";
      AbstractClassifier.runClassifier(sMO0, stringArray0);
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      AbstractClassifier.runClassifier((Classifier) null, stringArray0);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 59
  /*Coverage entropy=2.5323204850794725
  */
  @Test(timeout = 4000)
  public void test59()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SMO sMO0 = new SMO();
      Classifier classifier0 = AbstractClassifier.makeCopy(sMO0);
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      DecisionStump decisionStump0 = new DecisionStump();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "vK@";
      stringArray0[3] = "6zPt6O{}k/U Xe]+-";
      AbstractClassifier.runClassifier(classifier0, stringArray0);
      stringArray0[4] = "";
      stringArray0[5] = "";
      stringArray0[6] = "";
      stringArray0[7] = "-W";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 60
  /*Coverage entropy=2.534059615514255
  */
  @Test(timeout = 4000)
  public void test60()  throws Throwable  {
      double[] doubleArray0 = new double[1];
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      naiveBayesMultinomialText0.listOptions();
      DecisionStump decisionStump0 = new DecisionStump();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      
      String[] stringArray0 = new String[6];
      stringArray0[0] = "Use supervised discretization to convert numeric attributes to nominal ones.";
      stringArray0[1] = "        else if (i.attribute(j).isNumeric())\n";
      stringArray0[2] = "Use supervised discretization to convert numeric attributes to nominal ones.";
      stringArray0[3] = "-normalize";
      stringArray0[4] = "";
      stringArray0[5] = "{8Us-=pNr!2";
      naiveBayesMultinomialText1.setOptions(stringArray0);
      assertTrue(naiveBayesMultinomialText1.getNormalizeDocLength());
  }

  /**
  //Test case number: 61
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test61()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-u5D[HFh_5\"/xTvo{fR";
      stringArray0[1] = "_0}([2g\"6xo/z8r";
      stringArray0[2] = "anyways";
      NaiveBayesMultinomialText.main(stringArray0);
      assertEquals(3, stringArray0.length);
  }

  /**
  //Test case number: 62
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test62()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "): ";
      stringArray0[1] = "g'i2sV~d{6\\Tv>0Q=E";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.setLNorm(1989.70773674);
      assertEquals(1989.70773674, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 63
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test63()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      SystemInUtil.addInputLine("\t");
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      String[] stringArray0 = new String[6];
      stringArray0[1] = "qUuZ<nNdd&,k7";
      stringArray0[2] = "The independent probability of a class\n";
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "=)YLq@K,[rp5=+R)");
      stringArray0[3] = "8:IsW=gCfO=>9m2";
      stringArray0[4] = "";
      stringArray0[5] = "I:__ Fy^+d";
      NaiveBayesMultinomialText.main(stringArray0);
      assertEquals(6, stringArray0.length);
  }

  /**
  //Test case number: 64
  /*Coverage entropy=0.9623351446188083
  */
  @Test(timeout = 4000)
  public void test64()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("kernelMatrix.matrix");
      FileSystemHandling.createFolder(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      MockFile mockFile0 = new MockFile((String) null, "VemSB;Z_W^B<>U:fU");
      naiveBayesMultinomialText0.setStopwords(file0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 65
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test65()  throws Throwable  {
      double[] doubleArray0 = new double[1];
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      DenseInstance denseInstance0 = new DenseInstance(sparseInstance0);
      int[] intArray0 = new int[7];
      intArray0[0] = 1;
      intArray0[1] = 1;
      intArray0[2] = (-980);
      intArray0[3] = 1;
      intArray0[4] = 1;
      binarySparseInstance0.isMissing(1747);
      intArray0[5] = 1;
      intArray0[6] = 1;
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(0.0, intArray0, 2762);
      try { 
        naiveBayesMultinomialText0.updateClassifier(binarySparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 66
  /*Coverage entropy=2.8059494252188184
  */
  @Test(timeout = 4000)
  public void test66()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.reset();
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      
      String[] stringArray0 = new String[3];
      stringArray0[0] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[1] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[2] = "";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      String string1 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string1);
      
      String string2 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string2);
      
      String string3 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string3);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 67
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test67()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = (NaiveBayesMultinomialText)AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.debugTipText();
      naiveBayesMultinomialText1.setMinWordFrequency(3.0);
      boolean boolean0 = naiveBayesMultinomialText1.getUseWordFrequencies();
      assertFalse(boolean0);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
      
      Instances instances0 = naiveBayesMultinomialText1.m_data;
      KDTree kDTree0 = new KDTree((Instances) null);
      NaiveBayes naiveBayes0 = new NaiveBayes();
      naiveBayes0.getTechnicalInformation();
      NormalEstimator normalEstimator0 = new NormalEstimator((-1398.045103));
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.listOptions();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }
}
