/*
 * This file was automatically generated by EvoSuite
 * Fri Nov 15 15:55:35 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.Locale;
import java.util.Vector;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.Classifier;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.bayes.net.BIFReader;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.VotedPerceptron;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.functions.supportVector.StringKernel;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.meta.FilteredClassifier;
import weka.classifiers.meta.Stacking;
import weka.classifiers.rules.PART;
import weka.classifiers.rules.ZeroR;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.FindWithCapabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SelectedTag;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.neighboursearch.BallTree;
import weka.core.neighboursearch.LinearNNSearch;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.core.stemmers.LovinsStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.NGramTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.9039562017677047
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      naiveBayesMultinomialText0.getOptions();
      SGDText sGDText0 = new SGDText();
      VotedPerceptron votedPerceptron1 = new VotedPerceptron();
      sGDText0.setMinWordFrequency((-2106.2561));
      votedPerceptron1.setExponent(1);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.m_lowercaseTokens = true;
      naiveBayesMultinomialText1.setPeriodicPruning(8);
      VotedPerceptron votedPerceptron2 = new VotedPerceptron();
      votedPerceptron0.setDebug(false);
      votedPerceptron2.globalInfo();
      votedPerceptron0.setExponent(10.0);
      VotedPerceptron votedPerceptron3 = new VotedPerceptron();
      votedPerceptron2.setExponent(10.0);
      VotedPerceptron votedPerceptron4 = new VotedPerceptron();
      votedPerceptron1.setSeed((-835));
      Capabilities capabilities0 = naiveBayesMultinomialText1.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      naiveBayesMultinomialText1.buildClassifier(instances0);
      naiveBayesMultinomialText1.toString();
      assertTrue(naiveBayesMultinomialText1.getLowercaseTokens());
      
      System.setCurrentTimeMillis(1281L);
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.stemmerTipText();
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
  }

  /**
  //Test case number: 1
  /*Coverage entropy=2.0800261477282183
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "ym:q)6";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.setPeriodicPruning(1);
      MockFile mockFile0 = new MockFile("ym:q)6");
      mockFile0.getAbsoluteFile();
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.listOptions();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.0669185826236203
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      AbstractClassifier.makeCopies(costSensitiveClassifier0, 1);
      costSensitiveClassifier0.setDebug(false);
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.listOptions();
      precomputedKernelMatrixKernel0.setDebug(false);
      FilteredClassifier filteredClassifier1 = new FilteredClassifier();
      naiveBayesMultinomialText0.m_periodicP = 2;
      costSensitiveClassifier0.getOnDemandDirectory();
      SelectedTag selectedTag0 = new SelectedTag(1, costSensitiveClassifier0.TAGS_MATRIX_SOURCE);
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText1.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      
      System.setCurrentTimeMillis(0L);
      double double0 = naiveBayesMultinomialText1.getMinWordFrequency();
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertEquals(3.0, double0, 0.01);
  }

  /**
  //Test case number: 3
  /*Coverage entropy=2.1290003949677563
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      nGramTokenizer0.tokenize("t/SEj1~`(V1AeNs");
      String[] stringArray0 = new String[4];
      stringArray0[0] = "t/SEj1~`(V1AeNs";
      stringArray0[1] = "t/SEj1~`(V1AeNs";
      stringArray0[2] = "t/SEj1~`(V1AeNs";
      stringArray0[3] = "t/SEj1~`(V1AeNs";
      Tokenizer.runTokenizer(nGramTokenizer0, stringArray0);
      boolean boolean0 = true;
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      naiveBayesMultinomialText0.getLowercaseTokens();
      Random.setNextRandom((-201));
      naiveBayesMultinomialText0.getLNorm();
      Instance instance0 = null;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.2729977307421736
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumRelationalNumeric(1722);
      Instances instances0 = testInstances0.generate(">0?HRlOG<},jiJI");
      DenseInstance denseInstance0 = new DenseInstance(879);
      instances0.add((Instance) denseInstance0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      int int0 = (-4371);
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance((-4371), doubleArray0);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      SparseInstance sparseInstance2 = new SparseInstance(sparseInstance1);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance2);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance2);
      binarySparseInstance2.setWeight((-2));
      naiveBayesMultinomialText0.distributionForInstance(sparseInstance1);
      TestInstances testInstances1 = new TestInstances();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      Vector<String> vector0 = findWithCapabilities0.getMisses();
      Attribute attribute0 = new Attribute("weka.classifiers.bayes.NaiveBayesMultinomialText", vector0, 16);
      // Undeclared exception!
      try { 
        sparseInstance0.relationalValue(attribute0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Attribute isn't relation-valued!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=2.064323711975847
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      MockFile mockFile0 = (MockFile)naiveBayesMultinomialText0.m_stopwordsFile;
      costSensitiveClassifier0.setDebug(true);
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      AbstractClassifier.makeCopy(filteredClassifier0);
      costSensitiveClassifier0.setOnDemandDirectory(mockFile0);
      costSensitiveClassifier0.getOnDemandDirectory();
      SelectedTag selectedTag0 = new SelectedTag(1, costSensitiveClassifier0.TAGS_MATRIX_SOURCE);
      String[] stringArray0 = new String[3];
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      TestInstances testInstances0 = new TestInstances();
      naiveBayesMultinomialText0.m_normalize = true;
      testInstances0.setNumRelationalNominalValues(240);
      Instances instances0 = testInstances0.generate((String) null);
      int[] intArray0 = new int[7];
      intArray0[0] = 1;
      intArray0[1] = 240;
      intArray0[2] = 2;
      intArray0[3] = 240;
      intArray0[4] = 240;
      intArray0[5] = (-2113);
      intArray0[6] = 1;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1), intArray0, 1840700269);
      instances0.add((Instance) binarySparseInstance0);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 2, Size: 2
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=2.6709087878625355
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, true);
      naiveBayesMultinomialText0.setNorm((-24.549297343068));
      SystemInUtil.addInputLine("");
      naiveBayesMultinomialText0.getNorm();
      AbstractClassifier.makeCopies(naiveBayesMultinomialText0, 65);
      naiveBayesMultinomialText0.getStopwords();
      Random.setNextRandom(1461);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getRevision();
      assertEquals((-24.549297343068), naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 7
  /*Coverage entropy=3.047707978151193
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_periodicP = 365;
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "\":/X'dL");
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.m_periodicP = (-805);
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.setNorm((-3632.4));
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.getNorm();
      BIFReader bIFReader0 = new BIFReader();
      Instances instances0 = bIFReader0.m_Instances;
      LinearNNSearch linearNNSearch0 = new LinearNNSearch((Instances) null);
      BallTree ballTree0 = new BallTree();
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (double) (-805);
      doubleArray0[1] = (-3632.4);
      doubleArray0[2] = 3.0;
      int[] intArray0 = new int[7];
      intArray0[0] = (-805);
      intArray0[1] = (-805);
      intArray0[2] = 365;
      intArray0[3] = (-805);
      intArray0[4] = 365;
      intArray0[5] = (-805);
      intArray0[6] = (-805);
      SparseInstance sparseInstance0 = new SparseInstance((-805), doubleArray0, intArray0, (-1334));
      try { 
        ballTree0.nearestNeighbour(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.BallTree", e);
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("", arrayList0, 5);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: No attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.185851463196929
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      costSensitiveClassifier0.setDebug(true);
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.getOptions();
      precomputedKernelMatrixKernel0.setDebug(true);
      precomputedKernelMatrixKernel0.getKernelMatrixFile();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.generate("-tokenizer");
      costSensitiveClassifier0.setOptions(testInstances0.DEFAULT_WORDS);
      String[] stringArray0 = new String[9];
      stringArray0[0] = "@relation";
      stringArray0[1] = "";
      stringArray0[2] = "@relation";
      stringArray0[3] = "-tokenizer";
      stringArray0[4] = ".bsi";
      stringArray0[5] = "@relation";
      stringArray0[6] = "";
      stringArray0[7] = ".bsi";
      costSensitiveClassifier0.costMatrixSourceTipText();
      stringArray0[8] = "";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: ClassNotFoundException");
      
      } catch(ClassNotFoundException e) {
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=2.2536550811500584
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(">0?HRlOG<},jiJI");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      double[] doubleArray0 = new double[0];
      int[] intArray0 = new int[2];
      intArray0[0] = (-4371);
      intArray0[1] = (-1);
      SparseInstance sparseInstance0 = new SparseInstance(3961.0502044, doubleArray0, intArray0, (-1647));
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      testInstances0.setRelationalClassFormat(instances0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((Instance) binarySparseInstance1);
      instances0.delete();
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      binarySparseInstance2.setWeight((-247.970574328));
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=2.7084196820813156
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      SGDText sGDText0 = new SGDText();
      sGDText0.setTokenizer(wordTokenizer0);
      SGDText sGDText1 = new SGDText();
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "sx'1DLq$O*y%0D\"!");
      StringKernel stringKernel0 = new StringKernel();
      Capabilities capabilities0 = stringKernel0.getCapabilities();
      naiveBayesMultinomialText0.setUseStopList(true);
      capabilities0.dependencies();
      TestInstances.forCapabilities(capabilities0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.setNumRelationalNominalValues(1);
      naiveBayesMultinomialText0.listOptions();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      stringKernel0.getRevision();
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      Random.setNextRandom(357);
      naiveBayesMultinomialText0.toString();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 12
  /*Coverage entropy=3.1880781490311567
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostSensitiveClassifier costSensitiveClassifier1 = new CostSensitiveClassifier();
      CostSensitiveClassifier costSensitiveClassifier2 = new CostSensitiveClassifier();
      naiveBayesMultinomialText0.m_tokenizer = null;
      Stacking stacking0 = new Stacking();
      Classifier classifier0 = stacking0.getMetaClassifier();
      AbstractClassifier.makeCopies(classifier0, 1);
      costSensitiveClassifier2.setOptions(stringArray0);
      CostSensitiveClassifier costSensitiveClassifier3 = new CostSensitiveClassifier();
      MockFile mockFile0 = new MockFile("The LNorm to use for document length normalization.", "The LNorm to use for document length normalization.");
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("TcD(&WQsTM_]#r[");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.globalInfo();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.getOptions();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=1.9662848511774718
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      VotedPerceptron votedPerceptron1 = new VotedPerceptron();
      votedPerceptron1.setSeed(2720);
      VotedPerceptron votedPerceptron2 = new VotedPerceptron();
      votedPerceptron1.setSeed((-1435));
      VotedPerceptron votedPerceptron3 = new VotedPerceptron();
      votedPerceptron3.getTechnicalInformation();
      votedPerceptron3.setNumIterations(0);
      VotedPerceptron votedPerceptron4 = new VotedPerceptron();
      votedPerceptron3.setExponent((-959));
      VotedPerceptron votedPerceptron5 = new VotedPerceptron();
      votedPerceptron5.globalInfo();
      votedPerceptron5.setExponent(591.1249641705);
      VotedPerceptron votedPerceptron6 = new VotedPerceptron();
      votedPerceptron5.setExponent((-2348.998309));
      VotedPerceptron votedPerceptron7 = new VotedPerceptron();
      votedPerceptron7.setSeed(2720);
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("#^wL4");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.toString();
      System.setCurrentTimeMillis((-1435));
      Random.setNextRandom((-407));
  }

  /**
  //Test case number: 14
  /*Coverage entropy=2.70974955153484
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      SGDText sGDText0 = new SGDText();
      sGDText0.setTokenizer(wordTokenizer0);
      SGDText sGDText1 = new SGDText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props/Capabilities.props");
      FileSystemHandling.setPermissions(evoSuiteFile0, false, false, false);
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/wekafiles");
      FileSystemHandling.appendStringToFile(evoSuiteFile1, "sx'1DLq$O*y%0D\"!");
      StringKernel stringKernel0 = new StringKernel();
      Capabilities capabilities0 = stringKernel0.getCapabilities();
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      testInstances1.setNumRelationalNominalValues(1);
      naiveBayesMultinomialText0.listOptions();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      Instances instances0 = testInstances1.generate("weka/core/Capabilities.props");
      capabilities0.toSource("j)I^VP'd@5I", 0);
      testInstances0.generate("");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(12, stringArray0.length);
  }

  /**
  //Test case number: 15
  /*Coverage entropy=2.4351404426478833
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumRelationalNumeric(1722);
      Instances instances0 = testInstances0.generate(">0?HRlOG<},jiJI");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance((-4371), doubleArray0);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      SparseInstance sparseInstance2 = new SparseInstance(sparseInstance1);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance2);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance2);
      binarySparseInstance2.setWeight((-2));
      naiveBayesMultinomialText0.distributionForInstance(sparseInstance1);
      TestInstances testInstances1 = new TestInstances();
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((Instance) binarySparseInstance0);
      naiveBayesMultinomialText0.setNorm((-2));
      testInstances0.setNumRelationalNominalValues((-1));
      testInstances1.generate((String) null);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.toString();
      assertEquals((-2.0), naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 16
  /*Coverage entropy=2.738840717855686
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.getOptions();
      int[] intArray0 = new int[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1837.103765945), intArray0, 923);
      ArrayList<Locale.LanguageRange> arrayList0 = new ArrayList<Locale.LanguageRange>();
      Locale.LanguageRange locale_LanguageRange0 = null;
      try {
        locale_LanguageRange0 = new Locale.LanguageRange((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.Locale$LanguageRange", e);
      }
  }

  /**
  //Test case number: 17
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      Random.setNextRandom((-2316));
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string0);
      
      String string1 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string1);
      
      naiveBayesMultinomialText0.setStopwords((File) null);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.7204225901862604
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      String[] stringArray0 = new String[1];
      stringArray0[0] = "Classifications\n\n";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = 1.0;
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      doubleArray0[1] = (-1.0E-6);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      SGDText sGDText0 = new SGDText();
      Stemmer stemmer0 = sGDText0.getStemmer();
      naiveBayesMultinomialText0.m_stemmer = stemmer0;
      doubleArray0[2] = 0.0;
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (-2368.07454385097);
      doubleArray0[1] = (-2656.4047);
      doubleArray0[2] = 3441.204132;
      doubleArray0[3] = 4125.612;
      doubleArray0[4] = (-904.45384916004);
      doubleArray0[5] = 5.0;
      doubleArray0[6] = 2.0;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
  }

  /**
  //Test case number: 20
  /*Coverage entropy=3.1946531330062844
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      votedPerceptron0.setSeed(1);
      VotedPerceptron votedPerceptron1 = new VotedPerceptron();
      votedPerceptron1.setSeed((-255));
      VotedPerceptron votedPerceptron2 = new VotedPerceptron();
      VotedPerceptron votedPerceptron3 = new VotedPerceptron();
      votedPerceptron0.setExponent(1);
      VotedPerceptron votedPerceptron4 = new VotedPerceptron();
      votedPerceptron2.setExponent(7.0);
      votedPerceptron4.setExponent(18.0);
      votedPerceptron2.setSeed(1908874353);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1);
      SparseInstance sparseInstance0 = new SparseInstance(12);
      String[] stringArray0 = new String[4];
      stringArray0[0] = "1Rpx";
      stringArray0[1] = "";
      stringArray0[2] = "-stoplist";
      stringArray0[3] = "";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      File file1 = MockFile.createTempFile("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", "", file0);
      naiveBayesMultinomialText0.setStopwords(file1);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 22
  /*Coverage entropy=2.4885433205008853
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      wordTokenizer0.getOptions();
      SGDText sGDText0 = new SGDText();
      sGDText0.setTokenizer(wordTokenizer0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props/Capabilities.props");
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/wekafiles");
      byte[] byteArray0 = new byte[7];
      byteArray0[0] = (byte)16;
      byteArray0[1] = (byte)4;
      byteArray0[2] = (byte)3;
      byteArray0[3] = (byte)120;
      byteArray0[4] = (byte)117;
      byteArray0[5] = (byte)92;
      byteArray0[6] = (byte) (-40);
      FileSystemHandling.appendDataToFile(evoSuiteFile1, byteArray0);
      FileSystemHandling.setPermissions(evoSuiteFile0, false, false, false);
      byte[] byteArray1 = new byte[6];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      EvoSuiteFile evoSuiteFile2 = new EvoSuiteFile("/home/ubuntu/wekafiles");
      FileSystemHandling.appendStringToFile(evoSuiteFile2, "sx'1DLq$O*y%0D\"!");
      StringKernel stringKernel0 = new StringKernel();
      Capabilities capabilities0 = stringKernel0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.setNumRelationalNominalValues(1);
      WordTokenizer wordTokenizer1 = new WordTokenizer();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      capabilities0.toSource("org.tartarus.snowball", 1);
      MockFile mockFile0 = new MockFile("org.tartarus.snowball.ext", "org.tartarus.snowball.ext");
      File file0 = MockFile.createTempFile("@data", "org.tartarus.snowball", (File) mockFile0);
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      File file1 = MockFile.createTempFile("org.tartarus.snowball", " ", (File) mockFile0);
      file0.renameTo(file1);
      file0.setReadable(true, false);
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      
      naiveBayesMultinomialText0.setOptions(testInstances0.DEFAULT_WORDS);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 23
  /*Coverage entropy=2.230330547328481
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "l3D!W'3:YB,x(";
      stringArray0[1] = "Nom";
      stringArray0[2] = "l3D!W'3:YB,x(";
      naiveBayesMultinomialText0.reset();
      stringArray0[3] = "value of sigma must be > 0!";
      stringArray0[4] = "Whether to convert all tokens to lowercase";
      stringArray0[5] = "o>~Wa(hO7D8Bo;4<.1";
      stringArray0[6] = "";
      stringArray0[7] = "#M[='29>/i lco>$x";
      stringArray0[8] = ">0?HRlOG<},jiJI";
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("E\"LHa_\"\" b");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (double) (-1);
      int[] intArray0 = new int[4];
      intArray0[0] = (-1);
      intArray0[1] = (-2);
      intArray0[2] = (-1);
      intArray0[3] = (-2);
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0, intArray0, (-2));
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      binarySparseInstance0.setWeight((-2));
      double[] doubleArray1 = naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
      assertArrayEquals(new double[] {0.5454545454545454, 0.4545454545454546}, doubleArray1, 0.01);
      
      Random.setNextRandom((-2));
      naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, false);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.368373327680306
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1753);
      SparseInstance sparseInstance0 = new SparseInstance(1753);
      naiveBayesMultinomialText0.toString();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[1] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[2] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[3] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[4] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[5] = "NaiveBayesMultinomialText: No model built yet.\n";
      stringArray0[6] = "NaiveBayesMultinomialText: No model built yet.\n";
      costSensitiveClassifier0.getCostMatrixSource();
      stringArray0[7] = "-tokenizer";
      costSensitiveClassifier0.setOptions(stringArray0);
      costSensitiveClassifier0.getOnDemandDirectory();
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      SparseInstance sparseInstance1 = new SparseInstance(350);
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No value given for -tokenizer option.
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNoClass(true);
      Instances instances0 = testInstances0.generate(">0?HRlOG<},jiJI");
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Class attribute not set!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[0];
      int[] intArray0 = new int[2];
      intArray0[0] = (-4371);
      SparseInstance sparseInstance0 = new SparseInstance(3961.0502044, doubleArray0, intArray0, (-1647));
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      binarySparseInstance1.setWeight((-247.970574328));
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.getUseStopList();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (-99.0);
      doubleArray0[1] = (-99.0);
      doubleArray0[2] = (-99.0);
      doubleArray0[3] = (-99.0);
      doubleArray0[4] = (-99.0);
      SparseInstance sparseInstance0 = new SparseInstance((-99.0), doubleArray0);
      // Undeclared exception!
      try { 
        sparseInstance0.setClassMissing();
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=2.9632179853406906
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      naiveBayesMultinomialText0.getOptions();
      SGDText sGDText0 = new SGDText();
      VotedPerceptron votedPerceptron1 = new VotedPerceptron();
      votedPerceptron0.setSeed(0);
      VotedPerceptron votedPerceptron2 = new VotedPerceptron();
      VotedPerceptron votedPerceptron3 = new VotedPerceptron();
      votedPerceptron0.setExponent(0);
      votedPerceptron3.setExponent(0);
      VotedPerceptron votedPerceptron4 = new VotedPerceptron();
      votedPerceptron4.setExponent(2.0);
      votedPerceptron2.setSeed(0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(4);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[6];
      stringArray0[0] = " o ";
      stringArray0[1] = "";
      stringArray0[2] = "-norm";
      stringArray0[3] = " - ";
      stringArray0[4] = "";
      stringArray0[5] = "";
      try { 
        naiveBayesMultinomialText1.setOptions(stringArray0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      MockFile mockFile0 = (MockFile)naiveBayesMultinomialText0.m_stopwordsFile;
      costSensitiveClassifier0.setDebug(true);
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.setDebug(true);
      precomputedKernelMatrixKernel0.getKernelMatrixFile();
      FilteredClassifier filteredClassifier1 = new FilteredClassifier();
      costSensitiveClassifier0.setOnDemandDirectory(mockFile0);
      naiveBayesMultinomialText0.m_periodicP = 1;
      naiveBayesMultinomialText0.m_t = (double) 2;
      costSensitiveClassifier0.getOnDemandDirectory();
      SelectedTag selectedTag0 = new SelectedTag(1, costSensitiveClassifier0.TAGS_MATRIX_SOURCE);
      String[] stringArray0 = new String[3];
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("edu");
      DenseInstance denseInstance0 = new DenseInstance(1);
      instances0.set(18, (Instance) denseInstance0);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=1.9296217656001493
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_wordFrequencies = false;
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.m_lnorm = (double) 0;
      naiveBayesMultinomialText0.m_periodicP = 0;
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      Random.setNextRandom(321);
      Random.setNextRandom(321);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 31
  /*Coverage entropy=1.9296217656001493
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      MockFile mockFile0 = new MockFile("");
      mockFile0.setWritable(true, false);
      naiveBayesMultinomialText0.setPeriodicPruning(1);
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.getCapabilities();
      assertEquals(1, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 32
  /*Coverage entropy=3.554034413448894
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostSensitiveClassifier costSensitiveClassifier1 = new CostSensitiveClassifier();
      CostSensitiveClassifier costSensitiveClassifier2 = new CostSensitiveClassifier();
      Stacking stacking0 = new Stacking();
      Classifier classifier0 = stacking0.getMetaClassifier();
      AbstractClassifier.makeCopies(classifier0, 1);
      costSensitiveClassifier2.setOptions(stringArray0);
      naiveBayesMultinomialText0.m_t = (double) 1;
      CostSensitiveClassifier costSensitiveClassifier3 = new CostSensitiveClassifier();
      costSensitiveClassifier3.getOnDemandDirectory();
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      SparseInstance sparseInstance0 = new SparseInstance(19);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      try { 
        naiveBayesMultinomialText0.updateClassifier(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 33
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setMultiInstance(true);
      testInstances0.setNumRelationalNumeric(1722);
      Instances instances0 = testInstances0.generate(">0?HRlOG<},jiJI");
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Cannot handle relational attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 34
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      AbstractClassifier.makeCopy(filteredClassifier0);
      costSensitiveClassifier0.getOnDemandDirectory();
      SelectedTag selectedTag0 = new SelectedTag(1, costSensitiveClassifier0.TAGS_MATRIX_SOURCE);
      boolean boolean0 = naiveBayesMultinomialText0.getNormalizeDocLength();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(boolean0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 35
  /*Coverage entropy=2.0642222749513333
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.setDebug(true);
      precomputedKernelMatrixKernel0.getKernelMatrixFile();
      FilteredClassifier filteredClassifier1 = new FilteredClassifier();
      TestInstances testInstances0 = new TestInstances();
      naiveBayesMultinomialText0.m_normalize = true;
      testInstances0.setNumRelationalNominalValues(1932735283);
      Instances instances0 = testInstances0.generate("");
      LinkedList<Integer> linkedList0 = new LinkedList<Integer>();
      instances0.removeAll(linkedList0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 36
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      SGDText sGDText0 = new SGDText();
      VotedPerceptron votedPerceptron1 = new VotedPerceptron();
      votedPerceptron0.setSeed(0);
      VotedPerceptron votedPerceptron2 = new VotedPerceptron();
      VotedPerceptron votedPerceptron3 = new VotedPerceptron();
      votedPerceptron0.setExponent(0);
      VotedPerceptron votedPerceptron4 = new VotedPerceptron();
      votedPerceptron3.setExponent(534.98);
      VotedPerceptron votedPerceptron5 = new VotedPerceptron();
      votedPerceptron5.setExponent((-1.0));
      votedPerceptron3.setSeed(0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 37
  /*Coverage entropy=2.4674826682400175
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      wordTokenizer0.getOptions();
      SGDText sGDText0 = new SGDText();
      sGDText0.setTokenizer(wordTokenizer0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props/Capabilities.props");
      FileSystemHandling.setPermissions(evoSuiteFile0, false, false, false);
      byte[] byteArray0 = new byte[6];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/wekafiles");
      FileSystemHandling.appendStringToFile(evoSuiteFile1, "sx'1DLq$O*y%0D\"!");
      StringKernel stringKernel0 = new StringKernel();
      Capabilities capabilities0 = stringKernel0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.setNumRelationalNominalValues(1);
      WordTokenizer wordTokenizer1 = new WordTokenizer();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      capabilities0.toSource("org.tartarus.snowball", 1);
      MockFile mockFile0 = new MockFile("org.tartarus.snowball.ext", "org.tartarus.snowball.ext");
      File file0 = MockFile.createTempFile("@data", "org.tartarus.snowball", (File) mockFile0);
      FileSystemHandling fileSystemHandling1 = new FileSystemHandling();
      File file1 = MockFile.createTempFile("org.tartarus.snowball", " ", (File) mockFile0);
      file0.renameTo(file1);
      capabilities0.enableAllClassDependencies();
      file0.setReadable(false, false);
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      
      naiveBayesMultinomialText0.setOptions(testInstances0.DEFAULT_WORDS);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 38
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      VotedPerceptron votedPerceptron1 = new VotedPerceptron();
      votedPerceptron1.setSeed(2720);
      VotedPerceptron votedPerceptron2 = new VotedPerceptron();
      VotedPerceptron votedPerceptron3 = new VotedPerceptron();
      VotedPerceptron votedPerceptron4 = new VotedPerceptron();
      VotedPerceptron votedPerceptron5 = new VotedPerceptron();
      VotedPerceptron votedPerceptron6 = new VotedPerceptron();
      votedPerceptron1.setExponent(2720);
      String[] stringArray0 = new String[3];
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "tokenizer");
      VotedPerceptron votedPerceptron7 = new VotedPerceptron();
      votedPerceptron7.setNumIterations(2720);
      VotedPerceptron votedPerceptron8 = new VotedPerceptron();
      votedPerceptron7.setExponent((-1.0));
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 39
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      PART pART0 = new PART();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "Fabio Cozman and Marek Druzdzel and Daniel Garcia";
      stringArray0[1] = "Fabio Cozman and Marek Druzdzel and Daniel Garcia";
      stringArray0[2] = "";
      AbstractClassifier.runClassifier(pART0, stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int int0 = naiveBayesMultinomialText0.getPeriodicPruning();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(0, int0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 40
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      AbstractClassifier.makeCopies(costSensitiveClassifier0, 1);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance2);
      binarySparseInstance1.setWeight((-2458.457384861633));
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 41
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "l3D!W'3:YB,x(";
      stringArray0[1] = "l3D!W'3:YB,x(";
      stringArray0[2] = "/F7H/Fv)VOW4~KCNTjL";
      stringArray0[3] = "value of sigma must be > 0!";
      stringArray0[4] = ":ru+";
      stringArray0[5] = "o>~Wa(hO7D8Bo;4<.1";
      stringArray0[6] = "";
      stringArray0[7] = "#M[='29>/i lco>$x";
      stringArray0[8] = ">0?HRlOG<},jiJI";
      TestInstances testInstances0 = new TestInstances();
      testInstances0.getWords();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (-2);
      doubleArray0[1] = (double) (-2);
      doubleArray0[2] = 0.0;
      doubleArray0[3] = (double) (-2);
      doubleArray0[4] = 1229.1022025118534;
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) sparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 42
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 43
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance((-4371), doubleArray0);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      SparseInstance sparseInstance2 = new SparseInstance(sparseInstance1);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance2);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(sparseInstance2);
      binarySparseInstance2.setWeight((-2));
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 44
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1749);
      SparseInstance sparseInstance0 = new SparseInstance(2980);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("%");
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 45
  /*Coverage entropy=3.392306624162426
  */
  @Test(timeout = 4000)
  public void test45()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.setPeriodicPruning((-1390));
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "";
      stringArray0[1] = "";
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.m_norm = (-416.732413);
      stringArray0[2] = "";
      AbstractClassifier.makeCopies(naiveBayesMultinomialText0, 288);
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.m_lnorm = 1249.0;
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.pruneDictionary();
      assertEquals(1249.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 46
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test46()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 549.31;
      doubleArray0[1] = (-946.536214878);
      doubleArray0[2] = 1385.4434501196536;
      doubleArray0[3] = 0.0;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.listOptions();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertTrue(boolean0);
  }

  /**
  //Test case number: 47
  /*Coverage entropy=2.900015079480596
  */
  @Test(timeout = 4000)
  public void test47()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.stemmerTipText();
      SparseInstance sparseInstance0 = null;
      try {
        sparseInstance0 = new SparseInstance((SparseInstance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.SparseInstance", e);
      }
  }

  /**
  //Test case number: 48
  /*Coverage entropy=2.0557051606564785
  */
  @Test(timeout = 4000)
  public void test48()  throws Throwable  {
      SystemInUtil.addInputLine("{}Yy]QwFGI=?Fe:aMu");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      boolean boolean0 = true;
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.setStopwords((File) null);
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 20.0;
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, true, true);
      doubleArray0[1] = 20.0;
      doubleArray0[2] = 17.0;
      doubleArray0[3] = 20.0;
      SparseInstance sparseInstance0 = new SparseInstance(20.0, doubleArray0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(sparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 49
  /*Coverage entropy=2.4267173502315558
  */
  @Test(timeout = 4000)
  public void test49()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      MockFile mockFile0 = (MockFile)naiveBayesMultinomialText0.m_stopwordsFile;
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      AbstractClassifier.makeCopy(filteredClassifier0);
      costSensitiveClassifier0.setOnDemandDirectory(mockFile0);
      costSensitiveClassifier0.getOnDemandDirectory();
      SelectedTag selectedTag0 = new SelectedTag(1, costSensitiveClassifier0.TAGS_MATRIX_SOURCE);
      String[] stringArray0 = new String[3];
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      TestInstances testInstances0 = new TestInstances();
      naiveBayesMultinomialText0.m_normalize = true;
      testInstances0.setNumRelationalNominalValues(240);
      testInstances0.generate((String) null);
      naiveBayesMultinomialText0.setOptions(testInstances0.DEFAULT_WORDS);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 50
  /*Coverage entropy=2.7825850929940454
  */
  @Test(timeout = 4000)
  public void test50()  throws Throwable  {
      SystemInUtil.addInputLine("a{{<AY+WyYPtA]@_BF");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      naiveBayesMultinomialText0.m_minWordP = (-2059.689338);
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) nGramTokenizer0;
      naiveBayesMultinomialText0.setLNorm(549.5927241752584);
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      nGramTokenizer0.nextElement();
      naiveBayesMultinomialText0.getNorm();
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      nGramTokenizer0.nextElement();
      nGramTokenizer0.setNGramMaxSize((-758));
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.tokenizerTipText();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[1] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[2] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[3] = "The tokenizing algorithm to use on the strings.";
      stringArray0[4] = "a{{<AY+WyYPtA]@_BF";
      stringArray0[5] = "The tokenizing algorithm to use on the strings.";
      stringArray0[6] = "The tokenizing algorithm to use on the strings.";
      stringArray0[7] = "a{{<AY+WyYPtA]@_BF";
      Tokenizer.tokenize((Tokenizer) nGramTokenizer0, stringArray0);
      String[] stringArray1 = new String[2];
      stringArray1[0] = "The tokenizing algorithm to use on the strings.";
      stringArray1[1] = "a{{<AY+WyYPtA]@_BF";
      Tokenizer.runTokenizer(nGramTokenizer0, stringArray1);
      nGramTokenizer0.setNGramMaxSize(0);
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals(549.5927241752584, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 51
  /*Coverage entropy=3.4395082641515833
  */
  @Test(timeout = 4000)
  public void test51()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.periodicPruningTipText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostSensitiveClassifier costSensitiveClassifier1 = new CostSensitiveClassifier();
      CostSensitiveClassifier costSensitiveClassifier2 = new CostSensitiveClassifier();
      costSensitiveClassifier2.setOptions(stringArray0);
      CostSensitiveClassifier costSensitiveClassifier3 = new CostSensitiveClassifier();
      costSensitiveClassifier3.getOnDemandDirectory();
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      SparseInstance sparseInstance0 = new SparseInstance(19);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 52
  /*Coverage entropy=3.281646677047623
  */
  @Test(timeout = 4000)
  public void test52()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.setNorm(1.0E-8);
      naiveBayesMultinomialText0.stopwordsTipText();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "WRYyIn");
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.globalInfo();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[1] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[2] = "Use word frequencies rather than binary bag of words representation";
      stringArray0[3] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[4] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[5] = "The file containing the stopwords (if this is a directory then the default ones are used).";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      LovinsStemmer lovinsStemmer0 = new LovinsStemmer();
      naiveBayesMultinomialText0.setStemmer(lovinsStemmer0);
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 53
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test53()  throws Throwable  {
      String[] stringArray0 = new String[5];
      ZeroR zeroR0 = new ZeroR();
      AbstractClassifier.runClassifier(zeroR0, stringArray0);
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "normalize";
      stringArray0[3] = "";
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      stringArray0[4] = "";
      NaiveBayesMultinomialText.main(stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("The norm of the instances after normalization.", string0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 54
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test54()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[1] = (-946.536214878);
      doubleArray0[2] = 1385.4434501196536;
      doubleArray0[3] = 0.0;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.listOptions();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertTrue(boolean0);
  }

  /**
  //Test case number: 55
  /*Coverage entropy=2.2302982632284003
  */
  @Test(timeout = 4000)
  public void test55()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNumRelationalNumeric(1722);
      Instances instances0 = testInstances0.generate(">0?HRlOG<},jiJI");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance((-4371), doubleArray0);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      naiveBayesMultinomialText0.pruneDictionary();
      SparseInstance sparseInstance2 = new SparseInstance(sparseInstance1);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance2);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(sparseInstance2);
      binarySparseInstance1.setWeight((-2));
      naiveBayesMultinomialText0.distributionForInstance(sparseInstance1);
      TestInstances testInstances1 = new TestInstances();
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((Instance) binarySparseInstance0);
      // Undeclared exception!
      try { 
        binarySparseInstance2.insertAttributeAt((-4371));
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Can't insert attribute: index out of range
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 56
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test56()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-h|-help\n\tprints this help\n";
      stringArray0[1] = "/4u";
      Tokenizer.runTokenizer(tokenizer0, stringArray0);
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      naiveBayesMultinomialText0.getLowercaseTokens();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 57
  /*Coverage entropy=2.8077927431911682
  */
  @Test(timeout = 4000)
  public void test57()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = (-2992.460145);
      naiveBayesMultinomialText0.setPeriodicPruning(120);
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.m_normalize = false;
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.m_minWordP = 0.0;
      naiveBayesMultinomialText0.getUseWordFrequencies();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      String[] stringArray0 = new String[0];
      nGramTokenizer0.setDelimiters("4b");
      nGramTokenizer0.setOptions(stringArray0);
      NGramTokenizer.main(stringArray0);
      naiveBayesMultinomialText0.m_minWordP = (-2992.460145);
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      naiveBayesMultinomialText0.getUseWordFrequencies();
      NGramTokenizer nGramTokenizer1 = (NGramTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      nGramTokenizer1.getOptions();
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer1);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.periodicPruningTipText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 58
  /*Coverage entropy=3.4395082641515833
  */
  @Test(timeout = 4000)
  public void test58()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
      
      String string1 = naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string1);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostSensitiveClassifier costSensitiveClassifier1 = new CostSensitiveClassifier();
      CostSensitiveClassifier costSensitiveClassifier2 = new CostSensitiveClassifier();
      costSensitiveClassifier2.setOptions(stringArray0);
      CostSensitiveClassifier costSensitiveClassifier3 = new CostSensitiveClassifier();
      costSensitiveClassifier3.getOnDemandDirectory();
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      naiveBayesMultinomialText0.m_leplace = 490.089844;
      SparseInstance sparseInstance0 = new SparseInstance(19);
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(12, stringArray0.length);
      
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      String string2 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string2);
      
      String string3 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string3);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 59
  /*Coverage entropy=2.2584261358947213
  */
  @Test(timeout = 4000)
  public void test59()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      File file0 = costSensitiveClassifier0.getOnDemandDirectory();
      costSensitiveClassifier0.getCostMatrixSource();
      naiveBayesMultinomialText0.m_stopwordsFile = file0;
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.setMinWordFrequency(2);
      naiveBayesMultinomialText0.LNormTipText();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      Instances instances0 = naiveBayesMultinomialText0.m_data;
      // Undeclared exception!
      try { 
        BallNode.calcCentroidPivot((int[]) null, (Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.balltrees.BallNode", e);
      }
  }

  /**
  //Test case number: 60
  /*Coverage entropy=3.269394275120508
  */
  @Test(timeout = 4000)
  public void test60()  throws Throwable  {
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      VotedPerceptron votedPerceptron1 = new VotedPerceptron();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      VotedPerceptron votedPerceptron2 = new VotedPerceptron();
      VotedPerceptron votedPerceptron3 = new VotedPerceptron();
      VotedPerceptron votedPerceptron4 = new VotedPerceptron();
      VotedPerceptron votedPerceptron5 = new VotedPerceptron();
      VotedPerceptron votedPerceptron6 = new VotedPerceptron();
      votedPerceptron6.setExponent((-1.0));
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 61
  /*Coverage entropy=2.8048370781665377
  */
  @Test(timeout = 4000)
  public void test61()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      boolean boolean0 = naiveBayesMultinomialText0.m_normalize;
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      MockFile mockFile0 = (MockFile)naiveBayesMultinomialText0.m_stopwordsFile;
      costSensitiveClassifier0.setOnDemandDirectory(mockFile0);
      costSensitiveClassifier0.getOnDemandDirectory();
      costSensitiveClassifier0.getCostMatrixSource();
      String[] stringArray0 = new String[3];
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      TestInstances testInstances0 = new TestInstances();
      costSensitiveClassifier0.setOptions(testInstances0.DEFAULT_WORDS);
      CostSensitiveClassifier costSensitiveClassifier1 = new CostSensitiveClassifier();
      costSensitiveClassifier1.getOnDemandDirectory();
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      SparseInstance sparseInstance0 = new SparseInstance(1);
      naiveBayesMultinomialText0.setOptions(testInstances0.DEFAULT_WORDS);
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      
      String string1 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string1);
      
      String string2 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string2);
      
      String string3 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", string3);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }
}
