/*
 * This file was automatically generated by EvoSuite
 * Fri Nov 15 10:23:01 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.BufferedReader;
import java.io.File;
import java.io.StringReader;
import java.util.LinkedHashMap;
import java.util.Locale;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.attributeSelection.PrincipalComponents;
import weka.attributeSelection.WrapperSubsetEval;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.supportVector.NormalizedPolyKernel;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.misc.InputMappedClassifier;
import weka.core.AbstractInstance;
import weka.core.AllJavadoc;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.ChebyshevDistance;
import weka.core.CheckGOE;
import weka.core.DenseInstance;
import weka.core.EuclideanDistance;
import weka.core.FindWithCapabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.OptionHandlerJavadoc;
import weka.core.SparseInstance;
import weka.core.Stopwords;
import weka.core.TestInstances;
import weka.core.neighboursearch.KDTree;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.AlphabeticTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.filters.AllFilter;
import weka.filters.MultiFilter;
import weka.filters.supervised.attribute.Discretize;
import weka.filters.unsupervised.attribute.ReplaceMissingValues;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("8.7iT(vp8-v@fO%n:");
      DenseInstance denseInstance0 = new DenseInstance(0);
      instances0.add((Instance) denseInstance0);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=2.7746000829682944
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      TestInstances.main((String[]) null);
      NormalizedPolyKernel normalizedPolyKernel0 = new NormalizedPolyKernel();
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = sGDText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("stopwords");
      NullStemmer nullStemmer0 = new NullStemmer();
      ChebyshevDistance chebyshevDistance0 = new ChebyshevDistance(instances0);
      naiveBayesMultinomialText0.setTokenizer((Tokenizer) null);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.getOptions();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 2
  /*Coverage entropy=3.548493600576855
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.periodicPruningTipText();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      System.setCurrentTimeMillis(0L);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      FileSystemHandling.shouldAllThrowIOExceptions();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      Discretize discretize0 = new Discretize();
      // Undeclared exception!
      try { 
        discretize0.getOutputFormat();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // No output format defined.
         //
         verifyException("weka.filters.Filter", e);
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=2.228562068367228
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      
      naiveBayesMultinomialText0.stopwordsTipText();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 938.5;
      doubleArray0[2] = (-2612.9533827);
      doubleArray0[4] = (-1228.3429351503462);
      NormalizedPolyKernel normalizedPolyKernel0 = new NormalizedPolyKernel();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      capabilities0.enableAll();
      Instances instances0 = testInstances0.generate("");
      NullStemmer nullStemmer0 = new NullStemmer();
      ChebyshevDistance chebyshevDistance0 = new ChebyshevDistance(instances0);
      instances0.remove((Object) chebyshevDistance0);
      Capabilities.forInstances(instances0);
      TestInstances.main(testInstances0.DEFAULT_WORDS);
      Instances instances1 = testInstances0.generate("");
      NullStemmer nullStemmer1 = new NullStemmer();
      LinkedHashMap<CheckGOE, AllJavadoc> linkedHashMap0 = new LinkedHashMap<CheckGOE, AllJavadoc>();
      instances1.remove((Object) "");
      instances0.removeAll(instances1);
      testInstances0.setNumRelationalNominalValues((-3423));
      testInstances0.setNumNumeric(876);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      String string1 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string1);
      
      naiveBayesMultinomialText0.normTipText();
      String string2 = naiveBayesMultinomialText0.toString();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("The independent probability of a class\n--------------------------------------\nclass1\t9.0\nclass2\t4.0\nclass3\t7.0\nclass4\t4.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\tclass3\tclass4\t\nover\t2.718281828459045\t2.718281828459045\t7.38905609893065\t7.38905609893065\t\nthe\t7.38905609893065\t7.38905609893065\t2.718281828459045\t2.718281828459045\t\nThe\t7.38905609893065\t2.718281828459045\t7.38905609893065\t2.718281828459045\t\nquick\t7.38905609893065\t2.718281828459045\t7.38905609893065\t7.38905609893065\t\nlazy\t7.38905609893065\t2.718281828459045\t7.38905609893065\t2.718281828459045\t\njumps\t20.085536923187668\t7.38905609893065\t2.718281828459045\t2.718281828459045\t\nbrown\t7.38905609893065\t7.38905609893065\t2.718281828459045\t2.718281828459045\t\ndog\t7.38905609893065\t2.718281828459045\t7.38905609893065\t2.718281828459045\t\nfox\t2.718281828459045\t2.718281828459045\t7.38905609893065\t7.38905609893065\t\n", string2);
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.2595209449767455
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      byte[] byteArray0 = new byte[9];
      byteArray0[0] = (byte) (-104);
      byteArray0[3] = (byte) (-94);
      double[] doubleArray0 = new double[23];
      doubleArray0[0] = (double) (byte) (-94);
      doubleArray0[1] = (double) (byte) (-104);
      doubleArray0[2] = (double) (byte) (-104);
      naiveBayesMultinomialText0.m_leplace = 21.0;
      doubleArray0[3] = 17.0;
      doubleArray0[4] = (double) (byte) (-94);
      doubleArray0[5] = (double) (byte) (-94);
      doubleArray0[6] = (double) (byte) (-104);
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("L]");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      String string0 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string0);
      
      String string1 = naiveBayesMultinomialText0.normTipText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals("The norm of the instances after normalization.", string1);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 5
  /*Coverage entropy=2.614587722538201
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      TestInstances testInstances0 = new TestInstances();
      NullStemmer nullStemmer0 = new NullStemmer();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.setPeriodicPruning(120);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.setNorm(11.0);
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = 497.0974108626;
      doubleArray0[2] = (double) (-2);
      doubleArray0[3] = 497.0974108626;
      doubleArray0[4] = 11.0;
      doubleArray0[5] = (double) (-1);
      doubleArray0[6] = (double) (-2);
      doubleArray0[7] = 17.0;
      SparseInstance sparseInstance0 = new SparseInstance(497.0974108626, doubleArray0);
      try { 
        naiveBayesMultinomialText0.classifyInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=1.9296217656001493
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.setStopwords((File) null);
      System.setCurrentTimeMillis(0L);
      String string0 = naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string0);
      
      String string1 = naiveBayesMultinomialText0.stemmerTipText();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", string1);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 7
  /*Coverage entropy=1.8979130143405207
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 938.5;
      doubleArray0[2] = (-2612.9533827);
      doubleArray0[4] = (-1228.3429351503462);
      NormalizedPolyKernel normalizedPolyKernel0 = new NormalizedPolyKernel();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      capabilities0.enableAll();
      Instances instances0 = testInstances0.generate("");
      NullStemmer nullStemmer0 = new NullStemmer();
      ChebyshevDistance chebyshevDistance0 = new ChebyshevDistance(instances0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(876);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      binarySparseInstance1.setWeight(938.5);
      instances0.add((Instance) binarySparseInstance1);
      instances0.remove((Object) chebyshevDistance0);
      TestInstances.main(testInstances0.DEFAULT_WORDS);
      Instances instances1 = testInstances0.generate("");
      NullStemmer nullStemmer1 = new NullStemmer();
      LinkedHashMap<CheckGOE, AllJavadoc> linkedHashMap0 = new LinkedHashMap<CheckGOE, AllJavadoc>();
      instances1.remove((Object) "");
      testInstances0.setNumNumeric(876);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 5, Size: 5
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=2.8627288484291125
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("8.7iT(vp8-v@fO%n:");
      NullStemmer nullStemmer0 = new NullStemmer();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.setPeriodicPruning(120);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.setNorm(11.0);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.toString();
      SGDText sGDText0 = new SGDText();
      sGDText0.setPeriodicPruning((-717));
      KDTree kDTree0 = new KDTree();
      Integer.getInteger("The file containing the stopwords (if this is a directory then the default ones are used).", 2049870754);
      instances0.remove((Object) "The independent probability of a class\n--------------------------------------\nclass1\t12.0\nclass2\t10.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\t\n");
      TestInstances testInstances1 = new TestInstances();
      testInstances0.setNumNumeric((-1));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals(11.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 9
  /*Coverage entropy=3.230615668842372
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = 0.0;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      
      naiveBayesMultinomialText0.m_minWordP = 0.0;
      Stopwords stopwords0 = new Stopwords();
      naiveBayesMultinomialText0.m_stopwords = stopwords0;
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.getCapabilities();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      String[] stringArray0 = new String[9];
      stringArray0[0] = "weka/core/Capabilities.props";
      stringArray0[1] = "weka/core/Capabilities.props";
      stringArray0[2] = "weka/core/Capabilities.props";
      stringArray0[3] = "weka/core/Capabilities.props";
      stringArray0[4] = "weka/core/Capabilities.props";
      stringArray0[5] = "weka/core/Capabilities.props";
      stringArray0[6] = "weka/core/Capabilities.props";
      stringArray0[7] = "weka/core/Capabilities.props";
      stringArray0[8] = "weka/core/Capabilities.props";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.setNorm(0.0);
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getStemmer();
      assertEquals(0.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 10
  /*Coverage entropy=3.1111505849912096
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      TestInstances testInstances0 = new TestInstances();
      WrapperSubsetEval wrapperSubsetEval0 = new WrapperSubsetEval();
      SGDText sGDText0 = new SGDText();
      sGDText0.getTokenizer();
      TestInstances.main(testInstances0.DEFAULT_WORDS);
      Instances instances0 = testInstances0.generate(" ");
      NullStemmer nullStemmer0 = new NullStemmer();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.setPeriodicPruning(3);
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.setNorm(3);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.toString();
      sGDText0.setPeriodicPruning(7);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.setLNorm((-231.8523566390901));
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(3.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals((-231.8523566390901), double0, 0.01);
  }

  /**
  //Test case number: 11
  /*Coverage entropy=2.3098849832717785
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      boolean boolean0 = true;
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.globalInfo();
      MockFile mockFile0 = new MockFile("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", "5`AdE6Q=");
      File file0 = MockFile.createTempFile("[*MP?+1;)2j", "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", (File) mockFile0);
      file0.renameTo(mockFile0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/5`AdE6Q=/[*MP?+1;)2j0Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification/5`AdE6Q=");
      mockFile0.setWritable(true, true);
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification");
      MockFile mockFile1 = new MockFile(file0, "5`AdE6Q=");
      mockFile1.toURI();
      naiveBayesMultinomialText0.setStopwords(mockFile1);
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      KDTree kDTree0 = new KDTree();
      int[] intArray0 = null;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.5981863871455346
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      
      naiveBayesMultinomialText0.pruneDictionary();
      DenseInstance denseInstance0 = new DenseInstance(0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(denseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance1, false);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 13
  /*Coverage entropy=1.4572637190629707
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      String string0 = "[*MP?21;)2j";
      String string1 = "5`AdE6Q=";
      String string2 = "\\Q{{ClZA}~)qNa";
      MockFile mockFile0 = new MockFile("Q{{ClZA}~)qNa", "Whether to convert all tokens to lowercase");
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=2.1417112351515417
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      
      String string1 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string1);
      
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 938.5;
      doubleArray0[2] = (-2622.932415316394);
      doubleArray0[4] = (-1228.3429351503462);
      NormalizedPolyKernel normalizedPolyKernel0 = new NormalizedPolyKernel();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      capabilities0.enableAll();
      Instances instances0 = testInstances0.generate("");
      NullStemmer nullStemmer0 = new NullStemmer();
      ChebyshevDistance chebyshevDistance0 = new ChebyshevDistance(instances0);
      instances0.remove((Object) chebyshevDistance0);
      Capabilities.forInstances(instances0);
      TestInstances.main(testInstances0.DEFAULT_WORDS);
      Instances instances1 = testInstances0.generate("");
      NullStemmer nullStemmer1 = new NullStemmer();
      LinkedHashMap<CheckGOE, AllJavadoc> linkedHashMap0 = new LinkedHashMap<CheckGOE, AllJavadoc>();
      instances1.remove((Object) "");
      instances0.removeAll(instances1);
      testInstances0.setNumRelationalNominalValues((-3423));
      testInstances0.setNumNumeric((-1));
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      String string2 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string2);
      
      System.setCurrentTimeMillis((-2474L));
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 15
  /*Coverage entropy=2.7274335622103947
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizerTipText();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "The tokenizing algorithm to use on the strings.");
      System.setCurrentTimeMillis((-2958L));
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText1.getTokenizer();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "fp[b");
      naiveBayesMultinomialText1.setStopwords(file0);
      File file1 = naiveBayesMultinomialText1.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file1);
      naiveBayesMultinomialText1.normalizeDocLengthTipText();
      int[] intArray0 = new int[4];
      intArray0[0] = 7;
      intArray0[1] = 7;
      intArray0[2] = (-3189);
      intArray0[3] = 120;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(10.0, intArray0, (-3189));
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 16
  /*Coverage entropy=3.4854324703660744
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance((byte) (-94), doubleArray0);
      naiveBayesMultinomialText0.setPeriodicPruning((byte) (-73));
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.pruneDictionary();
      Locale.getISOCountries();
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 17
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = 13.0;
      doubleArray0[1] = 13.0;
      doubleArray0[2] = 1.0;
      doubleArray0[3] = 13.0;
      doubleArray0[4] = 13.0;
      doubleArray0[5] = 13.0;
      doubleArray0[6] = 13.0;
      doubleArray0[7] = 13.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(13.0, doubleArray0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) sparseInstance0);
      binarySparseInstance1.dataset();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 18
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte[] byteArray0 = new byte[25];
      byteArray0[1] = (byte)35;
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) (byte)35;
      doubleArray0[1] = 14.0;
      doubleArray0[2] = (double) (byte)35;
      doubleArray0[3] = (double) (byte)35;
      DenseInstance denseInstance0 = new DenseInstance((byte)35, doubleArray0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) denseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=1.8372038747330761
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      byte[] byteArray0 = new byte[9];
      byteArray0[0] = (byte) (-104);
      NormalizedPolyKernel normalizedPolyKernel0 = new NormalizedPolyKernel();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      capabilities0.enableAll();
      Instances instances0 = testInstances0.generate("");
      NullStemmer nullStemmer0 = new NullStemmer();
      ChebyshevDistance chebyshevDistance0 = new ChebyshevDistance(instances0);
      EuclideanDistance euclideanDistance0 = new EuclideanDistance();
      instances0.remove((Object) euclideanDistance0);
      TestInstances.main(testInstances0.DEFAULT_WORDS);
      TestInstances testInstances1 = new TestInstances();
      Instances instances1 = testInstances1.generate("");
      NullStemmer nullStemmer1 = new NullStemmer();
      LinkedHashMap<CheckGOE, AllJavadoc> linkedHashMap0 = new LinkedHashMap<CheckGOE, AllJavadoc>();
      Object object0 = new Object();
      instances1.remove(object0);
      testInstances0.setNumRelationalNominalValues(10000);
      TestInstances testInstances2 = new TestInstances();
      testInstances2.setNumNumeric(876);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.631353359565896
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte)28;
      byteArray0[1] = (byte)35;
      byteArray0[2] = (byte)28;
      byteArray0[3] = (byte)16;
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[0];
      naiveBayesMultinomialText0.setOptions(stringArray0);
      Discretize discretize0 = new Discretize();
      Discretize discretize1 = new Discretize();
      AllFilter allFilter0 = new AllFilter();
      Capabilities capabilities0 = allFilter0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Cannot handle relational attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 0.0;
      doubleArray0[4] = 0.0;
      doubleArray0[5] = 0.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.0, doubleArray0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      try { 
        naiveBayesMultinomialText0.updateClassifier(binarySparseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 23
  /*Coverage entropy=0.9004024235381879
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      byte[] byteArray0 = new byte[6];
      byteArray0[2] = (byte)125;
      byteArray0[3] = (byte)16;
      byteArray0[4] = (byte) (-111);
      KDTree kDTree0 = new KDTree();
      MultiFilter multiFilter0 = new MultiFilter();
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      StringReader stringReader0 = new StringReader("-stemmer <spec>");
      stringReader0.ready();
      stringReader0.ready();
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0);
      StringReader stringReader1 = new StringReader("ableness");
      BufferedReader bufferedReader1 = new BufferedReader(stringReader1, 1);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      DenseInstance denseInstance0 = new DenseInstance(2);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(denseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 24
  /*Coverage entropy=3.2301418474730283
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = 0.0;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.m_minWordP = 0.0;
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.getCapabilities();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "weka/core/Capabilities.props";
      stringArray0[1] = "weka/core/Capabilities.props";
      stringArray0[2] = "weka/core/Capabilities.props";
      stringArray0[3] = "weka/core/Capabilities.props";
      stringArray0[4] = "weka/core/Capabilities.props";
      stringArray0[5] = "weka/core/Capabilities.props";
      stringArray0[6] = "weka/core/Capabilities.props";
      stringArray0[7] = "weka/core/Capabilities.props";
      stringArray0[8] = "weka/core/Capabilities.props";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.setNorm(0.0);
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.normTipText();
      boolean boolean0 = naiveBayesMultinomialText0.getLowercaseTokens();
      assertTrue(boolean0);
  }

  /**
  //Test case number: 25
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      Random.setNextRandom(4863);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normTipText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=2.372821413206516
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)50;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      naiveBayesMultinomialText0.setTokenizer(wordTokenizer0);
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.setPeriodicPruning((byte)50);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 27
  /*Coverage entropy=2.656038865580901
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("8.7iT(vp8-v@fO%n:");
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.setPeriodicPruning(120);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      NormalizedPolyKernel normalizedPolyKernel0 = new NormalizedPolyKernel();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      capabilities0.enableAll();
      Instances instances1 = testInstances0.generate("The stemming algorithm to use on the words.");
      NullStemmer nullStemmer0 = new NullStemmer();
      ChebyshevDistance chebyshevDistance0 = new ChebyshevDistance(instances1);
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      instances0.remove((Object) alphabeticTokenizer0);
      TestInstances.main(testInstances0.DEFAULT_WORDS);
      testInstances1.generate("R;a>I:Vo(h=CFS");
      NullStemmer nullStemmer1 = new NullStemmer();
      LinkedHashMap<CheckGOE, AllJavadoc> linkedHashMap0 = new LinkedHashMap<CheckGOE, AllJavadoc>();
      Instances instances2 = new Instances(instances1);
      instances2.remove((Object) normalizedPolyKernel0);
      testInstances1.setNumRelationalNominalValues(10000);
      TestInstances testInstances2 = TestInstances.forCapabilities(capabilities0);
      testInstances2.setNumNumeric(3);
      naiveBayesMultinomialText0.buildClassifier(instances2);
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.normTipText();
      assertEquals(120, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 28
  /*Coverage entropy=2.7366202162385216
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("8.7iT(vp8-v@fO%n:");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.setPeriodicPruning(120);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      SystemInUtil.addInputLine("2l~K'x>TM ZVOm&b/");
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.toString();
      MultiFilter multiFilter0 = new MultiFilter();
      boolean boolean0 = naiveBayesMultinomialText0.m_useStopList;
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      StringReader stringReader0 = new StringReader("The stemming algorithm to use on the words.");
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0, 10000);
      BufferedReader bufferedReader1 = new BufferedReader(bufferedReader0, 1);
      stringReader0.markSupported();
      StringReader stringReader1 = new StringReader(".bsi");
      char[] charArray0 = new char[6];
      charArray0[0] = '\u001F';
      charArray0[1] = 'i';
      charArray0[2] = 'i';
      charArray0[3] = '\u001F';
      charArray0[4] = '\u001F';
      charArray0[5] = '\u001F';
      stringReader1.read(charArray0);
      BufferedReader bufferedReader2 = new BufferedReader(stringReader1);
      BufferedReader bufferedReader3 = new BufferedReader(bufferedReader1, 1399);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      assertEquals(120, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.9732546345717459
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = null;
      TestInstances.main((String[]) null);
      NormalizedPolyKernel normalizedPolyKernel0 = new NormalizedPolyKernel();
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = sGDText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("stopwords");
      NullStemmer nullStemmer0 = new NullStemmer();
      ChebyshevDistance chebyshevDistance0 = new ChebyshevDistance(instances0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(1);
      binarySparseInstance1.toString();
      chebyshevDistance0.getRanges();
      OptionHandlerJavadoc optionHandlerJavadoc0 = new OptionHandlerJavadoc();
      optionHandlerJavadoc0.setProlog(false);
      instances0.remove((Object) optionHandlerJavadoc0);
      LinkedHashMap<CheckGOE, AllJavadoc> linkedHashMap0 = new LinkedHashMap<CheckGOE, AllJavadoc>();
      instances0.remove((Object) instances0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.buildClassifier(instances0);
      naiveBayesMultinomialText1.setPeriodicPruning(1);
      naiveBayesMultinomialText1.pruneDictionary();
      ReplaceMissingValues replaceMissingValues0 = new ReplaceMissingValues();
      replaceMissingValues0.setIgnoreClass(true);
      ReplaceMissingValues replaceMissingValues1 = new ReplaceMissingValues();
      // Undeclared exception!
      try { 
        binarySparseInstance1.attribute((-1585));
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte)28;
      byteArray0[1] = (byte)35;
      byteArray0[2] = (byte)125;
      byteArray0[3] = (byte)16;
      byteArray0[4] = (byte) (-111);
      KDTree kDTree0 = new KDTree();
      MultiFilter multiFilter0 = new MultiFilter();
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      StringReader stringReader0 = new StringReader("-stemmer <spec>");
      stringReader0.markSupported();
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0);
      StringReader stringReader1 = new StringReader("ableness");
      stringReader1.close();
      BufferedReader bufferedReader1 = new BufferedReader(stringReader1, 1);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) (byte)28;
      doubleArray0[1] = (double) 0;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = Double.NEGATIVE_INFINITY;
      doubleArray0[4] = (double) (byte)35;
      doubleArray0[5] = (double) 1;
      doubleArray0[6] = (double) 2;
      doubleArray0[7] = (double) 1;
      doubleArray0[8] = (double) 2;
      DenseInstance denseInstance0 = new DenseInstance(2608.0, doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 31
  /*Coverage entropy=1.5981863871455344
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = 5.3;
      doubleArray0[1] = (double) (byte) (-104);
      SparseInstance sparseInstance0 = new SparseInstance(5.3, doubleArray0);
      try { 
        naiveBayesMultinomialText0.classifyInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 32
  /*Coverage entropy=1.6211272758470872
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      byte byte0 = (byte) (-104);
      naiveBayesMultinomialText0.getCapabilities();
      double[] doubleArray0 = new double[2];
      doubleArray0[1] = (double) (byte) (-104);
      SparseInstance sparseInstance0 = new SparseInstance(5.3, doubleArray0);
      try { 
        naiveBayesMultinomialText0.classifyInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 33
  /*Coverage entropy=3.269394275120508
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = 1478.892786;
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte)16;
      byteArray0[1] = (byte)35;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      byteArray0[2] = (byte)125;
      byteArray0[3] = (byte)16;
      byteArray0[4] = (byte) (-111);
      byteArray0[5] = (byte) (-74);
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      byte[] byteArray1 = new byte[3];
      byteArray1[0] = (byte) (-73);
      byteArray1[1] = (byte) (-73);
      byteArray1[2] = (byte) (-73);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      Discretize discretize0 = new Discretize();
      ReplaceMissingValues replaceMissingValues0 = new ReplaceMissingValues();
      // Undeclared exception!
      try { 
        replaceMissingValues0.output();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // No output instance format defined
         //
         verifyException("weka.filters.Filter", e);
      }
  }

  /**
  //Test case number: 34
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.toString();
      MultiFilter multiFilter0 = new MultiFilter();
      boolean boolean0 = naiveBayesMultinomialText0.m_useStopList;
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      StringReader stringReader0 = new StringReader("The stemming algorithm to use on the words.");
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0, 10000);
      BufferedReader bufferedReader1 = new BufferedReader(bufferedReader0, 1);
      stringReader0.markSupported();
      bufferedReader0.read();
      StringReader stringReader1 = new StringReader("Whether to convert all tokens to lowercase");
      char[] charArray0 = new char[0];
      stringReader1.read(charArray0);
      BufferedReader bufferedReader2 = new BufferedReader(stringReader0);
      BufferedReader bufferedReader3 = new BufferedReader(bufferedReader2);
      BufferedReader bufferedReader4 = null;
      try {
        bufferedReader4 = new BufferedReader(bufferedReader1, (-585));
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Buffer size <= 0
         //
         verifyException("java.io.BufferedReader", e);
      }
  }

  /**
  //Test case number: 35
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.getNorm();
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      Instances instances0 = null;
      SparseInstance sparseInstance0 = new SparseInstance(1620);
      SparseInstance sparseInstance1 = new SparseInstance(sparseInstance0);
      // Undeclared exception!
      try { 
        sparseInstance1.enumerateAttributes();
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "uM.s";
      stringArray0[1] = "\tMinimum word frequency. Words with less than this frequence are ignored.\n\tIf periodic pruning is turned on then this is also used to determine which\n\twords to remove from the dictionary (default = 3).";
      stringArray0[2] = "";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      AbstractClassifier.makeCopy(naiveBayesMultinomialText0);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals(0.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 37
  /*Coverage entropy=3.048820325203473
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 938.5;
      doubleArray0[1] = 938.5;
      doubleArray0[2] = (-2612.9533827);
      doubleArray0[4] = (-1228.3429351503462);
      doubleArray0[5] = (-260.632840708532);
      doubleArray0[8] = (-2612.9533827);
      SparseInstance sparseInstance0 = new SparseInstance((-2612.9533827), doubleArray0);
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 38
  /*Coverage entropy=1.6211272758470872
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = 5.3;
      doubleArray0[1] = (double) (byte) (-104);
      SparseInstance sparseInstance0 = new SparseInstance(5.3, doubleArray0);
      naiveBayesMultinomialText0.globalInfo();
      AbstractInstance.s_numericAfterDecimalPoint = 9;
      try { 
        naiveBayesMultinomialText0.classifyInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 39
  /*Coverage entropy=3.2698986887396755
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      byte[] byteArray0 = new byte[25];
      byteArray0[0] = (byte)16;
      byteArray0[1] = (byte)35;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      byte[] byteArray1 = new byte[4];
      byteArray1[0] = (byte) (-74);
      byteArray1[1] = (byte) (-74);
      byteArray1[2] = (byte)16;
      byteArray1[3] = (byte) (-74);
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.setTokenizer(alphabeticTokenizer0);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      byte[] byteArray2 = new byte[4];
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      byteArray2[0] = (byte) (-74);
      byteArray2[1] = (byte) (-74);
      byteArray2[2] = (byte) (-74);
      byteArray2[3] = (byte)16;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray2);
      Discretize discretize0 = new Discretize();
      ReplaceMissingValues replaceMissingValues0 = new ReplaceMissingValues();
      // Undeclared exception!
      try { 
        replaceMissingValues0.outputPeek();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // No output instance format defined
         //
         verifyException("weka.filters.Filter", e);
      }
  }

  /**
  //Test case number: 40
  /*Coverage entropy=3.269394275120508
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      byte[] byteArray0 = new byte[9];
      byteArray0[0] = (byte) (-104);
      byteArray0[3] = (byte) (-94);
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (double) (byte) (-94);
      doubleArray0[2] = (double) (byte) (-104);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      byte[] byteArray1 = new byte[0];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      Discretize discretize0 = new Discretize();
      ReplaceMissingValues replaceMissingValues0 = new ReplaceMissingValues();
      // Undeclared exception!
      try { 
        replaceMissingValues0.output();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // No output instance format defined
         //
         verifyException("weka.filters.Filter", e);
      }
  }

  /**
  //Test case number: 41
  /*Coverage entropy=2.214734015212756
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_periodicP = 2301;
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (-1210.24875);
      doubleArray0[1] = 938.5;
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      doubleArray0[2] = (-260.632840708532);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2301);
      try { 
        naiveBayesMultinomialText0.classifyInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 42
  /*Coverage entropy=3.2698986887396755
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.setTokenizer(alphabeticTokenizer0);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      TestInstances testInstances0 = new TestInstances();
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities1 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities2 = new FindWithCapabilities();
      testInstances0.generate();
      FindWithCapabilities[] findWithCapabilitiesArray0 = new FindWithCapabilities[6];
      FindWithCapabilities findWithCapabilities3 = new FindWithCapabilities();
      FindWithCapabilities findWithCapabilities4 = new FindWithCapabilities();
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.UNARY_CLASS;
      FindWithCapabilities findWithCapabilities5 = new FindWithCapabilities();
      // Undeclared exception!
      try { 
        findWithCapabilities5.setFilename((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.FindWithCapabilities", e);
      }
  }

  /**
  //Test case number: 43
  /*Coverage entropy=2.555632017870312
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      byte[] byteArray0 = new byte[8];
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      byteArray0[0] = (byte) (-77);
      byteArray0[1] = (byte) (-36);
      byteArray0[2] = (byte) (-60);
      byteArray0[3] = (byte)21;
      byteArray0[4] = (byte)61;
      byteArray0[5] = (byte)112;
      byteArray0[6] = (byte)62;
      byteArray0[7] = (byte)1;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stopwordsTipText();
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(938.5, doubleArray0);
      FileSystemHandling.shouldAllThrowIOExceptions();
      sparseInstance0.replaceMissingValues(doubleArray0);
      double double0 = naiveBayesMultinomialText0.m_t;
      naiveBayesMultinomialText0.getUseWordFrequencies();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLNorm((byte) (-36));
      naiveBayesMultinomialText1.useStopListTipText();
      naiveBayesMultinomialText0.m_norm = (double) 9;
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      assertEquals((-36.0), naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      String string0 = naiveBayesMultinomialText1.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string0);
  }

  /**
  //Test case number: 44
  /*Coverage entropy=3.2698986887396755
  */
  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte) (-111);
      byteArray0[1] = (byte) (-74);
      boolean boolean0 = naiveBayesMultinomialText0.m_normalize;
      FileSystemHandling.shouldAllThrowIOExceptions();
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.m_normalize = true;
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setTokenizer(alphabeticTokenizer0);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      TestInstances testInstances0 = new TestInstances();
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      Discretize discretize0 = new Discretize();
      ReplaceMissingValues replaceMissingValues0 = new ReplaceMissingValues();
      // Undeclared exception!
      try { 
        replaceMissingValues0.output();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // No output instance format defined
         //
         verifyException("weka.filters.Filter", e);
      }
  }

  /**
  //Test case number: 45
  /*Coverage entropy=3.4386291405681724
  */
  @Test(timeout = 4000)
  public void test45()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getLNorm();
      String[] stringArray0 = new String[5];
      naiveBayesMultinomialText0.setUseStopList(false);
      stringArray0[0] = "k=Ld";
      naiveBayesMultinomialText0.setPeriodicPruning((-3983));
      stringArray0[1] = "-lowercase";
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      stringArray0[2] = "aGzm`hNg|cgD#..";
      stringArray0[3] = "";
      naiveBayesMultinomialText0.setMinWordFrequency((-3983));
      stringArray0[4] = "P";
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.globalInfo();
      wordTokenizer0.tokenize("");
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.setNorm(2.0);
      Tokenizer.tokenize(naiveBayesMultinomialText0.m_tokenizer, stringArray0);
      wordTokenizer0.setDelimiters("k=Ld");
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.setLNorm((-697.1));
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.listOptions();
      assertEquals((-3983.0), naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 46
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test46()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getMinWordFrequency();
      BallNode ballNode0 = new BallNode(1, 1, (-2703), (Instance) null, 1);
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      try { 
        principalComponents0.transformedHeader();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Principal components hasn't been built yet
         //
         verifyException("weka.attributeSelection.PrincipalComponents", e);
      }
  }

  /**
  //Test case number: 47
  /*Coverage entropy=1.5981863871455346
  */
  @Test(timeout = 4000)
  public void test47()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte)16;
      byteArray0[1] = (byte)35;
      byteArray0[2] = (byte)125;
      String[] stringArray0 = new String[6];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "G!&-";
      stringArray0[3] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[4] = "pJ&:y4(7VaXB{P5ML";
      stringArray0[5] = ")2h|Xs[";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = (double) (byte)65;
      doubleArray0[1] = 497.0974108626;
      doubleArray0[2] = (double) (byte)16;
      doubleArray0[3] = (double) (byte) (-94);
      doubleArray0[4] = 17.0;
      doubleArray0[5] = 17.0;
      SparseInstance sparseInstance0 = new SparseInstance(100.0, doubleArray0);
      try { 
        naiveBayesMultinomialText0.classifyInstance(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 48
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test48()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte)16;
      byteArray0[1] = (byte)16;
      byteArray0[2] = (byte)125;
      byteArray0[3] = (byte)16;
      byteArray0[4] = (byte)35;
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      byteArray0[5] = (byte) (-74);
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getNormalizeDocLength();
      Discretize discretize0 = new Discretize();
      ReplaceMissingValues replaceMissingValues0 = new ReplaceMissingValues();
      // Undeclared exception!
      try { 
        replaceMissingValues0.output();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // No output instance format defined
         //
         verifyException("weka.filters.Filter", e);
      }
  }

  /**
  //Test case number: 49
  /*Coverage entropy=2.218655583840207
  */
  @Test(timeout = 4000)
  public void test49()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      byte[] byteArray0 = new byte[9];
      byteArray0[0] = (byte) (-104);
      byteArray0[1] = (byte)47;
      byteArray0[2] = (byte) (-104);
      byteArray0[3] = (byte) (-94);
      byteArray0[4] = (byte) (-4);
      byteArray0[5] = (byte) (-86);
      byteArray0[6] = (byte)44;
      byteArray0[7] = (byte) (-104);
      byteArray0[8] = (byte)14;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      naiveBayesMultinomialText0.globalInfo();
      MockFile mockFile0 = new MockFile("", "5`AdE6Q=");
      File file0 = MockFile.createTempFile("[*MP?+1;)2j", "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", (File) mockFile0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "N+F*=4S>u}!yA.,HY");
      mockFile0.toURI();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      Capabilities capabilities0 = new Capabilities(naiveBayesMultinomialText0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      naiveBayesMultinomialText0.setStopwords(file0);
      testInstances0.getRelationalClassFormat();
      naiveBayesMultinomialText0.m_normalize = true;
      // Undeclared exception!
      try { 
        BallNode.calcCentroidPivot((int[]) null, (Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.balltrees.BallNode", e);
      }
  }

  /**
  //Test case number: 50
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test50()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int int0 = 2301;
      naiveBayesMultinomialText0.m_periodicP = 2301;
      naiveBayesMultinomialText0.getStemmer();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (-1210.24875);
      doubleArray0[1] = 938.5;
      doubleArray0[2] = (-260.632840708532);
      SparseInstance sparseInstance0 = new SparseInstance(938.5, doubleArray0);
      // Undeclared exception!
      try { 
        sparseInstance0.isMissingSparse(2301);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 2301
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 51
  /*Coverage entropy=3.474430935281374
  */
  @Test(timeout = 4000)
  public void test51()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.globalInfo();
      MockFile mockFile0 = new MockFile("");
      File file0 = MockFile.createTempFile("[:*MP?+1)2", "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", (File) mockFile0);
      file0.getAbsoluteFile();
      MockFile mockFile1 = new MockFile(file0, "5`AdE6Q=");
      String[] stringArray0 = new String[1];
      stringArray0[0] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.setPeriodicPruning((-3281));
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.setNorm(1696.0);
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.toString();
      SGDText sGDText0 = new SGDText();
      sGDText0.setPeriodicPruning(90);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.setLNorm((-4703.63217853871));
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.LNormTipText();
      assertEquals((-3281), naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 52
  /*Coverage entropy=2.5537169868187317
  */
  @Test(timeout = 4000)
  public void test52()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stemmerTipText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("8.7iT(vp8-v@fO%n:");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.toString();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      FileSystemHandling.createFolder(evoSuiteFile0);
      MultiFilter multiFilter0 = new MultiFilter();
      naiveBayesMultinomialText0.getLowercaseTokens();
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      StringReader stringReader0 = new StringReader("The stemming algorithm to use on the words.");
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0, 10000);
      BufferedReader bufferedReader1 = new BufferedReader(bufferedReader0, 1);
      stringReader0.markSupported();
      bufferedReader0.read();
      StringReader stringReader1 = new StringReader("8.7iT(vp8-v@fO%n:");
      char[] charArray0 = new char[0];
      stringReader1.read(charArray0);
      BufferedReader bufferedReader2 = new BufferedReader(stringReader0);
      BufferedReader bufferedReader3 = new BufferedReader(bufferedReader2);
      BufferedReader bufferedReader4 = null;
      try {
        bufferedReader4 = new BufferedReader(bufferedReader1, (-617));
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Buffer size <= 0
         //
         verifyException("java.io.BufferedReader", e);
      }
  }
}
