/*
 * This file was automatically generated by EvoSuite
 * Tue Nov 19 17:03:19 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.BufferedReader;
import java.io.File;
import java.io.StringReader;
import java.nio.CharBuffer;
import java.nio.ReadOnlyBufferException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import java.util.Properties;
import java.util.Set;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;
import weka.attributeSelection.OneRAttributeEval;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.meta.Vote;
import weka.classifiers.misc.InputMappedClassifier;
import weka.classifiers.misc.SerializedClassifier;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.ProtectedProperties;
import weka.core.SparseInstance;
import weka.core.Stopwords;
import weka.core.TestInstances;
import weka.core.neighboursearch.KDTree;
import weka.core.stemmers.IteratedLovinsStemmer;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.AlphabeticTokenizer;
import weka.core.tokenizers.NGramTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.estimators.DiscreteEstimator;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      long long0 = 1992L;
      System.setCurrentTimeMillis(1992L);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double double0 = 0.0;
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("", arrayList0, 2934);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2934);
      instances0.add((Instance) binarySparseInstance0);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: No attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=2.74054655890746
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setMinWordFrequency((-141.73429652));
      naiveBayesMultinomialText0.m_periodicP = 132;
      String[] stringArray0 = new String[0];
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      Random.setNextRandom((-1));
  }

  /**
  //Test case number: 2
  /*Coverage entropy=1.0365141682948127
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int int0 = 140;
      naiveBayesMultinomialText0.m_periodicP = 140;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=2.2163385134086346
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      naiveBayesMultinomialText0.m_periodicP = (-20);
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) (-20);
      doubleArray0[1] = 407.4979;
      doubleArray0[2] = (-5478.918192921);
      doubleArray0[3] = (double) (-20);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      String string0 = naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string0);
      
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.clone();
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      naiveBayesMultinomialText0.getTokenizer();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertEquals(1.0, double0, 0.01);
      
      naiveBayesMultinomialText0.pruneDictionary();
      String string1 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string1);
      
      naiveBayesMultinomialText0.getLowercaseTokens();
      String string2 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string2);
      
      boolean boolean0 = naiveBayesMultinomialText0.getLowercaseTokens();
      assertFalse(boolean0);
      
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.getTokenizer();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.887511378356885
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      naiveBayesMultinomialText0.m_periodicP = (-20);
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) (-20);
      doubleArray0[1] = 407.4979;
      doubleArray0[2] = (-5478.918192921);
      doubleArray0[3] = (double) (-20);
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.pruneDictionary();
      File file0 = naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      assertEquals((-20), naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 5
  /*Coverage entropy=2.4196189862824298
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "-lnorm");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.LNormTipText();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, false, false);
      naiveBayesMultinomialText0.listOptions();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "The norm of the instances after normalization.";
      stringArray0[1] = "-lnorm";
      stringArray0[2] = "UC~&tO@tAGO*f";
      stringArray0[3] = "The LNorm to use for document length normalization.";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=2.8624911671521485
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte[] byteArray0 = new byte[8];
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      byteArray0[0] = (byte) (-53);
      byteArray0[1] = (byte) (-53);
      byteArray0[2] = (byte) (-91);
      byteArray0[3] = (byte)50;
      byteArray0[4] = (byte) (-15);
      byteArray0[5] = (byte)60;
      byteArray0[6] = (byte) (-40);
      byteArray0[7] = (byte)16;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.setMinWordFrequency(0);
      naiveBayesMultinomialText0.m_normalize = false;
      naiveBayesMultinomialText0.setTokenizer((Tokenizer) null);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.getOptions();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 7
  /*Coverage entropy=1.9462570102898904
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normTipText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      FileSystemHandling.shouldAllThrowIOExceptions();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      Stopwords stopwords0 = naiveBayesMultinomialText1.m_stopwords;
      naiveBayesMultinomialText0.m_stopwords = null;
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.m_probOfWordGivenClass = null;
      MockFile mockFile0 = new MockFile("The norm of the instances after normalization.", "weka/core/Capabilities.props");
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.toString();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=3.1125212449139825
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      MockFile mockFile0 = new MockFile("'B2of2'", "'B2of2'");
      naiveBayesMultinomialText0.m_stopwordsFile = (File) mockFile0;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.getLowercaseTokens();
      mockFile0.toURI();
      mockFile0.getCanonicalPath();
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      assertEquals(14, stringArray1.length);
      
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      naiveBayesMultinomialText0.normTipText();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      mockFile0.delete();
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      
      String string1 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string1);
      
      String string2 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string2);
      
      String string3 = naiveBayesMultinomialText0.normTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals("The norm of the instances after normalization.", string3);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.274406158904335
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)50;
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      DenseInstance denseInstance0 = new DenseInstance(2934);
      instances0.add((Instance) denseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.m_leplace = (double) (-1113);
      ArrayList<DenseInstance> arrayList0 = new ArrayList<DenseInstance>();
      StringReader stringReader0 = new StringReader(".arff");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      ArrayList<DenseInstance> arrayList1 = new ArrayList<DenseInstance>();
      naiveBayesMultinomialText0.pruneDictionary();
      double[] doubleArray0 = new double[0];
      DenseInstance denseInstance1 = new DenseInstance((-603.1598716091), doubleArray0);
      naiveBayesMultinomialText0.distributionForInstance(denseInstance1);
      double[] doubleArray1 = naiveBayesMultinomialText0.distributionForInstance(denseInstance1);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertArrayEquals(new double[] {0.5454545454545454, 0.4545454545454546}, doubleArray1, 0.01);
  }

  /**
  //Test case number: 10
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)50;
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      DenseInstance denseInstance0 = new DenseInstance(0);
      instances0.remove((Object) testInstances0);
      instances0.add((Instance) denseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=2.509144254848123
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)50;
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      DenseInstance denseInstance0 = new DenseInstance(2934);
      instances0.add((Instance) denseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      ArrayList<DenseInstance> arrayList0 = new ArrayList<DenseInstance>();
      StringReader stringReader0 = new StringReader(".arff");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.globalInfo();
      ArrayList<DenseInstance> arrayList1 = new ArrayList<DenseInstance>();
      naiveBayesMultinomialText0.pruneDictionary();
      double[] doubleArray0 = new double[0];
      DenseInstance denseInstance1 = new DenseInstance((-603.1598716091), doubleArray0);
      naiveBayesMultinomialText0.distributionForInstance(denseInstance1);
      double double0 = naiveBayesMultinomialText0.m_leplace;
      File file0 = MockFile.createTempFile("Classifier for building 'logistic model trees', which are classification trees with logistic regression functions at the leaves. The algorithm can deal with binary and multi-class target variables, numeric and nominal attributes and missing values.\n\nFor more information see: \n\n", ".arff");
      MockFile.createTempFile(".arff", "Classifier for building 'logistic model trees', which are classification trees with logistic regression functions at the leaves. The algorithm can deal with binary and multi-class target variables, numeric and nominal attributes and missing values.\n\nFor more information see: \n\n");
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.distributionForInstance(denseInstance1);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.9296217656001493
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, (String) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getCapabilities();
      int int0 = 6;
      naiveBayesMultinomialText0.setPeriodicPruning(6);
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setStopwords((File) null);
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1275);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      Locale locale0 = Locale.KOREA;
      Set<String> set0 = locale0.getUnicodeLocaleAttributes();
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.MAP_EXTENDED_RANGES;
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) set0, locale_FilteringMode0);
      Properties properties0 = new Properties();
      ProtectedProperties protectedProperties0 = new ProtectedProperties(properties0);
      ProtectedProperties protectedProperties1 = new ProtectedProperties(protectedProperties0);
      ProtectedProperties protectedProperties2 = new ProtectedProperties(protectedProperties1);
      Attribute attribute0 = new Attribute("", list0, protectedProperties2);
      // Undeclared exception!
      try { 
        binarySparseInstance0.toString(attribute0, (-1328));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=2.4651789675537366
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      DenseInstance denseInstance0 = new DenseInstance(2934);
      instances0.add((Instance) denseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      ArrayList<DenseInstance> arrayList0 = new ArrayList<DenseInstance>();
      ArrayList<DenseInstance> arrayList1 = new ArrayList<DenseInstance>();
      naiveBayesMultinomialText0.pruneDictionary();
      double[] doubleArray0 = new double[0];
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, true, true);
      File file0 = naiveBayesMultinomialText0.getStopwords();
      File file1 = MockFile.createTempFile("@relation", "SCHOOL", file0);
      naiveBayesMultinomialText0.setStopwords(file1);
      SGDText sGDText0 = new SGDText();
      sGDText0.getLossFunction();
      DenseInstance denseInstance1 = new DenseInstance(1262.24005322, doubleArray0);
      naiveBayesMultinomialText0.distributionForInstance(denseInstance1);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 14
  /*Coverage entropy=1.9012735713814104
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)50;
      byteArray0[1] = (byte) (-84);
      byteArray0[3] = (byte)0;
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, true, true, true);
      byteArray0[4] = (byte)97;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      byte[] byteArray1 = new byte[3];
      byteArray1[0] = (byte) (-1);
      byteArray1[1] = (byte)0;
      byteArray1[0] = (byte)70;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      File file1 = MockFile.createTempFile("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", file0);
      file1.setReadable(false);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      naiveBayesMultinomialText0.setStopwords(file1);
      sGDText0.getLossFunction();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (byte)70;
      doubleArray0[1] = (double) (byte)0;
      doubleArray0[2] = (double) (byte)97;
      DenseInstance denseInstance0 = new DenseInstance((byte) (-84), doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 15
  /*Coverage entropy=1.7576378583071737
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "Ey&y5Grn.hZbb");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNorm();
      double[] doubleArray0 = new double[9];
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("Ey&y5Grn.hZbb");
      SnowballStemmer.main((String[]) null);
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      doubleArray0[0] = 1.0;
      doubleArray0[1] = 1.0;
      doubleArray0[2] = 1.0;
      doubleArray0[3] = 1.0;
      doubleArray0[4] = 1187.57188781;
      doubleArray0[5] = 1.0;
      doubleArray0[6] = 0.3;
      doubleArray0[7] = 1.0;
      doubleArray0[8] = 1.0;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1.0, doubleArray0);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      Capabilities capabilities0 = precomputedKernelMatrixKernel0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("9?f");
      binarySparseInstance0.setDataset(instances0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 2, Size: 2
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  /**
  //Test case number: 16
  /*Coverage entropy=1.847832822658352
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte byte0 = (byte)50;
      byte byte1 = (byte) (-84);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "";
      String string0 = "?o]CW.Rce`}";
      stringArray0[1] = "?o]CW.Rce`}";
      stringArray0[2] = "address";
      stringArray0[3] = "-lnorm";
      try { 
        naiveBayesMultinomialText1.setOptions(stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No value given for -lnorm option.
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 17
  /*Coverage entropy=2.6446593184291487
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      OneRAttributeEval oneRAttributeEval0 = new OneRAttributeEval();
      Capabilities capabilities0 = oneRAttributeEval0.getCapabilities();
      Capabilities capabilities1 = capabilities0.getOtherCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities1);
      testInstances0.generate();
      Instances instances0 = testInstances0.getData();
      instances0.enumerateInstances();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText1.normTipText();
      ArrayList<DenseInstance> arrayList0 = new ArrayList<DenseInstance>();
      oneRAttributeEval0.setSeed((-1364));
      Capabilities.Capability capabilities_Capability0 = Capabilities.Capability.DATE_CLASS;
      capabilities0.disable(capabilities_Capability0);
      naiveBayesMultinomialText0.pruneDictionary();
      double[] doubleArray0 = new double[0];
      DenseInstance denseInstance0 = new DenseInstance((-2), doubleArray0);
      naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      denseInstance0.toStringNoWeight();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText1.normalizeDocLengthTipText();
      naiveBayesMultinomialText2.LNormTipText();
      naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
      naiveBayesMultinomialText0.getCapabilities();
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 18
  /*Coverage entropy=3.2828430896432517
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.setUseStopList(false);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, true, false);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.setMinWordFrequency((-2418.98));
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.normTipText();
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getOptions();
      assertEquals((-2418.98), naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 19
  /*Coverage entropy=2.209406559005219
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      SnowballStemmer snowballStemmer1 = new SnowballStemmer("");
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "org.tartarus.snowball.ext";
      stringArray0[2] = "org.tartarus.snowball";
      stringArray0[3] = "KKT condition 3 violated: ";
      stringArray0[4] = "org.tartarus.snowball.ext";
      stringArray0[5] = "org.tartarus.snowball";
      stringArray0[6] = "org.tartarus.snowball.ext";
      stringArray0[7] = "";
      stringArray0[8] = "org.tartarus.snowball.ext";
      snowballStemmer1.setOptions(stringArray0);
      SnowballStemmer snowballStemmer2 = new SnowballStemmer("vG9");
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      
      String string1 = naiveBayesMultinomialText0.globalInfo();
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string1);
      
      MockFile mockFile0 = new MockFile("'C|#>D|", "6n4t2Vh.\"Or");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      File file0 = naiveBayesMultinomialText0.getStopwords();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(file0.canRead());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.297687147780183
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "5\".~8hm.ocM1W9a\"#p");
      naiveBayesMultinomialText0.m_lnorm = (-459.777);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.setMinWordFrequency((-333.6111));
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.stemmerTipText();
      System.setCurrentTimeMillis(0L);
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file0 = serializedClassifier0.getModelFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals((-459.777), double0, 0.01);
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 0.0;
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "org.tartarus.snowball.ext";
      stringArray0[1] = "org.tartarus.snowball.ext";
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "hzuB72XY^jW?K,5t\"$@");
      DiscreteEstimator discreteEstimator0 = new DiscreteEstimator(711, false);
      Capabilities capabilities0 = discreteEstimator0.getCapabilities();
      TestInstances.forCapabilities(capabilities0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Class attribute not set!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=2.1341286000959614
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Stopwords stopwords0 = naiveBayesMultinomialText0.m_stopwords;
      naiveBayesMultinomialText0.m_stopwords = null;
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      File file0 = naiveBayesMultinomialText1.getStopwords();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.listOptions();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 23
  /*Coverage entropy=1.9662848511774718
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      FileSystemHandling.shouldAllThrowIOExceptions();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      String string0 = naiveBayesMultinomialText0.toString();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals("The independent probability of a class\n--------------------------------------\nclass1\t9.0\nclass2\t4.0\nclass3\t7.0\nclass4\t4.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\tclass3\tclass4\t\nover\t2.718281828459045\t2.718281828459045\t7.38905609893065\t7.38905609893065\t\nthe\t7.38905609893065\t7.38905609893065\t2.718281828459045\t2.718281828459045\t\nThe\t7.38905609893065\t2.718281828459045\t7.38905609893065\t2.718281828459045\t\nquick\t7.38905609893065\t2.718281828459045\t7.38905609893065\t7.38905609893065\t\nlazy\t7.38905609893065\t2.718281828459045\t7.38905609893065\t2.718281828459045\t\njumps\t20.085536923187668\t7.38905609893065\t2.718281828459045\t2.718281828459045\t\nbrown\t7.38905609893065\t7.38905609893065\t2.718281828459045\t2.718281828459045\t\ndog\t7.38905609893065\t2.718281828459045\t7.38905609893065\t2.718281828459045\t\nfox\t2.718281828459045\t2.718281828459045\t7.38905609893065\t7.38905609893065\t\n", string0);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 24
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Vote vote0 = new Vote();
      Capabilities capabilities0 = vote0.getCapabilities();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      capabilities0.disableAllAttributeDependencies();
      Instances instances0 = testInstances1.generate();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Cannot handle relational attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      byte[] byteArray0 = new byte[5];
      byte byte0 = (byte)50;
      byteArray0[0] = (byte)50;
      byteArray0[1] = (byte) (-84);
      byteArray0[3] = (byte)0;
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, true, true, true);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=3.1524064268007286
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normTipText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setMinWordFrequency(1034.9);
      KDTree kDTree0 = new KDTree();
      kDTree0.setMeasurePerformance(false);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "sent");
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = 0.0;
      int[] intArray0 = new int[2];
      intArray0[0] = 1;
      intArray0[1] = 1357;
      SparseInstance sparseInstance0 = new SparseInstance((-983.1035042662437), doubleArray0, intArray0, (-1629));
      try { 
        naiveBayesMultinomialText0.classifyInstance(sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 0.0;
      int[] intArray0 = new int[9];
      intArray0[8] = (-1364);
      intArray0[2] = 3929;
      intArray0[3] = (-2350);
      intArray0[8] = (-1629);
      intArray0[5] = (-2607);
      intArray0[6] = (-2607);
      intArray0[7] = 1331;
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0, intArray0, 0);
      sparseInstance0.setWeight(2835);
      try { 
        naiveBayesMultinomialText0.updateClassifier(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.8978657693160126
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normTipText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      FileSystemHandling.shouldAllThrowIOExceptions();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      MockFile mockFile0 = new MockFile("QR", "weka/core/Capabilities.props");
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      BinarySparseInstance binarySparseInstance0 = null;
      try {
        binarySparseInstance0 = new BinarySparseInstance((-1));
        fail("Expecting exception: NegativeArraySizeException");
      
      } catch(NegativeArraySizeException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.BinarySparseInstance", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = ";Wa<=";
      stringArray0[0] = ";Wa<=";
      StringReader stringReader0 = new StringReader("");
      char[] charArray0 = new char[2];
      charArray0[0] = '8';
      charArray0[1] = 'A';
      CharBuffer charBuffer0 = CharBuffer.wrap(charArray0);
      stringReader0.read(charBuffer0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getStemmer();
      FileSystemHandling.setPermissions(evoSuiteFile0, true, true, true);
      stringReader0.read();
      long long0 = stringReader0.skip((-363L));
      assertEquals(0L, long0);
  }

  /**
  //Test case number: 31
  /*Coverage entropy=2.8827437576468555
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.pruneDictionary();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "nhQP_[FWSG$q";
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      stringArray0[1] = "%b-xSFHEO^J:w!Rb!";
      stringArray0[2] = "";
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.reset();
      naiveBayesMultinomialText1.setUseWordFrequencies(true);
      naiveBayesMultinomialText1.getNorm();
      naiveBayesMultinomialText0.pruneDictionary();
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 32
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)50;
      byteArray0[1] = (byte) (-84);
      byteArray0[3] = (byte)0;
      byteArray0[4] = (byte)77;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      byte[] byteArray1 = new byte[3];
      byteArray1[0] = (byte) (-1);
      byteArray1[1] = (byte)0;
      byteArray1[2] = (byte)70;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      File file1 = MockFile.createTempFile("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", file0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      naiveBayesMultinomialText0.setStopwords(file1);
      sGDText0.getLossFunction();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (byte) (-1);
      doubleArray0[1] = (double) (byte)0;
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 4664.0;
      doubleArray0[4] = (double) 1;
      boolean boolean0 = naiveBayesMultinomialText0.getLowercaseTokens();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      assertFalse(boolean0);
  }

  /**
  //Test case number: 33
  /*Coverage entropy=3.171769530903426
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_t = 0.0;
      naiveBayesMultinomialText0.setMinWordFrequency(540.0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText1.getUseStopList();
      naiveBayesMultinomialText1.getStopwords();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText1.getMinWordFrequency();
      naiveBayesMultinomialText0.setLNorm((-161.57791793444));
      assertEquals((-161.57791793444), naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.getLNorm();
      naiveBayesMultinomialText1.getRevision();
      String string0 = naiveBayesMultinomialText1.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string0);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=0.9623351446188083
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      boolean boolean0 = true;
      NullStemmer nullStemmer0 = (NullStemmer)naiveBayesMultinomialText0.m_stemmer;
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) nullStemmer0;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 35
  /*Coverage entropy=0.8505612088663046
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      intArray0[0] = (-3077);
      intArray0[1] = 998;
      intArray0[2] = 112;
      intArray0[3] = (-1);
      intArray0[4] = 1187;
      intArray0[5] = 467;
      intArray0[6] = 10000;
      intArray0[7] = 18;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(4103.9, intArray0, (-1));
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=1.9012735713814104
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)50;
      byteArray0[1] = (byte) (-84);
      byteArray0[3] = (byte)0;
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      byteArray0[4] = (byte)97;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      byte[] byteArray1 = new byte[3];
      byteArray1[0] = (byte) (-1);
      byteArray1[1] = (byte)0;
      byteArray1[0] = (byte)70;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "Zao{L");
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      File file1 = MockFile.createTempFile("Zao{L", "Zao{L", file0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      naiveBayesMultinomialText0.setStopwords(file1);
      sGDText0.getLossFunction();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (byte)70;
      doubleArray0[1] = (double) (byte)0;
      doubleArray0[2] = (double) (byte)97;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((byte)0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 37
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      StringReader stringReader0 = new StringReader("Headers match");
      StringReader stringReader1 = new StringReader("Headers match");
      CharBuffer.wrap((CharSequence) "Headers match");
      char[] charArray0 = new char[9];
      charArray0[0] = 'x';
      charArray0[1] = ']';
      charArray0[2] = '&';
      charArray0[3] = '\"';
      charArray0[4] = '<';
      charArray0[5] = 'q';
      charArray0[6] = 'o';
      charArray0[7] = 'R';
      charArray0[8] = ']';
      // Undeclared exception!
      try { 
        stringReader1.read(charArray0, 104, 1294);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.io.StringReader", e);
      }
  }

  /**
  //Test case number: 38
  /*Coverage entropy=2.876156142363588
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("idQ;LAb,W3]ME(MYhB");
      SnowballStemmer.listStemmers();
      naiveBayesMultinomialText0.setStemmer(snowballStemmer0);
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.stopwordsTipText();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 39
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification0Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification");
      byte[] byteArray0 = new byte[5];
      byteArray0[2] = (byte)50;
      byteArray0[4] = (byte) (-84);
      byteArray0[2] = (byte) (-84);
      byteArray0[3] = (byte)0;
      byteArray0[4] = (byte)97;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      byte[] byteArray1 = new byte[3];
      byteArray1[0] = (byte) (-1);
      byteArray1[1] = (byte)0;
      byteArray1[2] = (byte)70;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      sGDText0.setSeed((byte)70);
      File file0 = sGDText0.getStopwords();
      File file1 = MockFile.createTempFile("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", file0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      naiveBayesMultinomialText0.setStopwords(file1);
      SGDText sGDText1 = new SGDText();
      sGDText1.getLossFunction();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (byte) (-1);
      doubleArray0[1] = (double) (byte)0;
      Random.setNextRandom(1);
      boolean boolean0 = naiveBayesMultinomialText0.getUseStopList();
      assertTrue(boolean0);
  }

  /**
  //Test case number: 40
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 41
  /*Coverage entropy=2.56055716002842
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "6v4 ^~XxU";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      stringArray0[4] = ",1MIZT&;`ok6fDz?";
      stringArray0[5] = "MXC;%8aRL7(&xzgRU";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      SGDText sGDText0 = new SGDText();
      Stemmer stemmer0 = sGDText0.getStemmer();
      naiveBayesMultinomialText0.setStemmer(stemmer0);
      boolean boolean0 = naiveBayesMultinomialText0.getUseStopList();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(boolean0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 42
  /*Coverage entropy=2.6709087878625355
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)1;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      File file0 = MockFile.createTempFile("@b!1*Bx21BBb2\"Q~*v", "");
      naiveBayesMultinomialText0.m_stopwordsFile = file0;
      naiveBayesMultinomialText0.setLNorm(1.0E-10);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.LNormTipText();
      System.setCurrentTimeMillis(2667L);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.stemmerTipText();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[1] = "If true then document length is normalized according to the settings for norm and lnorm";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 43
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setMinWordFrequency(642.82318277);
      naiveBayesMultinomialText0.getMinWordFrequency();
      IteratedLovinsStemmer iteratedLovinsStemmer0 = new IteratedLovinsStemmer();
      iteratedLovinsStemmer0.getTechnicalInformation();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "";
      IteratedLovinsStemmer.main(stringArray0);
      iteratedLovinsStemmer0.getRevision();
      naiveBayesMultinomialText0.setStemmer(iteratedLovinsStemmer0);
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 44
  /*Coverage entropy=3.0279017942068247
  */
  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)1;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      File file0 = MockFile.createTempFile("@b!1*Bx21BBb2\"Q~*v", "");
      naiveBayesMultinomialText0.m_stopwordsFile = file0;
      naiveBayesMultinomialText0.setLNorm(1.0E-10);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.LNormTipText();
      System.setCurrentTimeMillis(2667L);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.stemmerTipText();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[1] = "The LNorm to use for document length normalization.";
      stringArray0[2] = "The norm of the instances after normalization.";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals(1.0E-10, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 45
  /*Coverage entropy=2.8778952727983707
  */
  @Test(timeout = 4000)
  public void test45()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.setTokenizer(alphabeticTokenizer0);
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.m_norm = (-373.035226959575);
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.setMinWordFrequency((-447.621515));
      naiveBayesMultinomialText0.m_periodicP = 1022;
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.useStopListTipText();
      assertEquals((-373.035226959575), naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 46
  /*Coverage entropy=2.2654436797543704
  */
  @Test(timeout = 4000)
  public void test46()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      OneRAttributeEval oneRAttributeEval0 = new OneRAttributeEval();
      String string0 = naiveBayesMultinomialText1.normTipText();
      assertEquals("The norm of the instances after normalization.", string0);
      assertEquals(0, naiveBayesMultinomialText1.getPeriodicPruning());
      
      ArrayList<DenseInstance> arrayList0 = new ArrayList<DenseInstance>();
      naiveBayesMultinomialText0.pruneDictionary();
      double[] doubleArray0 = new double[0];
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.normalizeDocLengthTipText();
      String string1 = naiveBayesMultinomialText1.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string1);
      
      String string2 = naiveBayesMultinomialText2.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string2);
      
      String string3 = naiveBayesMultinomialText1.globalInfo();
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getUseWordFrequencies());
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string3);
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
  }

  /**
  //Test case number: 47
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test47()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 48
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test48()  throws Throwable  {
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, (String) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = 699.39216;
      doubleArray0[1] = 699.39216;
      doubleArray0[2] = 699.39216;
      doubleArray0[3] = 699.39216;
      doubleArray0[4] = 699.39216;
      doubleArray0[5] = 699.39216;
      doubleArray0[6] = 699.39216;
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      doubleArray0[7] = 699.39216;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(699.39216, doubleArray0);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) binarySparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 49
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test49()  throws Throwable  {
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)50;
      byteArray0[1] = (byte) (-84);
      byteArray0[3] = (byte)0;
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, true, true, true);
      byteArray0[4] = (byte)97;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      byte[] byteArray1 = new byte[3];
      byteArray1[1] = (byte)0;
      byteArray1[0] = (byte)70;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray1);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "Zao{L");
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (byte)70;
      doubleArray0[1] = (double) (byte)0;
      doubleArray0[2] = (double) (byte)97;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((byte)0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 50
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test50()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      naiveBayesMultinomialText0.getTokenizer();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 51
  /*Coverage entropy=2.070976373972562
  */
  @Test(timeout = 4000)
  public void test51()  throws Throwable  {
      System.setCurrentTimeMillis((-1517L));
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.useStopListTipText();
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.setPeriodicPruning((-2256));
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      Random.setNextRandom((-2256));
  }

  /**
  //Test case number: 52
  /*Coverage entropy=2.4267173502315558
  */
  @Test(timeout = 4000)
  public void test52()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification0Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification");
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)50;
      byteArray0[1] = (byte) (-84);
      byteArray0[2] = (byte) (-84);
      byteArray0[3] = (byte)0;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      byte[] byteArray1 = new byte[3];
      byteArray1[0] = (byte) (-1);
      byteArray1[1] = (byte)0;
      byteArray1[2] = (byte)70;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray1);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[5];
      stringArray0[0] = ",1MIZT&;`ok6fDz?";
      stringArray0[1] = "MXC;%8aRL7(&xzgRU";
      naiveBayesMultinomialText0.m_useStopList = true;
      stringArray0[2] = "MXC;%8aRL7(&xzgRU";
      stringArray0[3] = "^'>J";
      stringArray0[4] = ",1MIZT&;`ok6fDz?";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      Random.setNextRandom((byte) (-1));
  }

  /**
  //Test case number: 53
  /*Coverage entropy=2.781540041453182
  */
  @Test(timeout = 4000)
  public void test53()  throws Throwable  {
      byte[] byteArray0 = new byte[3];
      byteArray0[0] = (byte) (-1);
      byteArray0[1] = (byte) (-52);
      byteArray0[2] = (byte)70;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SGDText sGDText0 = new SGDText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.useStopListTipText();
      Stopwords stopwords0 = new Stopwords();
      instances0.toSummaryString();
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.m_stopwords = stopwords0;
      ArrayList<DenseInstance> arrayList0 = new ArrayList<DenseInstance>();
      MockFile mockFile0 = new MockFile("@relation", "If true, ignores all words that are on the stoplist.");
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText1.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string0);
      
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      
      String string1 = naiveBayesMultinomialText1.LNormTipText();
      assertEquals("The LNorm to use for document length normalization.", string1);
      
      String string2 = naiveBayesMultinomialText1.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string2);
      
      naiveBayesMultinomialText1.tokenizerTipText();
      assertEquals(3.0, naiveBayesMultinomialText1.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText1.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText1.getLNorm(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText1.getNorm(), 0.01);
  }

  /**
  //Test case number: 54
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test54()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      CharBuffer.wrap((CharSequence) "Headers match");
      char[] charArray0 = new char[9];
      charArray0[0] = 'x';
      charArray0[1] = ']';
      charArray0[2] = '&';
      charArray0[3] = '\"';
      charArray0[4] = '<';
      charArray0[5] = 'q';
      charArray0[6] = 'o';
      charArray0[7] = 'R';
  }

  /**
  //Test case number: 55
  /*Coverage entropy=3.269394275120508
  */
  @Test(timeout = 4000)
  public void test55()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = 0.0;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      StringReader stringReader0 = new StringReader("Headers match");
      StringReader stringReader1 = new StringReader("Headers match");
      CharBuffer charBuffer0 = CharBuffer.wrap((CharSequence) "Headers match");
      char[] charArray0 = new char[9];
      charArray0[0] = 'x';
      charArray0[1] = 'o';
      charArray0[2] = '&';
      charArray0[3] = '\"';
      charArray0[4] = '<';
      charArray0[5] = 'q';
      charArray0[6] = 'o';
      // Undeclared exception!
      try { 
        stringReader1.read(charBuffer0);
        fail("Expecting exception: ReadOnlyBufferException");
      
      } catch(ReadOnlyBufferException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.nio.StringCharBuffer", e);
      }
  }

  /**
  //Test case number: 56
  /*Coverage entropy=3.2696544884954752
  */
  @Test(timeout = 4000)
  public void test56()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm(12.73);
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      StringReader stringReader0 = new StringReader("Headers match");
      StringReader stringReader1 = new StringReader("Headers match");
      CharBuffer charBuffer0 = CharBuffer.wrap((CharSequence) "Headers match");
      char[] charArray0 = new char[9];
      charArray0[0] = 'y';
      charArray0[1] = 'y';
      charArray0[2] = '&';
      charArray0[0] = '\"';
      stringReader0.ready();
      StringReader stringReader2 = new StringReader("Headers match");
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0, 1469);
      BufferedReader bufferedReader1 = new BufferedReader(stringReader0);
      BufferedReader bufferedReader2 = new BufferedReader(stringReader0, 10000);
      CharBuffer.wrap((CharSequence) charBuffer0);
      // Undeclared exception!
      try { 
        stringReader2.read(charBuffer0);
        fail("Expecting exception: ReadOnlyBufferException");
      
      } catch(ReadOnlyBufferException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.nio.StringCharBuffer", e);
      }
  }

  /**
  //Test case number: 57
  /*Coverage entropy=3.192898685950695
  */
  @Test(timeout = 4000)
  public void test57()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      naiveBayesMultinomialText0.setNorm((-1589.05210735443));
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.setNorm((-1589.05210735443));
      naiveBayesMultinomialText0.normTipText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[1] = "org.tartarus.snowball.ext";
      stringArray0[2] = "The norm of the instances after normalization.";
      stringArray0[3] = "org.tartarus.snowball";
      stringArray0[4] = "org.tartarus.snowball";
      stringArray0[5] = "If true then document length is normalized according to the settings for norm and lnorm";
      stringArray0[6] = "org.tartarus.snowball";
      stringArray0[7] = "org.tartarus.snowball.ext";
      stringArray0[8] = "Whether to convert all tokens to lowercase";
      snowballStemmer0.setOptions(stringArray0);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.getRevision();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals((-1589.05210735443), naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 58
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test58()  throws Throwable  {
      String[] stringArray0 = new String[5];
      stringArray0[0] = "l}jz1>KHrQ\"[tkdU";
      stringArray0[1] = "Extracting data...";
      stringArray0[2] = "*P";
      stringArray0[3] = "s|)z9g8d{&oAiv";
      stringArray0[4] = "L*MY|<n~)n_$";
      NaiveBayesMultinomialText.main(stringArray0);
      assertEquals(5, stringArray0.length);
  }
}
