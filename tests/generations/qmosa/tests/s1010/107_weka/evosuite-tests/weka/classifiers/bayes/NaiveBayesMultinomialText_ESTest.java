/*
 * This file was automatically generated by EvoSuite
 * Sat Nov 16 09:10:06 GMT 2019
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.net.URISyntaxException;
import java.util.ArrayList;
import java.util.Locale;
import java.util.Properties;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.net.MockURI;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.LinearRegression;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.supportVector.Kernel;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.misc.SerializedClassifier;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.ProtectedProperties;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.neighboursearch.CoverTree;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.AlphabeticTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.estimators.KernelEstimator;
import weka.filters.Filter;
import weka.filters.MultiFilter;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.009298287305441
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      testInstances0.setNoClass(true);
      Instances instances0 = testInstances0.generate(" ");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_normalize = true;
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Class attribute not set!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=3.59037912687189
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("-stopwords <file>/Sets whether the number of LogitBoost iterations is to be cross-validated or the stopping criterion on the training set should be used. If not set (and no fixed number of iterations was given), the number of LogitBoost iterations is used that minimizes the error on the training set (misclassification error or error on probabilities depending on errorOnProbabilities)./o09$E.{@'nFF0itousness");
      FileSystemHandling.createFolder(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = 0.0;
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "*");
      naiveBayesMultinomialText0.LNormTipText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) alphabeticTokenizer0;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      MockFile mockFile0 = new MockFile("/xF4U4w=[yr0r0M", "The LNorm to use for document length normalization.");
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      System.setCurrentTimeMillis(42L);
      System.setCurrentTimeMillis(634L);
      naiveBayesMultinomialText0.normTipText();
      mockFile0.mkdirs();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel2 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel3 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel4 = new PrecomputedKernelMatrixKernel();
      Kernel.makeCopies(precomputedKernelMatrixKernel1, 36);
      precomputedKernelMatrixKernel4.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel5 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel6 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel7 = new PrecomputedKernelMatrixKernel();
      naiveBayesMultinomialText0.useStopListTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertEquals(0.0, double0, 0.01);
  }

  /**
  //Test case number: 2
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances(")", arrayList0, 289);
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: No attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 3
  /*Coverage entropy=2.368373327680306
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(13);
      SparseInstance sparseInstance0 = new SparseInstance(13);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "w5eX>JEk#";
      stringArray0[1] = "-stemmer";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No value given for -stemmer option.
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.2567576795645348
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "ztN";
      stringArray0[2] = "bwC=(rk+HX H";
      stringArray0[3] = "";
      stringArray0[4] = "-stemmer";
      stringArray0[5] = "-stemmer";
      stringArray0[6] = "w5eX>JEk#";
      stringArray0[7] = "}[fwGG,N";
      stringArray0[8] = "The tokenizing algorithm to use on the strings.";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: ClassNotFoundException");
      
      } catch(ClassNotFoundException e) {
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=2.298139573011908
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(true);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.toString();
      SparseInstance sparseInstance0 = null;
      try {
        sparseInstance0 = new SparseInstance((-2));
        fail("Expecting exception: NegativeArraySizeException");
      
      } catch(NegativeArraySizeException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.SparseInstance", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=2.6014480335519155
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      testInstances1.assign(testInstances0);
      Instances instances0 = testInstances1.generate(" ");
      testInstances0.setNumNumeric(1398);
      testInstances1.setClassType((-4689));
      Instances instances1 = new Instances(instances0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      instances0.deleteStringAttributes();
      naiveBayesMultinomialText0.setPeriodicPruning(2803);
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      alphabeticTokenizer0.tokenize(".arff");
      alphabeticTokenizer0.setOptions(testInstances0.DEFAULT_WORDS);
      Tokenizer.runTokenizer(alphabeticTokenizer0, testInstances1.DEFAULT_WORDS);
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      String[] stringArray0 = new String[9];
      stringArray0[0] = ".arff";
      stringArray0[1] = " ";
      testInstances1.setNoClass(false);
      stringArray0[2] = "";
      stringArray0[3] = ".arff";
      stringArray0[4] = ".bsi";
      stringArray0[5] = " ";
      stringArray0[6] = "";
      stringArray0[7] = "@data";
      stringArray0[8] = "@relation";
      Tokenizer.runTokenizer(wordTokenizer0, stringArray0);
      String[] stringArray1 = TestInstances.DEFAULT_WORDS;
      naiveBayesMultinomialText0.setNorm(1645.735);
      naiveBayesMultinomialText0.setMinWordFrequency(2803);
      File file0 = MockFile.createTempFile("The LNorm to use for document length normalization.", "/numPackages.txt");
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.pruneDictionary();
      assertEquals(2803, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 7
  /*Coverage entropy=3.256327362913385
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      testInstances0.generate();
      Instances instances0 = testInstances0.generate("Num Instances:  ");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.LNormTipText();
      testInstances0.getRelationalClassFormat();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setOptions(testInstances0.DEFAULT_WORDS);
      TestInstances testInstances1 = new TestInstances();
      TestInstances testInstances2 = new TestInstances();
      naiveBayesMultinomialText0.setPeriodicPruning((-2));
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      alphabeticTokenizer0.tokenize(".bsi");
      AlphabeticTokenizer alphabeticTokenizer1 = new AlphabeticTokenizer();
      alphabeticTokenizer0.setOptions(testInstances0.DEFAULT_WORDS);
      Tokenizer.runTokenizer(alphabeticTokenizer1, testInstances0.DEFAULT_WORDS);
      String[] stringArray0 = new String[4];
      stringArray0[0] = "Num Instances:  ";
      stringArray0[1] = "@relation";
      stringArray0[2] = "The independent probability of a class\n--------------------------------------\nclass1\t11.0\nclass2\t11.0\n\nThe probability of a word given the class\n-----------------------------------------\n\tclass1\tclass2\t\n";
      stringArray0[3] = "@data";
      Tokenizer.runTokenizer(alphabeticTokenizer0, stringArray0);
      String[] stringArray1 = TestInstances.DEFAULT_WORDS;
      naiveBayesMultinomialText0.setNorm(1.0);
      naiveBayesMultinomialText1.setMinWordFrequency(1.0);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText1.getMinWordFrequency();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel1.getKernelMatrixFile();
      naiveBayesMultinomialText1.listOptions();
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getTokenizer();
      assertEquals((-2), naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 8
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[2] = "bwC=(rk+HX H";
      stringArray0[3] = "";
      stringArray0[4] = "-stemmer";
      Tokenizer.runTokenizer((Tokenizer) null, stringArray0);
      String[] stringArray1 = TestInstances.DEFAULT_WORDS;
      naiveBayesMultinomialText0.setNorm(1645.735);
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getMinWordFrequency();
      System.setCurrentTimeMillis(0L);
      Random.setNextRandom((-1));
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.6709087878625355
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      precomputedKernelMatrixKernel0.getOptions();
      naiveBayesMultinomialText0.m_stopwordsFile = file0;
      File file1 = MockFile.createTempFile("S`M3<)", "S`M3<)");
      precomputedKernelMatrixKernel0.setKernelMatrixFile(file1);
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      String string0 = naiveBayesMultinomialText0.getRevision();
      assertEquals("9122", string0);
      
      int int0 = naiveBayesMultinomialText0.getPeriodicPruning();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, int0);
      
      naiveBayesMultinomialText0.m_wordFrequencies = false;
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertEquals(1.0, double0, 0.01);
      
      naiveBayesMultinomialText0.m_t = 1.0;
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.getTokenizer();
      precomputedKernelMatrixKernel0.toString();
      System.setCurrentTimeMillis(0L);
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Random.setNextRandom(0);
      String string1 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string1);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 10
  /*Coverage entropy=2.108838365573966
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_leplace = (-56.009422592);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      SerializedClassifier serializedClassifier1 = new SerializedClassifier();
      serializedClassifier0.getModelFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.setChecksTurnedOff(false);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.getKernelMatrixFile();
      MultiFilter multiFilter0 = new MultiFilter();
      Filter.makeCopy(multiFilter0);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel2 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel3 = new PrecomputedKernelMatrixKernel();
      TestInstances testInstances1 = new TestInstances();
      testInstances1.setClassIndex((-1693));
      precomputedKernelMatrixKernel2.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel4 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel5 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel6 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel7 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel8 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel8.getKernelMatrixFile();
      assertEquals(0L, file0.lastModified());
  }

  /**
  //Test case number: 11
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      double[] doubleArray0 = new double[3];
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      doubleArray0[0] = 1.0;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = 1047.87;
      naiveBayesMultinomialText0.m_probOfClass = doubleArray0;
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.toString();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(13);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(13);
      SparseInstance sparseInstance0 = new SparseInstance((Instance) binarySparseInstance0);
      binarySparseInstance0.toStringNoWeight((-1946));
      SparseInstance sparseInstance1 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      binarySparseInstance0.toStringNoWeight();
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance5 = new BinarySparseInstance((SparseInstance) binarySparseInstance4);
      DenseInstance denseInstance0 = new DenseInstance(binarySparseInstance5);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      DenseInstance denseInstance1 = new DenseInstance(13);
      BinarySparseInstance binarySparseInstance6 = new BinarySparseInstance(17);
      binarySparseInstance6.copy();
      binarySparseInstance4.isMissing((-4624));
      SparseInstance sparseInstance2 = new SparseInstance((SparseInstance) binarySparseInstance1);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance2);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("-stopwords <file>/Sets whether the number of LogitBoost iterations is to be cross-validated or the stopping criterion on the training set should be used. If not set (and no fixed number of iterations was given), the number of LogitBoost iterations is used that minimizes the error on the training set (misclassification error or error on probabilities depending on errorOnProbabilities)./o09$E.{@'nFF0itousness");
      FileSystemHandling.createFolder(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      KernelEstimator kernelEstimator0 = new KernelEstimator((-1.0));
      Capabilities capabilities0 = kernelEstimator0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Attribute attribute0 = new Attribute("", 255);
      instances0.setClass(attribute0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.buildClassifier(instances0);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 255, Size: 1
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=1.8408398156653452
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      LinearRegression linearRegression0 = new LinearRegression();
      Capabilities capabilities0 = linearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText1.buildClassifier(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.classifiers.bayes.NaiveBayesMultinomialText: Cannot handle numeric class!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 15
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      testInstances0.getData();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 16
  /*Coverage entropy=1.830738805564335
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_stopwords = null;
      String[] stringArray0 = new String[5];
      stringArray0[1] = "aical";
      stringArray0[2] = "ym~-b15b2bG5zr<'h";
      naiveBayesMultinomialText0.setLNorm(0);
      naiveBayesMultinomialText0.setNorm(307.1480932146625);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(307.1480932146625, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  /**
  //Test case number: 17
  /*Coverage entropy=2.2623477045221723
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      testInstances0.assign(testInstances1);
      testInstances1.generate(" ");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Properties properties0 = new Properties();
      ProtectedProperties protectedProperties0 = new ProtectedProperties(properties0);
      naiveBayesMultinomialText0.setPeriodicPruning(82);
      naiveBayesMultinomialText0.getPeriodicPruning();
      naiveBayesMultinomialText0.getPeriodicPruning();
      SystemInUtil.addInputLine("w{");
      naiveBayesMultinomialText0.getNorm();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setLNorm((-1));
      naiveBayesMultinomialText0.setNorm((-1890.9698654149934));
      String string0 = "6G+[*YIvc";
      MockFile mockFile0 = new MockFile(".bsi", "6G+[*YIvc");
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      serializedClassifier0.setDebug(false);
      SerializedClassifier serializedClassifier1 = new SerializedClassifier();
      serializedClassifier1.getModelFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.getKernelMatrixFile();
      try { 
        MockURI.URI("", ".bsi", " ", "NCx_'J+1IP", "@relation");
        fail("Expecting exception: URISyntaxException");
      
      } catch(URISyntaxException e) {
         //
         // Relative path in absolute URI: ://.bsi%20?NCx_'J+1IP#@relation
         //
         verifyException("java.net.URI", e);
      }
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.022248870579868
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "");
      FileSystemHandling.shouldAllThrowIOExceptions();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.setPeriodicPruning(93);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "| t&jymC\"ICZ";
      stringArray0[1] = "";
      Tokenizer.runTokenizer(alphabeticTokenizer0, stringArray0);
      naiveBayesMultinomialText0.setNorm(691.7832598311);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file0 = serializedClassifier0.getModelFile();
      MockFile mockFile0 = new MockFile(file0, "| t&jymC\"ICZ");
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getStopwords();
      assertEquals(93, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 19
  /*Coverage entropy=3.590058459884556
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) alphabeticTokenizer0;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      MockFile mockFile0 = new MockFile("/xF4U4w=[yr0r0M", "-stopwords <ile>");
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      System.setCurrentTimeMillis(1585L);
      naiveBayesMultinomialText0.normTipText();
      mockFile0.mkdirs();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel2 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel3 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel4 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel4.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel5 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel6 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel7 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel7.getKernelMatrixFile();
      precomputedKernelMatrixKernel4.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel8 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel9 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel10 = new PrecomputedKernelMatrixKernel();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      Random.setNextRandom(77);
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.063983366979555
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      testInstances1.assign(testInstances0);
      Instances instances0 = testInstances1.generate(" ");
      testInstances0.setNumNumeric(1398);
      testInstances1.setClassType((-4689));
      Instances instances1 = new Instances(instances0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      AlphabeticTokenizer alphabeticTokenizer1 = new AlphabeticTokenizer();
      alphabeticTokenizer1.tokenize("=n'`KJUMq?W)");
      alphabeticTokenizer0.setOptions(testInstances0.DEFAULT_WORDS);
      Tokenizer.runTokenizer(alphabeticTokenizer1, testInstances1.DEFAULT_WORDS);
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      testInstances1.setNoClass(false);
      Tokenizer.runTokenizer(alphabeticTokenizer0, testInstances1.DEFAULT_WORDS);
      String[] stringArray0 = TestInstances.DEFAULT_WORDS;
      naiveBayesMultinomialText0.setNorm(1398);
      naiveBayesMultinomialText0.setMinWordFrequency((-1));
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getMinWordFrequency();
      System.setCurrentTimeMillis((-4689));
      Random.setNextRandom(1398);
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.6868977693384446
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "ztN";
      stringArray0[2] = "bwC=(rk+HX H";
      stringArray0[3] = "";
      stringArray0[4] = "-stemmer";
      stringArray0[5] = "weka.core.neighboursearch.balltrees.MedianDistanceFromArbitraryPoint";
      stringArray0[6] = "w5eX>JEk#";
      stringArray0[7] = "[fHwGGx,ON";
      System.setCurrentTimeMillis((-1189L));
      Random.setNextRandom((-1945));
      naiveBayesMultinomialText0.useStopListTipText();
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      File file1 = MockFile.createTempFile("-decimals", "", file0);
      naiveBayesMultinomialText0.setStopwords(file1);
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 22
  /*Coverage entropy=3.1483487414730105
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.LNormTipText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getOptions();
      // Undeclared exception!
      try { 
        testInstances0.setRelationalFormat((-2), instances0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -2
         //
         verifyException("weka.core.TestInstances", e);
      }
  }

  /**
  //Test case number: 23
  /*Coverage entropy=3.325943460438359
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      SparseInstance sparseInstance0 = new SparseInstance((Instance) binarySparseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      MockFile mockFile0 = new MockFile("~");
      mockFile0.setReadable(true, true);
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      naiveBayesMultinomialText0.LNormTipText();
      naiveBayesMultinomialText0.setDebug(true);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setNormalizeDocLength(true);
      naiveBayesMultinomialText1.useStopListTipText();
      naiveBayesMultinomialText1.stopwordsTipText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.setStopwords(mockFile0);
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText1.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.setOptions(stringArray1);
      naiveBayesMultinomialText0.setNorm(2599.19855818812);
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.setNorm(77.00297526690389);
      assertEquals(0.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.823770781636355
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNorm((-1.0));
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.setLNorm(0.0);
      naiveBayesMultinomialText0.setNorm(270.1381621754);
      naiveBayesMultinomialText0.setLNorm(0.0);
      assertEquals(270.1381621754, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 25
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(13);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(13);
      SparseInstance sparseInstance0 = new SparseInstance((Instance) binarySparseInstance0);
      binarySparseInstance0.deleteAttributeAt(1932735253);
      binarySparseInstance0.toStringNoWeight((-1946));
      SparseInstance sparseInstance1 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      binarySparseInstance0.toStringNoWeight();
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance5 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      DenseInstance denseInstance0 = new DenseInstance(binarySparseInstance5);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      DenseInstance denseInstance1 = new DenseInstance(13);
      binarySparseInstance0.copy();
      binarySparseInstance1.isMissing(13);
      SparseInstance sparseInstance2 = new SparseInstance((SparseInstance) binarySparseInstance4);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=3.2179188410897126
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.setPeriodicPruning(93);
      String[] stringArray0 = new String[6];
      stringArray0[0] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[1] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[2] = "Dk";
      stringArray0[3] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      Tokenizer.runTokenizer(alphabeticTokenizer0, stringArray0);
      naiveBayesMultinomialText0.setTokenizer((Tokenizer) null);
      naiveBayesMultinomialText0.setNorm(93);
      naiveBayesMultinomialText0.setNorm(1.0);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.getOptions();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.6969987794394548
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_probOfClass = null;
      naiveBayesMultinomialText0.toString();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText1.tokenizeInstance((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 28
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(13);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(1);
      SparseInstance sparseInstance0 = new SparseInstance((Instance) binarySparseInstance2);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      SparseInstance sparseInstance2 = new SparseInstance(99);
      SparseInstance sparseInstance3 = new SparseInstance((Instance) binarySparseInstance0);
      DenseInstance denseInstance0 = new DenseInstance(binarySparseInstance1);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      DenseInstance denseInstance1 = new DenseInstance(35);
      try { 
        naiveBayesMultinomialText0.updateClassifier(denseInstance1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 29
  /*Coverage entropy=2.2567576795645348
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "ztN";
      stringArray0[2] = "bwC=(rk+HX H";
      stringArray0[3] = "";
      stringArray0[4] = "-stemmer";
      stringArray0[5] = "weka.core.neighboursearch.balltrees.MedianDistanceFromArbitraryPoint";
      stringArray0[6] = "w5eX>JEk#";
      stringArray0[7] = "[fHwGGx,ON";
      stringArray0[8] = "RtTs";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // weka.core.neighboursearch.balltrees.MedianDistanceFromArbitraryPoint cannot be cast to weka.core.stemmers.Stemmer
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=1.5271837172395382
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "ztN";
      stringArray0[2] = "bwC=(rk+HX H";
      stringArray0[1] = "";
      stringArray0[4] = "-stemmer";
      stringArray0[5] = "weka.core.neighboursearch.balltrees.MedianDistanceFromArbitraryPoint";
      stringArray0[6] = "w5eX>JEk#";
      stringArray0[7] = "[fwGG,N";
      stringArray0[8] = "The tokenizing algorithm to use on the strings.";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 31
  /*Coverage entropy=3.486071407135196
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "\tSpecify L-norm to use (default 2.0)";
      stringArray0[1] = "Ashraf Masood Kibriya";
      stringArray0[2] = "Invalid stemmer specification string";
      stringArray0[3] = "";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText0.m_stopwords = null;
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.setLowercaseTokens(true);
      Tokenizer tokenizer0 = naiveBayesMultinomialText0.getTokenizer();
      Tokenizer.runTokenizer(tokenizer0, stringArray0);
      naiveBayesMultinomialText0.listOptions();
      naiveBayesMultinomialText0.setTokenizer(tokenizer0);
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setNorm(787.381911935983);
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setMinWordFrequency((-685.4));
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.m_minWordP = (-685.4);
      naiveBayesMultinomialText1.lowercaseTokensTipText();
      naiveBayesMultinomialText1.periodicPruningTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 32
  /*Coverage entropy=3.4763993264720776
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[0];
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.setUseStopList(true);
      SystemInUtil.addInputLine(" whereas it is found to be: ");
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.setStemmer((Stemmer) null);
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      naiveBayesMultinomialText0.setDebug(true);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.setMinWordFrequency((-1260.74609));
      naiveBayesMultinomialText0.m_minWordP = (-1.0);
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.setPeriodicPruning(2762);
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.m_norm = 304.67235855;
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.getLNorm();
      naiveBayesMultinomialText0.useStopListTipText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.normTipText();
      assertEquals(2762, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 33
  /*Coverage entropy=2.727829997593668
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(13);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setOptions((String[]) null);
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      testInstances1.assign(testInstances0);
      testInstances0.getRelationalClassFormat();
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.setNorm(0.0);
      naiveBayesMultinomialText0.setLNorm((-2));
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals((-2.0), double0, 0.01);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=3.5906696134368867
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(true);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "*");
      naiveBayesMultinomialText0.LNormTipText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      MockFile mockFile0 = new MockFile((String) null, "-stopwords <ile>");
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.tokenizerTipText();
      naiveBayesMultinomialText1.stopwordsTipText();
      System.setCurrentTimeMillis(42L);
      System.setCurrentTimeMillis(42L);
      naiveBayesMultinomialText0.normTipText();
      mockFile0.mkdirs();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel2 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel3 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel1.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel4 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel2.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel5 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel6 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel7 = new PrecomputedKernelMatrixKernel();
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.useStopListTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.normTipText();
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 35
  /*Coverage entropy=2.0642222749513333
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate(" ");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_normalize = true;
      naiveBayesMultinomialText0.buildClassifier(instances0);
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      SerializedClassifier serializedClassifier1 = new SerializedClassifier();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.setChecksTurnedOff(true);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel2 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel2.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel3 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel4 = new PrecomputedKernelMatrixKernel();
      TestInstances testInstances1 = new TestInstances();
      testInstances0.setClassIndex(10000);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel5 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel1.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel6 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel7 = new PrecomputedKernelMatrixKernel();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel8 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel9 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel10 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel11 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel12 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel9.getKernelMatrixFile();
      assertEquals("kernelMatrix.matrix", file0.getName());
  }

  /**
  //Test case number: 36
  /*Coverage entropy=2.3489234016633707
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_periodicP = 200;
      naiveBayesMultinomialText0.buildClassifier(instances0);
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.LNormTipText();
      // Undeclared exception!
      try { 
        testInstances0.setRelationalFormat((-2), instances0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -2
         //
         verifyException("weka.core.TestInstances", e);
      }
  }

  /**
  //Test case number: 37
  /*Coverage entropy=2.015255863586861
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      Tokenizer.runTokenizer(alphabeticTokenizer0, (String[]) null);
      Tokenizer.runTokenizer(alphabeticTokenizer0, (String[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int int0 = 70;
      naiveBayesMultinomialText0.setPeriodicPruning(70);
      alphabeticTokenizer0.tokenize("T7LQ@XGA>]CC(=pL");
      Tokenizer.runTokenizer(alphabeticTokenizer0, (String[]) null);
      Tokenizer.runTokenizer(alphabeticTokenizer0, (String[]) null);
      String[] stringArray0 = TestInstances.DEFAULT_WORDS;
      naiveBayesMultinomialText0.setNorm((-3421.956828793503));
      naiveBayesMultinomialText0.setMinWordFrequency(1293.355153);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 38
  /*Coverage entropy=2.738840717855686
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "whom");
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(13);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(13);
      SparseInstance sparseInstance0 = new SparseInstance((Instance) binarySparseInstance2);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance2);
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile1);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) binarySparseInstance2);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "f1:/D]r%iK`Xv%";
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      stringArray0[1] = "Thirteenth International Conference on Machine Learning";
      stringArray0[2] = "'49{Mwe VK0ey[`Q#";
      stringArray0[3] = "";
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.getOptions();
      CoverTree coverTree0 = new CoverTree();
      // Undeclared exception!
      try { 
        sparseInstance0.insertAttributeAt(23);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Can't insert attribute: index out of range
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 39
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      TestInstances testInstances1 = new TestInstances();
      testInstances1.assign(testInstances0);
      TestInstances testInstances2 = new TestInstances();
      testInstances0.assign(testInstances2);
      testInstances0.generate(" ");
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning((-2));
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      alphabeticTokenizer0.tokenize("@data");
      alphabeticTokenizer0.setOptions(testInstances1.DEFAULT_WORDS);
      Tokenizer.runTokenizer(alphabeticTokenizer0, testInstances2.DEFAULT_WORDS);
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      testInstances2.setNoClass(true);
      String[] stringArray0 = new String[2];
      stringArray0[0] = " ";
      stringArray0[1] = "m";
      Tokenizer.runTokenizer(wordTokenizer0, stringArray0);
      String[] stringArray1 = TestInstances.DEFAULT_WORDS;
      naiveBayesMultinomialText0.setNorm((-4781.343140049092));
      naiveBayesMultinomialText0.setMinWordFrequency(12.0);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getMinWordFrequency();
      System.setCurrentTimeMillis(0L);
      Random.setNextRandom((-2580));
  }

  /**
  //Test case number: 40
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "ztN";
      stringArray0[2] = "bwC=(rk+HX H";
      stringArray0[3] = "";
      stringArray0[4] = "-stemmer";
      stringArray0[5] = "weka.core.neighboursearch.balltrees.MedianDistanceFromArbitraryPoint";
      stringArray0[6] = "w5eX>JEk#";
      stringArray0[7] = "[fwGG,N";
      stringArray0[8] = "The tokenizing algorithm to use on the strings.";
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.globalInfo();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 41
  /*Coverage entropy=2.7853437136837007
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      String[] stringArray0 = new String[5];
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) alphabeticTokenizer0;
      stringArray0[0] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[1] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[2] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[3] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      stringArray0[4] = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      Tokenizer.runTokenizer(alphabeticTokenizer0, stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      boolean boolean0 = naiveBayesMultinomialText1.m_wordFrequencies;
      assertFalse(boolean0);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.tokenizerTipText();
      naiveBayesMultinomialText1.stemmerTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      double double0 = naiveBayesMultinomialText2.m_minWordP;
      naiveBayesMultinomialText0.useStopListTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText4 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stopwordsTipText();
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 42
  /*Coverage entropy=1.2961346570528898
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(13);
      SparseInstance sparseInstance0 = new SparseInstance(13);
      binarySparseInstance0.toStringNoWeight((-1946));
      SparseInstance sparseInstance1 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      binarySparseInstance0.toStringNoWeight();
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance((SparseInstance) binarySparseInstance3);
      DenseInstance denseInstance0 = new DenseInstance(binarySparseInstance4);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      DenseInstance denseInstance1 = new DenseInstance(13);
      BinarySparseInstance binarySparseInstance5 = new BinarySparseInstance(13);
      BinarySparseInstance binarySparseInstance6 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance7 = new BinarySparseInstance((Instance) binarySparseInstance0);
      binarySparseInstance7.isMissing(13);
      BinarySparseInstance binarySparseInstance8 = new BinarySparseInstance(13);
      SparseInstance sparseInstance2 = new SparseInstance((SparseInstance) binarySparseInstance8);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance2);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 43
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      try { 
        naiveBayesMultinomialText0.updateClassifier((Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 44
  /*Coverage entropy=1.3788419678046633
  */
  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_stopwords = null;
      String[] stringArray0 = new String[5];
      stringArray0[0] = "F@hA-#n8&hskrqnQzb";
      stringArray0[1] = "aical";
      stringArray0[2] = "ym~-b15b2bG5zxr<th";
      stringArray0[3] = "";
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file0 = serializedClassifier0.getModelFile();
      MockFile mockFile0 = new MockFile(file0, "b");
      naiveBayesMultinomialText0.setStopwords((File) null);
      naiveBayesMultinomialText0.getStopwords();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 45
  /*Coverage entropy=3.590222852454012
  */
  @Test(timeout = 4000)
  public void test45()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.LNormTipText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) alphabeticTokenizer0;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(12, stringArray0.length);
      
      MockFile mockFile0 = new MockFile("/xF4U4w=[yr0r0M", "The LNorm to use for document length normalization.");
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      
      String string1 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string1);
      
      System.setCurrentTimeMillis(1585L);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel2 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel3 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel4 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel1.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel5 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel6 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel7 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel5.getKernelMatrixFile();
      MockFile mockFile1 = new MockFile("The LNorm to use for document length normalization.", "The LNorm to use for document length normalization.");
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel8 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel9 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel10 = new PrecomputedKernelMatrixKernel();
      String string2 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string2);
      
      String string3 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string3);
      
      String string4 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals("Whether to convert all tokens to lowercase", string4);
      
      String string5 = naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string5);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 46
  /*Coverage entropy=2.419594359581629
  */
  @Test(timeout = 4000)
  public void test46()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(13);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(1);
      SparseInstance sparseInstance0 = new SparseInstance((Instance) binarySparseInstance2);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance(13);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.getLowercaseTokens();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.tokenizerTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      double double0 = naiveBayesMultinomialText0.m_minWordP;
      naiveBayesMultinomialText0.useStopListTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.stopwordsTipText();
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
  }

  /**
  //Test case number: 47
  /*Coverage entropy=3.3994042323820763
  */
  @Test(timeout = 4000)
  public void test47()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("-stopwords <file>/Sets whether the number of LogitBoost iterations is to be cross-validated or the stopping criterion on the training set should be used. If not set (and no fixed number of iterations was given), the number of LogitBoost iterations is used that minimizes the error on the training set (misclassification error or error on probabilities depending on errorOnProbabilities)./o09$E.{@'nFF0itousness");
      FileSystemHandling.createFolder(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.LNormTipText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      String[] stringArray0 = new String[8];
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) alphabeticTokenizer0;
      stringArray0[0] = "The LNorm to use for document length normalization.";
      String[] stringArray1 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray1);
      String string0 = "Sets whether the number of LogitBoost iterations is to be cross-validated or the stopping criterion on the training set should be used. If not set (and no fixed number of iterations was given), the number of LogitBoost iterations is used that minimizes the error on the training set (misclassification error or error on probabilities depending on errorOnProbabilities).";
      MockFile mockFile0 = new MockFile("/xF4U4w=[yr0r0M", "-stopwords <ile>");
      mockFile0.mkdirs();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      mockFile0.mkdir();
      double double0 = naiveBayesMultinomialText0.m_minWordP;
      try { 
        MockURI.URI("Uq;ds+JX*8:`vUUy", "If true then document length is normalized according to the settings for norm and lnorm", "noj}zs$/", "The stemming algorithm to use on the words.", (String) null);
        fail("Expecting exception: URISyntaxException");
      
      } catch(URISyntaxException e) {
         //
         // Relative path in absolute URI: Uq;ds+JX*8:`vUUy://If%20true%20then%20document%20length%20is%20normalized%20according%20to%20the%20settings%20for%20norm%20and%20lnormnoj%7Dzs$/?The%20stemming%20algorithm%20to%20use%20on%20the%20words.
         //
         verifyException("java.net.URI", e);
      }
  }

  /**
  //Test case number: 48
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test48()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Random.setNextRandom(120);
      boolean boolean0 = naiveBayesMultinomialText0.getUseWordFrequencies();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(boolean0);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 49
  /*Coverage entropy=2.253297930766516
  */
  @Test(timeout = 4000)
  public void test49()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("-stopwords <file>/Sets whether the number of LogitBoost iterations is to be cross-validated or the stopping criterion on the training set should be used. If not set (and no fixed number of iterations was given), the number of LogitBoost iterations is used that minimizes the error on the training set (misclassification error or error on probabilities depending on errorOnProbabilities)./o09$E.{@'nFF0itousness");
      FileSystemHandling.createFolder(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.LNormTipText();
      SystemInUtil.addInputLine("Eliminate colinear attributes.");
      naiveBayesMultinomialText0.getNorm();
      naiveBayesMultinomialText0.setLNorm(1.0);
      naiveBayesMultinomialText0.setNorm((-2336.56));
      MockFile mockFile0 = new MockFile("% cached)", ")_x}@e");
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      serializedClassifier0.setDebug(true);
      serializedClassifier0.getModelFile();
      MockFile mockFile1 = new MockFile("indicate", "% cached)");
      MockFile mockFile2 = new MockFile(mockFile0, ";/=F");
      assertFalse(mockFile2.equals((Object)mockFile0));
  }

  /**
  //Test case number: 50
  /*Coverage entropy=3.572804529428276
  */
  @Test(timeout = 4000)
  public void test50()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("-stopwords <file>/Sets whether the number of LogitBoost iterations is to be cross-validated or the stopping criterion on the training set should be used. If not set (and no fixed number of iterations was given), the number of LogitBoost iterations is used that minimizes the error on the training set (misclassification error or error on probabilities depending on errorOnProbabilities)./o09$E.{@'nFF0itousness");
      FileSystemHandling.createFolder(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = 0.0;
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "*");
      naiveBayesMultinomialText0.LNormTipText();
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) alphabeticTokenizer0;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      MockFile mockFile0 = new MockFile("/xF4U4w=[yr0r0M", "-stopwords <ile>");
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      mockFile0.toURI();
      System.setCurrentTimeMillis(42L);
      System.setCurrentTimeMillis(634L);
      naiveBayesMultinomialText0.normTipText();
      mockFile0.mkdirs();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel1 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel2 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel3 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel4 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel4.getKernelMatrixFile();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel5 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel6 = new PrecomputedKernelMatrixKernel();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel7 = new PrecomputedKernelMatrixKernel();
      naiveBayesMultinomialText0.useStopListTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.useWordFrequenciesTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.setStopwords(file0);
      assertEquals(0.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 51
  /*Coverage entropy=0.9623351446188083
  */
  @Test(timeout = 4000)
  public void test51()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(13);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(1);
      SparseInstance sparseInstance0 = new SparseInstance((Instance) binarySparseInstance2);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file0 = serializedClassifier0.getModelFile();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setStopwords(file0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 52
  /*Coverage entropy=1.0931471805599453
  */
  @Test(timeout = 4000)
  public void test52()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(13);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(13);
      SparseInstance sparseInstance0 = new SparseInstance(13);
      binarySparseInstance0.toStringNoWeight((-1946));
      SparseInstance sparseInstance1 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance((SparseInstance) binarySparseInstance2);
      binarySparseInstance0.toStringNoWeight();
      BinarySparseInstance binarySparseInstance4 = new BinarySparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance5 = new BinarySparseInstance((SparseInstance) binarySparseInstance4);
      DenseInstance denseInstance0 = new DenseInstance(binarySparseInstance5);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      DenseInstance denseInstance1 = new DenseInstance(13);
      BinarySparseInstance binarySparseInstance6 = new BinarySparseInstance(13);
      BinarySparseInstance binarySparseInstance7 = new BinarySparseInstance((SparseInstance) binarySparseInstance1);
      BinarySparseInstance binarySparseInstance8 = new BinarySparseInstance((Instance) binarySparseInstance1);
      naiveBayesMultinomialText0.getUseStopList();
      BinarySparseInstance binarySparseInstance9 = new BinarySparseInstance(13);
      SparseInstance sparseInstance2 = new SparseInstance((SparseInstance) binarySparseInstance9);
      double[] doubleArray0 = naiveBayesMultinomialText0.m_wordsPerClass;
      Random.setNextRandom(419);
  }

  /**
  //Test case number: 53
  /*Coverage entropy=2.723789593553264
  */
  @Test(timeout = 4000)
  public void test53()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("-stopwords <file>/Sets whether the number of LogitBoost iterations is to be cross-validated or the stopping criterion on the training set should be used. If not set (and no fixed number of iterations was given), the number of LogitBoost iterations is used that minimizes the error on the training set (misclassification error or error on probabilities depending on errorOnProbabilities)./o09$E.{@'nFF0itousness");
      FileSystemHandling.createFolder(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.LNormTipText();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "The LNorm to use for document length normalization.";
      String[] stringArray1 = Locale.getISOLanguages();
      naiveBayesMultinomialText0.setOptions(stringArray1);
      String string0 = "Sets whether the number of LogitBoost iterations is to be cross-validated or the stopping criterion on the training set should be used. If not set (and no fixed number of iterations was given), the number of LogitBoost iterations is used that minimizes the error on the training set (misclassification error or error on probabilities depending on errorOnProbabilities).";
      MockFile mockFile0 = new MockFile("/xF4U4w=[yr0r0M", "-stopwords <ile>");
      mockFile0.mkdirs();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      mockFile0.mkdir();
      double double0 = naiveBayesMultinomialText0.m_minWordP;
      naiveBayesMultinomialText1.setLowercaseTokens(true);
      try { 
        MockURI.URI("Uq;ds+JX*8:`vUUy", "If true then document length is normalized according to the settings for norm and lnorm", "noj}zs$/", "The stemming algorithm to use on the words.", (String) null);
        fail("Expecting exception: URISyntaxException");
      
      } catch(URISyntaxException e) {
         //
         // Relative path in absolute URI: Uq;ds+JX*8:`vUUy://If%20true%20then%20document%20length%20is%20normalized%20according%20to%20the%20settings%20for%20norm%20and%20lnormnoj%7Dzs$/?The%20stemming%20algorithm%20to%20use%20on%20the%20words.
         //
         verifyException("java.net.URI", e);
      }
  }

  /**
  //Test case number: 54
  /*Coverage entropy=2.419594359581629
  */
  @Test(timeout = 4000)
  public void test54()  throws Throwable  {
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance(13);
      BinarySparseInstance binarySparseInstance2 = new BinarySparseInstance(1);
      SparseInstance sparseInstance0 = new SparseInstance((Instance) binarySparseInstance2);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      BinarySparseInstance binarySparseInstance3 = new BinarySparseInstance(13);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText1.tokenizerTipText();
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      
      String string1 = naiveBayesMultinomialText0.stemmerTipText();
      assertEquals("The stemming algorithm to use on the words.", string1);
      
      String string2 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string2);
      
      double double0 = naiveBayesMultinomialText0.m_minWordP;
      assertEquals(3.0, double0, 0.01);
      
      String string3 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals("If true, ignores all words that are on the stoplist.", string3);
      
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      String string4 = naiveBayesMultinomialText0.stopwordsTipText();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string4);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
  }

  /**
  //Test case number: 55
  /*Coverage entropy=2.41257681572198
  */
  @Test(timeout = 4000)
  public void test55()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/termite/projects/107_weka");
      FileSystemHandling.createFolder(evoSuiteFile0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getNorm();
      NullStemmer nullStemmer0 = (NullStemmer)naiveBayesMultinomialText0.m_stemmer;
      naiveBayesMultinomialText0.setStemmer(nullStemmer0);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      
      naiveBayesMultinomialText0.setLNorm(1.0);
      naiveBayesMultinomialText0.setNorm(1.0);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(1.0, double0, 0.01);
  }
}
